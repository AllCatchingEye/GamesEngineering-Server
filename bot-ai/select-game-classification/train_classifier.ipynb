{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save(filename, *args):\n",
    "    # Get global dictionary\n",
    "    glob = globals()\n",
    "    d = {}\n",
    "    for v in args:\n",
    "        # Copy over desired values\n",
    "        d[v] = glob[v]\n",
    "    with open(filename, 'wb') as f:\n",
    "        # Put them in the file \n",
    "        pickle.dump(d, f)\n",
    "\n",
    "def load(filename):\n",
    "    # Get global dictionary\n",
    "    glob = globals()\n",
    "    with open(filename, 'rb') as f:\n",
    "        for k, v in pickle.load(f).items():\n",
    "            # Set each global variable to the value from the file\n",
    "            glob[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player1</th>\n",
       "      <th>Player2</th>\n",
       "      <th>Player3</th>\n",
       "      <th>Player4</th>\n",
       "      <th>Eichel Ober</th>\n",
       "      <th>Eichel Unter</th>\n",
       "      <th>Eichel Ass</th>\n",
       "      <th>Eichel 10</th>\n",
       "      <th>Eichel König</th>\n",
       "      <th>Eichel 9</th>\n",
       "      <th>...</th>\n",
       "      <th>SchellenOber</th>\n",
       "      <th>SchellenUnter</th>\n",
       "      <th>SchellenAss</th>\n",
       "      <th>Schellen10</th>\n",
       "      <th>SchellenKönig</th>\n",
       "      <th>Schellen9</th>\n",
       "      <th>Schellen8</th>\n",
       "      <th>Schellen7</th>\n",
       "      <th>Modus</th>\n",
       "      <th>Win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>weiter</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>weiter</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Farbwenz Schelle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Farbgeier Schelle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>weiter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Player1  Player2  Player3  Player4  Eichel Ober  Eichel Unter  Eichel Ass  \\\n",
       "0        1        0        0        0            1             0           1   \n",
       "1        0        1        0        0            0             0           0   \n",
       "2        0        0        0        1            0             1           0   \n",
       "3        0        0        0        1            1             0           0   \n",
       "4        1        0        0        0            0             0           0   \n",
       "\n",
       "   Eichel 10  Eichel König  Eichel 9  ...  SchellenOber  SchellenUnter  \\\n",
       "0          0             1         0  ...             0              0   \n",
       "1          0             0         1  ...             0              0   \n",
       "2          0             0         0  ...             1              1   \n",
       "3          0             0         0  ...             1              1   \n",
       "4          0             1         0  ...             1              0   \n",
       "\n",
       "   SchellenAss  Schellen10  SchellenKönig  Schellen9  Schellen8  Schellen7  \\\n",
       "0            0           0              1          1          0          0   \n",
       "1            0           1              0          0          0          0   \n",
       "2            0           0              0          0          0          1   \n",
       "3            0           0              0          0          0          1   \n",
       "4            0           0              0          0          1          1   \n",
       "\n",
       "               Modus  Win  \n",
       "0             weiter   -1  \n",
       "1             weiter   -1  \n",
       "2   Farbwenz Schelle    1  \n",
       "3  Farbgeier Schelle    1  \n",
       "4             weiter    1  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"select-game-classification/data.csv\", sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wins are currently excluded. A Correlation between wins and the game mode is not trivial.\n",
    "\n",
    "TODO: Research if wins are also helpful for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eichel Ober</th>\n",
       "      <th>Eichel Unter</th>\n",
       "      <th>Eichel Ass</th>\n",
       "      <th>Eichel 10</th>\n",
       "      <th>Eichel König</th>\n",
       "      <th>Eichel 9</th>\n",
       "      <th>Eichel 8</th>\n",
       "      <th>Eichel 7</th>\n",
       "      <th>Gras Ober</th>\n",
       "      <th>Gras Unter</th>\n",
       "      <th>...</th>\n",
       "      <th>Herz 8</th>\n",
       "      <th>Herz 7</th>\n",
       "      <th>SchellenOber</th>\n",
       "      <th>SchellenUnter</th>\n",
       "      <th>SchellenAss</th>\n",
       "      <th>Schellen10</th>\n",
       "      <th>SchellenKönig</th>\n",
       "      <th>Schellen9</th>\n",
       "      <th>Schellen8</th>\n",
       "      <th>Schellen7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Eichel Ober  Eichel Unter  Eichel Ass  Eichel 10  Eichel König  Eichel 9  \\\n",
       "0          1.0           0.0         1.0        0.0           1.0       0.0   \n",
       "1          0.0           0.0         0.0        0.0           0.0       1.0   \n",
       "2          0.0           1.0         0.0        0.0           0.0       0.0   \n",
       "3          1.0           0.0         0.0        0.0           0.0       0.0   \n",
       "4          0.0           0.0         0.0        0.0           1.0       0.0   \n",
       "\n",
       "   Eichel 8  Eichel 7  Gras Ober  Gras Unter  ...  Herz 8  Herz 7  \\\n",
       "0       0.0       1.0        0.0         0.0  ...     0.0     1.0   \n",
       "1       0.0       0.0        0.0         0.0  ...     0.0     0.0   \n",
       "2       1.0       0.0        0.0         1.0  ...     0.0     0.0   \n",
       "3       1.0       0.0        1.0         0.0  ...     0.0     0.0   \n",
       "4       0.0       0.0        0.0         0.0  ...     1.0     0.0   \n",
       "\n",
       "   SchellenOber  SchellenUnter  SchellenAss  Schellen10  SchellenKönig  \\\n",
       "0           0.0            0.0          0.0         0.0            1.0   \n",
       "1           0.0            0.0          0.0         1.0            0.0   \n",
       "2           1.0            1.0          0.0         0.0            0.0   \n",
       "3           1.0            1.0          0.0         0.0            0.0   \n",
       "4           1.0            0.0          0.0         0.0            0.0   \n",
       "\n",
       "   Schellen9  Schellen8  Schellen7  \n",
       "0        1.0        0.0        0.0  \n",
       "1        0.0        0.0        0.0  \n",
       "2        0.0        0.0        1.0  \n",
       "3        0.0        0.0        1.0  \n",
       "4        0.0        1.0        1.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = df.drop(['Player1','Player2','Player3','Player4','Win','Modus'], axis=1).astype(\"float32\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Size:  32\n"
     ]
    }
   ],
   "source": [
    "train_data_size = np.shape(np.array(train_data))\n",
    "input_size = train_data_size[1]\n",
    "print(\"Input Size: \", input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               weiter\n",
       "1               weiter\n",
       "2     Farbwenz Schelle\n",
       "3    Farbgeier Schelle\n",
       "4               weiter\n",
       "Name: Modus, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data = df['Modus']\n",
    "output_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Size:  18\n"
     ]
    }
   ],
   "source": [
    "output_data_codes = output_data.astype(\"category\").cat.codes\n",
    "output_size = max(output_data_codes) + 1\n",
    "y = output_data_codes.astype(\"long\")\n",
    "print(\"Output Size: \", output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_data, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectGameDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor([self.X.iloc[idx]], device=device), torch.tensor(self.y.iloc[idx], device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SelectGameDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SelectGameDataset(X_val, y_val)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectGameNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectGameNN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=18, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SelectGameNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167/2378170592.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return torch.tensor([self.X.iloc[idx]], device=device), torch.tensor(self.y.iloc[idx], device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] Batch [100/2120] Loss: 1.4790\n",
      "Epoch [1/100] Batch [200/2120] Loss: 0.9483\n",
      "Epoch [1/100] Batch [300/2120] Loss: 0.9089\n",
      "Epoch [1/100] Batch [400/2120] Loss: 0.8613\n",
      "Epoch [1/100] Batch [500/2120] Loss: 0.7969\n",
      "Epoch [1/100] Batch [600/2120] Loss: 0.7735\n",
      "Epoch [1/100] Batch [700/2120] Loss: 0.7070\n",
      "Epoch [1/100] Batch [800/2120] Loss: 0.6567\n",
      "Epoch [1/100] Batch [900/2120] Loss: 0.6279\n",
      "Epoch [1/100] Batch [1000/2120] Loss: 0.6224\n",
      "Epoch [1/100] Batch [1100/2120] Loss: 0.6170\n",
      "Epoch [1/100] Batch [1200/2120] Loss: 0.5638\n",
      "Epoch [1/100] Batch [1300/2120] Loss: 0.5861\n",
      "Epoch [1/100] Batch [1400/2120] Loss: 0.5503\n",
      "Epoch [1/100] Batch [1500/2120] Loss: 0.5327\n",
      "Epoch [1/100] Batch [1600/2120] Loss: 0.5301\n",
      "Epoch [1/100] Batch [1700/2120] Loss: 0.5422\n",
      "Epoch [1/100] Batch [1800/2120] Loss: 0.5312\n",
      "Epoch [1/100] Batch [1900/2120] Loss: 0.5207\n",
      "Epoch [1/100] Batch [2000/2120] Loss: 0.5223\n",
      "Epoch [1/100] Batch [2100/2120] Loss: 0.5236\n",
      "Epoch [2/100] Batch [100/2120] Loss: 0.5075\n",
      "Epoch [2/100] Batch [200/2120] Loss: 0.5113\n",
      "Epoch [2/100] Batch [300/2120] Loss: 0.5312\n",
      "Epoch [2/100] Batch [400/2120] Loss: 0.5129\n",
      "Epoch [2/100] Batch [500/2120] Loss: 0.4969\n",
      "Epoch [2/100] Batch [600/2120] Loss: 0.4893\n",
      "Epoch [2/100] Batch [700/2120] Loss: 0.4771\n",
      "Epoch [2/100] Batch [800/2120] Loss: 0.5152\n",
      "Epoch [2/100] Batch [900/2120] Loss: 0.4899\n",
      "Epoch [2/100] Batch [1000/2120] Loss: 0.5063\n",
      "Epoch [2/100] Batch [1100/2120] Loss: 0.4868\n",
      "Epoch [2/100] Batch [1200/2120] Loss: 0.4699\n",
      "Epoch [2/100] Batch [1300/2120] Loss: 0.4746\n",
      "Epoch [2/100] Batch [1400/2120] Loss: 0.4656\n",
      "Epoch [2/100] Batch [1500/2120] Loss: 0.4699\n",
      "Epoch [2/100] Batch [1600/2120] Loss: 0.4567\n",
      "Epoch [2/100] Batch [1700/2120] Loss: 0.4686\n",
      "Epoch [2/100] Batch [1800/2120] Loss: 0.4717\n",
      "Epoch [2/100] Batch [1900/2120] Loss: 0.4903\n",
      "Epoch [2/100] Batch [2000/2120] Loss: 0.4696\n",
      "Epoch [2/100] Batch [2100/2120] Loss: 0.4804\n",
      "Epoch [3/100] Batch [100/2120] Loss: 0.4713\n",
      "Epoch [3/100] Batch [200/2120] Loss: 0.4322\n",
      "Epoch [3/100] Batch [300/2120] Loss: 0.4751\n",
      "Epoch [3/100] Batch [400/2120] Loss: 0.4525\n",
      "Epoch [3/100] Batch [500/2120] Loss: 0.4602\n",
      "Epoch [3/100] Batch [600/2120] Loss: 0.4408\n",
      "Epoch [3/100] Batch [700/2120] Loss: 0.4481\n",
      "Epoch [3/100] Batch [800/2120] Loss: 0.4593\n",
      "Epoch [3/100] Batch [900/2120] Loss: 0.4389\n",
      "Epoch [3/100] Batch [1000/2120] Loss: 0.4452\n",
      "Epoch [3/100] Batch [1100/2120] Loss: 0.4522\n",
      "Epoch [3/100] Batch [1200/2120] Loss: 0.4476\n",
      "Epoch [3/100] Batch [1300/2120] Loss: 0.4398\n",
      "Epoch [3/100] Batch [1400/2120] Loss: 0.4512\n",
      "Epoch [3/100] Batch [1500/2120] Loss: 0.4387\n",
      "Epoch [3/100] Batch [1600/2120] Loss: 0.4322\n",
      "Epoch [3/100] Batch [1700/2120] Loss: 0.4391\n",
      "Epoch [3/100] Batch [1800/2120] Loss: 0.4379\n",
      "Epoch [3/100] Batch [1900/2120] Loss: 0.4357\n",
      "Epoch [3/100] Batch [2000/2120] Loss: 0.4353\n",
      "Epoch [3/100] Batch [2100/2120] Loss: 0.4257\n",
      "Epoch [4/100] Batch [100/2120] Loss: 0.4359\n",
      "Epoch [4/100] Batch [200/2120] Loss: 0.4301\n",
      "Epoch [4/100] Batch [300/2120] Loss: 0.4122\n",
      "Epoch [4/100] Batch [400/2120] Loss: 0.4432\n",
      "Epoch [4/100] Batch [500/2120] Loss: 0.4151\n",
      "Epoch [4/100] Batch [600/2120] Loss: 0.4251\n",
      "Epoch [4/100] Batch [700/2120] Loss: 0.4257\n",
      "Epoch [4/100] Batch [800/2120] Loss: 0.4127\n",
      "Epoch [4/100] Batch [900/2120] Loss: 0.4308\n",
      "Epoch [4/100] Batch [1000/2120] Loss: 0.4427\n",
      "Epoch [4/100] Batch [1100/2120] Loss: 0.4370\n",
      "Epoch [4/100] Batch [1200/2120] Loss: 0.4184\n",
      "Epoch [4/100] Batch [1300/2120] Loss: 0.4280\n",
      "Epoch [4/100] Batch [1400/2120] Loss: 0.4355\n",
      "Epoch [4/100] Batch [1500/2120] Loss: 0.4228\n",
      "Epoch [4/100] Batch [1600/2120] Loss: 0.4184\n",
      "Epoch [4/100] Batch [1700/2120] Loss: 0.4219\n",
      "Epoch [4/100] Batch [1800/2120] Loss: 0.4328\n",
      "Epoch [4/100] Batch [1900/2120] Loss: 0.4267\n",
      "Epoch [4/100] Batch [2000/2120] Loss: 0.4290\n",
      "Epoch [4/100] Batch [2100/2120] Loss: 0.4406\n",
      "Epoch [5/100] Batch [100/2120] Loss: 0.4162\n",
      "Epoch [5/100] Batch [200/2120] Loss: 0.4214\n",
      "Epoch [5/100] Batch [300/2120] Loss: 0.4099\n",
      "Epoch [5/100] Batch [400/2120] Loss: 0.4218\n",
      "Epoch [5/100] Batch [500/2120] Loss: 0.4215\n",
      "Epoch [5/100] Batch [600/2120] Loss: 0.4018\n",
      "Epoch [5/100] Batch [700/2120] Loss: 0.4232\n",
      "Epoch [5/100] Batch [800/2120] Loss: 0.4108\n",
      "Epoch [5/100] Batch [900/2120] Loss: 0.4293\n",
      "Epoch [5/100] Batch [1000/2120] Loss: 0.4272\n",
      "Epoch [5/100] Batch [1100/2120] Loss: 0.4107\n",
      "Epoch [5/100] Batch [1200/2120] Loss: 0.4241\n",
      "Epoch [5/100] Batch [1300/2120] Loss: 0.4153\n",
      "Epoch [5/100] Batch [1400/2120] Loss: 0.4353\n",
      "Epoch [5/100] Batch [1500/2120] Loss: 0.4107\n",
      "Epoch [5/100] Batch [1600/2120] Loss: 0.4110\n",
      "Epoch [5/100] Batch [1700/2120] Loss: 0.3981\n",
      "Epoch [5/100] Batch [1800/2120] Loss: 0.4182\n",
      "Epoch [5/100] Batch [1900/2120] Loss: 0.4390\n",
      "Epoch [5/100] Batch [2000/2120] Loss: 0.4266\n",
      "Epoch [5/100] Batch [2100/2120] Loss: 0.4201\n",
      "Epoch [6/100] Batch [100/2120] Loss: 0.4144\n",
      "Epoch [6/100] Batch [200/2120] Loss: 0.4122\n",
      "Epoch [6/100] Batch [300/2120] Loss: 0.4248\n",
      "Epoch [6/100] Batch [400/2120] Loss: 0.4327\n",
      "Epoch [6/100] Batch [500/2120] Loss: 0.4080\n",
      "Epoch [6/100] Batch [600/2120] Loss: 0.4149\n",
      "Epoch [6/100] Batch [700/2120] Loss: 0.4015\n",
      "Epoch [6/100] Batch [800/2120] Loss: 0.4256\n",
      "Epoch [6/100] Batch [900/2120] Loss: 0.4089\n",
      "Epoch [6/100] Batch [1000/2120] Loss: 0.4232\n",
      "Epoch [6/100] Batch [1100/2120] Loss: 0.4214\n",
      "Epoch [6/100] Batch [1200/2120] Loss: 0.4017\n",
      "Epoch [6/100] Batch [1300/2120] Loss: 0.4175\n",
      "Epoch [6/100] Batch [1400/2120] Loss: 0.4202\n",
      "Epoch [6/100] Batch [1500/2120] Loss: 0.4016\n",
      "Epoch [6/100] Batch [1600/2120] Loss: 0.4120\n",
      "Epoch [6/100] Batch [1700/2120] Loss: 0.4103\n",
      "Epoch [6/100] Batch [1800/2120] Loss: 0.3901\n",
      "Epoch [6/100] Batch [1900/2120] Loss: 0.4090\n",
      "Epoch [6/100] Batch [2000/2120] Loss: 0.4167\n",
      "Epoch [6/100] Batch [2100/2120] Loss: 0.4116\n",
      "Epoch [7/100] Batch [100/2120] Loss: 0.4059\n",
      "Epoch [7/100] Batch [200/2120] Loss: 0.4174\n",
      "Epoch [7/100] Batch [300/2120] Loss: 0.4035\n",
      "Epoch [7/100] Batch [400/2120] Loss: 0.4093\n",
      "Epoch [7/100] Batch [500/2120] Loss: 0.4039\n",
      "Epoch [7/100] Batch [600/2120] Loss: 0.4075\n",
      "Epoch [7/100] Batch [700/2120] Loss: 0.4145\n",
      "Epoch [7/100] Batch [800/2120] Loss: 0.4217\n",
      "Epoch [7/100] Batch [900/2120] Loss: 0.4040\n",
      "Epoch [7/100] Batch [1000/2120] Loss: 0.4131\n",
      "Epoch [7/100] Batch [1100/2120] Loss: 0.4162\n",
      "Epoch [7/100] Batch [1200/2120] Loss: 0.4086\n",
      "Epoch [7/100] Batch [1300/2120] Loss: 0.4193\n",
      "Epoch [7/100] Batch [1400/2120] Loss: 0.4151\n",
      "Epoch [7/100] Batch [1500/2120] Loss: 0.4094\n",
      "Epoch [7/100] Batch [1600/2120] Loss: 0.3992\n",
      "Epoch [7/100] Batch [1700/2120] Loss: 0.4082\n",
      "Epoch [7/100] Batch [1800/2120] Loss: 0.3912\n",
      "Epoch [7/100] Batch [1900/2120] Loss: 0.4127\n",
      "Epoch [7/100] Batch [2000/2120] Loss: 0.4175\n",
      "Epoch [7/100] Batch [2100/2120] Loss: 0.3974\n",
      "Epoch [8/100] Batch [100/2120] Loss: 0.4072\n",
      "Epoch [8/100] Batch [200/2120] Loss: 0.3978\n",
      "Epoch [8/100] Batch [300/2120] Loss: 0.4106\n",
      "Epoch [8/100] Batch [400/2120] Loss: 0.3991\n",
      "Epoch [8/100] Batch [500/2120] Loss: 0.4062\n",
      "Epoch [8/100] Batch [600/2120] Loss: 0.4032\n",
      "Epoch [8/100] Batch [700/2120] Loss: 0.4022\n",
      "Epoch [8/100] Batch [800/2120] Loss: 0.3976\n",
      "Epoch [8/100] Batch [900/2120] Loss: 0.3965\n",
      "Epoch [8/100] Batch [1000/2120] Loss: 0.3909\n",
      "Epoch [8/100] Batch [1100/2120] Loss: 0.4178\n",
      "Epoch [8/100] Batch [1200/2120] Loss: 0.4116\n",
      "Epoch [8/100] Batch [1300/2120] Loss: 0.4096\n",
      "Epoch [8/100] Batch [1400/2120] Loss: 0.4257\n",
      "Epoch [8/100] Batch [1500/2120] Loss: 0.4018\n",
      "Epoch [8/100] Batch [1600/2120] Loss: 0.4075\n",
      "Epoch [8/100] Batch [1700/2120] Loss: 0.4012\n",
      "Epoch [8/100] Batch [1800/2120] Loss: 0.4167\n",
      "Epoch [8/100] Batch [1900/2120] Loss: 0.4019\n",
      "Epoch [8/100] Batch [2000/2120] Loss: 0.3985\n",
      "Epoch [8/100] Batch [2100/2120] Loss: 0.4161\n",
      "Epoch [9/100] Batch [100/2120] Loss: 0.4089\n",
      "Epoch [9/100] Batch [200/2120] Loss: 0.4021\n",
      "Epoch [9/100] Batch [300/2120] Loss: 0.3915\n",
      "Epoch [9/100] Batch [400/2120] Loss: 0.4067\n",
      "Epoch [9/100] Batch [500/2120] Loss: 0.3893\n",
      "Epoch [9/100] Batch [600/2120] Loss: 0.4000\n",
      "Epoch [9/100] Batch [700/2120] Loss: 0.4223\n",
      "Epoch [9/100] Batch [800/2120] Loss: 0.3948\n",
      "Epoch [9/100] Batch [900/2120] Loss: 0.4045\n",
      "Epoch [9/100] Batch [1000/2120] Loss: 0.4079\n",
      "Epoch [9/100] Batch [1100/2120] Loss: 0.4052\n",
      "Epoch [9/100] Batch [1200/2120] Loss: 0.4014\n",
      "Epoch [9/100] Batch [1300/2120] Loss: 0.3996\n",
      "Epoch [9/100] Batch [1400/2120] Loss: 0.4014\n",
      "Epoch [9/100] Batch [1500/2120] Loss: 0.4008\n",
      "Epoch [9/100] Batch [1600/2120] Loss: 0.3980\n",
      "Epoch [9/100] Batch [1700/2120] Loss: 0.3922\n",
      "Epoch [9/100] Batch [1800/2120] Loss: 0.4043\n",
      "Epoch [9/100] Batch [1900/2120] Loss: 0.4136\n",
      "Epoch [9/100] Batch [2000/2120] Loss: 0.4176\n",
      "Epoch [9/100] Batch [2100/2120] Loss: 0.4015\n",
      "Epoch [10/100] Batch [100/2120] Loss: 0.3946\n",
      "Epoch [10/100] Batch [200/2120] Loss: 0.4071\n",
      "Epoch [10/100] Batch [300/2120] Loss: 0.3971\n",
      "Epoch [10/100] Batch [400/2120] Loss: 0.4123\n",
      "Epoch [10/100] Batch [500/2120] Loss: 0.3993\n",
      "Epoch [10/100] Batch [600/2120] Loss: 0.3820\n",
      "Epoch [10/100] Batch [700/2120] Loss: 0.4001\n",
      "Epoch [10/100] Batch [800/2120] Loss: 0.4017\n",
      "Epoch [10/100] Batch [900/2120] Loss: 0.4006\n",
      "Epoch [10/100] Batch [1000/2120] Loss: 0.4060\n",
      "Epoch [10/100] Batch [1100/2120] Loss: 0.4015\n",
      "Epoch [10/100] Batch [1200/2120] Loss: 0.4150\n",
      "Epoch [10/100] Batch [1300/2120] Loss: 0.4087\n",
      "Epoch [10/100] Batch [1400/2120] Loss: 0.4049\n",
      "Epoch [10/100] Batch [1500/2120] Loss: 0.3926\n",
      "Epoch [10/100] Batch [1600/2120] Loss: 0.3857\n",
      "Epoch [10/100] Batch [1700/2120] Loss: 0.3994\n",
      "Epoch [10/100] Batch [1800/2120] Loss: 0.3989\n",
      "Epoch [10/100] Batch [1900/2120] Loss: 0.3970\n",
      "Epoch [10/100] Batch [2000/2120] Loss: 0.3935\n",
      "Epoch [10/100] Batch [2100/2120] Loss: 0.4159\n",
      "Epoch [11/100] Batch [100/2120] Loss: 0.3872\n",
      "Epoch [11/100] Batch [200/2120] Loss: 0.3823\n",
      "Epoch [11/100] Batch [300/2120] Loss: 0.3884\n",
      "Epoch [11/100] Batch [400/2120] Loss: 0.4112\n",
      "Epoch [11/100] Batch [500/2120] Loss: 0.3992\n",
      "Epoch [11/100] Batch [600/2120] Loss: 0.3958\n",
      "Epoch [11/100] Batch [700/2120] Loss: 0.3874\n",
      "Epoch [11/100] Batch [800/2120] Loss: 0.3958\n",
      "Epoch [11/100] Batch [900/2120] Loss: 0.4183\n",
      "Epoch [11/100] Batch [1000/2120] Loss: 0.4006\n",
      "Epoch [11/100] Batch [1100/2120] Loss: 0.4103\n",
      "Epoch [11/100] Batch [1200/2120] Loss: 0.3924\n",
      "Epoch [11/100] Batch [1300/2120] Loss: 0.4039\n",
      "Epoch [11/100] Batch [1400/2120] Loss: 0.3957\n",
      "Epoch [11/100] Batch [1500/2120] Loss: 0.3897\n",
      "Epoch [11/100] Batch [1600/2120] Loss: 0.3918\n",
      "Epoch [11/100] Batch [1700/2120] Loss: 0.3926\n",
      "Epoch [11/100] Batch [1800/2120] Loss: 0.3888\n",
      "Epoch [11/100] Batch [1900/2120] Loss: 0.4154\n",
      "Epoch [11/100] Batch [2000/2120] Loss: 0.4220\n",
      "Epoch [11/100] Batch [2100/2120] Loss: 0.3978\n",
      "Epoch [12/100] Batch [100/2120] Loss: 0.3897\n",
      "Epoch [12/100] Batch [200/2120] Loss: 0.3773\n",
      "Epoch [12/100] Batch [300/2120] Loss: 0.3972\n",
      "Epoch [12/100] Batch [400/2120] Loss: 0.4067\n",
      "Epoch [12/100] Batch [500/2120] Loss: 0.3971\n",
      "Epoch [12/100] Batch [600/2120] Loss: 0.3857\n",
      "Epoch [12/100] Batch [700/2120] Loss: 0.4007\n",
      "Epoch [12/100] Batch [800/2120] Loss: 0.3897\n",
      "Epoch [12/100] Batch [900/2120] Loss: 0.3964\n",
      "Epoch [12/100] Batch [1000/2120] Loss: 0.3916\n",
      "Epoch [12/100] Batch [1100/2120] Loss: 0.4106\n",
      "Epoch [12/100] Batch [1200/2120] Loss: 0.4090\n",
      "Epoch [12/100] Batch [1300/2120] Loss: 0.3972\n",
      "Epoch [12/100] Batch [1400/2120] Loss: 0.3979\n",
      "Epoch [12/100] Batch [1500/2120] Loss: 0.3951\n",
      "Epoch [12/100] Batch [1600/2120] Loss: 0.3830\n",
      "Epoch [12/100] Batch [1700/2120] Loss: 0.4106\n",
      "Epoch [12/100] Batch [1800/2120] Loss: 0.4117\n",
      "Epoch [12/100] Batch [1900/2120] Loss: 0.4089\n",
      "Epoch [12/100] Batch [2000/2120] Loss: 0.3822\n",
      "Epoch [12/100] Batch [2100/2120] Loss: 0.3995\n",
      "Epoch [13/100] Batch [100/2120] Loss: 0.4000\n",
      "Epoch [13/100] Batch [200/2120] Loss: 0.4040\n",
      "Epoch [13/100] Batch [300/2120] Loss: 0.3857\n",
      "Epoch [13/100] Batch [400/2120] Loss: 0.3996\n",
      "Epoch [13/100] Batch [500/2120] Loss: 0.3988\n",
      "Epoch [13/100] Batch [600/2120] Loss: 0.3715\n",
      "Epoch [13/100] Batch [700/2120] Loss: 0.3799\n",
      "Epoch [13/100] Batch [800/2120] Loss: 0.4056\n",
      "Epoch [13/100] Batch [900/2120] Loss: 0.3916\n",
      "Epoch [13/100] Batch [1000/2120] Loss: 0.3937\n",
      "Epoch [13/100] Batch [1100/2120] Loss: 0.4045\n",
      "Epoch [13/100] Batch [1200/2120] Loss: 0.4141\n",
      "Epoch [13/100] Batch [1300/2120] Loss: 0.3885\n",
      "Epoch [13/100] Batch [1400/2120] Loss: 0.4080\n",
      "Epoch [13/100] Batch [1500/2120] Loss: 0.3917\n",
      "Epoch [13/100] Batch [1600/2120] Loss: 0.3940\n",
      "Epoch [13/100] Batch [1700/2120] Loss: 0.4080\n",
      "Epoch [13/100] Batch [1800/2120] Loss: 0.3936\n",
      "Epoch [13/100] Batch [1900/2120] Loss: 0.3958\n",
      "Epoch [13/100] Batch [2000/2120] Loss: 0.3813\n",
      "Epoch [13/100] Batch [2100/2120] Loss: 0.3829\n",
      "Epoch [14/100] Batch [100/2120] Loss: 0.3887\n",
      "Epoch [14/100] Batch [200/2120] Loss: 0.3867\n",
      "Epoch [14/100] Batch [300/2120] Loss: 0.3850\n",
      "Epoch [14/100] Batch [400/2120] Loss: 0.3952\n",
      "Epoch [14/100] Batch [500/2120] Loss: 0.3834\n",
      "Epoch [14/100] Batch [600/2120] Loss: 0.3773\n",
      "Epoch [14/100] Batch [700/2120] Loss: 0.4061\n",
      "Epoch [14/100] Batch [800/2120] Loss: 0.3867\n",
      "Epoch [14/100] Batch [900/2120] Loss: 0.4006\n",
      "Epoch [14/100] Batch [1000/2120] Loss: 0.3851\n",
      "Epoch [14/100] Batch [1100/2120] Loss: 0.3888\n",
      "Epoch [14/100] Batch [1200/2120] Loss: 0.4150\n",
      "Epoch [14/100] Batch [1300/2120] Loss: 0.3951\n",
      "Epoch [14/100] Batch [1400/2120] Loss: 0.3906\n",
      "Epoch [14/100] Batch [1500/2120] Loss: 0.3948\n",
      "Epoch [14/100] Batch [1600/2120] Loss: 0.3936\n",
      "Epoch [14/100] Batch [1700/2120] Loss: 0.3860\n",
      "Epoch [14/100] Batch [1800/2120] Loss: 0.3942\n",
      "Epoch [14/100] Batch [1900/2120] Loss: 0.3925\n",
      "Epoch [14/100] Batch [2000/2120] Loss: 0.4057\n",
      "Epoch [14/100] Batch [2100/2120] Loss: 0.3933\n",
      "Epoch [15/100] Batch [100/2120] Loss: 0.3792\n",
      "Epoch [15/100] Batch [200/2120] Loss: 0.3986\n",
      "Epoch [15/100] Batch [300/2120] Loss: 0.3901\n",
      "Epoch [15/100] Batch [400/2120] Loss: 0.4003\n",
      "Epoch [15/100] Batch [500/2120] Loss: 0.3915\n",
      "Epoch [15/100] Batch [600/2120] Loss: 0.3884\n",
      "Epoch [15/100] Batch [700/2120] Loss: 0.4003\n",
      "Epoch [15/100] Batch [800/2120] Loss: 0.3931\n",
      "Epoch [15/100] Batch [900/2120] Loss: 0.3982\n",
      "Epoch [15/100] Batch [1000/2120] Loss: 0.3971\n",
      "Epoch [15/100] Batch [1100/2120] Loss: 0.3937\n",
      "Epoch [15/100] Batch [1200/2120] Loss: 0.3827\n",
      "Epoch [15/100] Batch [1300/2120] Loss: 0.3764\n",
      "Epoch [15/100] Batch [1400/2120] Loss: 0.3945\n",
      "Epoch [15/100] Batch [1500/2120] Loss: 0.3856\n",
      "Epoch [15/100] Batch [1600/2120] Loss: 0.3843\n",
      "Epoch [15/100] Batch [1700/2120] Loss: 0.3908\n",
      "Epoch [15/100] Batch [1800/2120] Loss: 0.4105\n",
      "Epoch [15/100] Batch [1900/2120] Loss: 0.3863\n",
      "Epoch [15/100] Batch [2000/2120] Loss: 0.3885\n",
      "Epoch [15/100] Batch [2100/2120] Loss: 0.3844\n",
      "Epoch [16/100] Batch [100/2120] Loss: 0.3839\n",
      "Epoch [16/100] Batch [200/2120] Loss: 0.3802\n",
      "Epoch [16/100] Batch [300/2120] Loss: 0.3806\n",
      "Epoch [16/100] Batch [400/2120] Loss: 0.3838\n",
      "Epoch [16/100] Batch [500/2120] Loss: 0.3953\n",
      "Epoch [16/100] Batch [600/2120] Loss: 0.3965\n",
      "Epoch [16/100] Batch [700/2120] Loss: 0.3979\n",
      "Epoch [16/100] Batch [800/2120] Loss: 0.4126\n",
      "Epoch [16/100] Batch [900/2120] Loss: 0.3874\n",
      "Epoch [16/100] Batch [1000/2120] Loss: 0.3955\n",
      "Epoch [16/100] Batch [1100/2120] Loss: 0.3764\n",
      "Epoch [16/100] Batch [1200/2120] Loss: 0.3895\n",
      "Epoch [16/100] Batch [1300/2120] Loss: 0.3807\n",
      "Epoch [16/100] Batch [1400/2120] Loss: 0.4005\n",
      "Epoch [16/100] Batch [1500/2120] Loss: 0.4011\n",
      "Epoch [16/100] Batch [1600/2120] Loss: 0.3841\n",
      "Epoch [16/100] Batch [1700/2120] Loss: 0.3907\n",
      "Epoch [16/100] Batch [1800/2120] Loss: 0.3987\n",
      "Epoch [16/100] Batch [1900/2120] Loss: 0.3953\n",
      "Epoch [16/100] Batch [2000/2120] Loss: 0.3874\n",
      "Epoch [16/100] Batch [2100/2120] Loss: 0.3821\n",
      "Epoch [17/100] Batch [100/2120] Loss: 0.3716\n",
      "Epoch [17/100] Batch [200/2120] Loss: 0.4032\n",
      "Epoch [17/100] Batch [300/2120] Loss: 0.3756\n",
      "Epoch [17/100] Batch [400/2120] Loss: 0.3747\n",
      "Epoch [17/100] Batch [500/2120] Loss: 0.3648\n",
      "Epoch [17/100] Batch [600/2120] Loss: 0.3845\n",
      "Epoch [17/100] Batch [700/2120] Loss: 0.4004\n",
      "Epoch [17/100] Batch [800/2120] Loss: 0.3854\n",
      "Epoch [17/100] Batch [900/2120] Loss: 0.4037\n",
      "Epoch [17/100] Batch [1000/2120] Loss: 0.3918\n",
      "Epoch [17/100] Batch [1100/2120] Loss: 0.3950\n",
      "Epoch [17/100] Batch [1200/2120] Loss: 0.3877\n",
      "Epoch [17/100] Batch [1300/2120] Loss: 0.3745\n",
      "Epoch [17/100] Batch [1400/2120] Loss: 0.3935\n",
      "Epoch [17/100] Batch [1500/2120] Loss: 0.4114\n",
      "Epoch [17/100] Batch [1600/2120] Loss: 0.3982\n",
      "Epoch [17/100] Batch [1700/2120] Loss: 0.4058\n",
      "Epoch [17/100] Batch [1800/2120] Loss: 0.3864\n",
      "Epoch [17/100] Batch [1900/2120] Loss: 0.3782\n",
      "Epoch [17/100] Batch [2000/2120] Loss: 0.4020\n",
      "Epoch [17/100] Batch [2100/2120] Loss: 0.3794\n",
      "Epoch [18/100] Batch [100/2120] Loss: 0.3796\n",
      "Epoch [18/100] Batch [200/2120] Loss: 0.3963\n",
      "Epoch [18/100] Batch [300/2120] Loss: 0.3727\n",
      "Epoch [18/100] Batch [400/2120] Loss: 0.3686\n",
      "Epoch [18/100] Batch [500/2120] Loss: 0.3851\n",
      "Epoch [18/100] Batch [600/2120] Loss: 0.3879\n",
      "Epoch [18/100] Batch [700/2120] Loss: 0.3842\n",
      "Epoch [18/100] Batch [800/2120] Loss: 0.3895\n",
      "Epoch [18/100] Batch [900/2120] Loss: 0.3902\n",
      "Epoch [18/100] Batch [1000/2120] Loss: 0.3892\n",
      "Epoch [18/100] Batch [1100/2120] Loss: 0.3928\n",
      "Epoch [18/100] Batch [1200/2120] Loss: 0.3924\n",
      "Epoch [18/100] Batch [1300/2120] Loss: 0.4049\n",
      "Epoch [18/100] Batch [1400/2120] Loss: 0.3953\n",
      "Epoch [18/100] Batch [1500/2120] Loss: 0.3955\n",
      "Epoch [18/100] Batch [1600/2120] Loss: 0.4061\n",
      "Epoch [18/100] Batch [1700/2120] Loss: 0.4020\n",
      "Epoch [18/100] Batch [1800/2120] Loss: 0.3719\n",
      "Epoch [18/100] Batch [1900/2120] Loss: 0.3743\n",
      "Epoch [18/100] Batch [2000/2120] Loss: 0.3889\n",
      "Epoch [18/100] Batch [2100/2120] Loss: 0.3910\n",
      "Epoch [19/100] Batch [100/2120] Loss: 0.3726\n",
      "Epoch [19/100] Batch [200/2120] Loss: 0.3851\n",
      "Epoch [19/100] Batch [300/2120] Loss: 0.3777\n",
      "Epoch [19/100] Batch [400/2120] Loss: 0.3811\n",
      "Epoch [19/100] Batch [500/2120] Loss: 0.3925\n",
      "Epoch [19/100] Batch [600/2120] Loss: 0.3684\n",
      "Epoch [19/100] Batch [700/2120] Loss: 0.3967\n",
      "Epoch [19/100] Batch [800/2120] Loss: 0.3859\n",
      "Epoch [19/100] Batch [900/2120] Loss: 0.3778\n",
      "Epoch [19/100] Batch [1000/2120] Loss: 0.3851\n",
      "Epoch [19/100] Batch [1100/2120] Loss: 0.4091\n",
      "Epoch [19/100] Batch [1200/2120] Loss: 0.3948\n",
      "Epoch [19/100] Batch [1300/2120] Loss: 0.3833\n",
      "Epoch [19/100] Batch [1400/2120] Loss: 0.3655\n",
      "Epoch [19/100] Batch [1500/2120] Loss: 0.3972\n",
      "Epoch [19/100] Batch [1600/2120] Loss: 0.3854\n",
      "Epoch [19/100] Batch [1700/2120] Loss: 0.3921\n",
      "Epoch [19/100] Batch [1800/2120] Loss: 0.3915\n",
      "Epoch [19/100] Batch [1900/2120] Loss: 0.3855\n",
      "Epoch [19/100] Batch [2000/2120] Loss: 0.3906\n",
      "Epoch [19/100] Batch [2100/2120] Loss: 0.4030\n",
      "Epoch [20/100] Batch [100/2120] Loss: 0.3797\n",
      "Epoch [20/100] Batch [200/2120] Loss: 0.3785\n",
      "Epoch [20/100] Batch [300/2120] Loss: 0.3880\n",
      "Epoch [20/100] Batch [400/2120] Loss: 0.3828\n",
      "Epoch [20/100] Batch [500/2120] Loss: 0.3972\n",
      "Epoch [20/100] Batch [600/2120] Loss: 0.3786\n",
      "Epoch [20/100] Batch [700/2120] Loss: 0.3738\n",
      "Epoch [20/100] Batch [800/2120] Loss: 0.3931\n",
      "Epoch [20/100] Batch [900/2120] Loss: 0.3882\n",
      "Epoch [20/100] Batch [1000/2120] Loss: 0.3813\n",
      "Epoch [20/100] Batch [1100/2120] Loss: 0.3777\n",
      "Epoch [20/100] Batch [1200/2120] Loss: 0.4058\n",
      "Epoch [20/100] Batch [1300/2120] Loss: 0.3849\n",
      "Epoch [20/100] Batch [1400/2120] Loss: 0.3984\n",
      "Epoch [20/100] Batch [1500/2120] Loss: 0.3878\n",
      "Epoch [20/100] Batch [1600/2120] Loss: 0.3922\n",
      "Epoch [20/100] Batch [1700/2120] Loss: 0.3772\n",
      "Epoch [20/100] Batch [1800/2120] Loss: 0.3780\n",
      "Epoch [20/100] Batch [1900/2120] Loss: 0.3896\n",
      "Epoch [20/100] Batch [2000/2120] Loss: 0.3853\n",
      "Epoch [20/100] Batch [2100/2120] Loss: 0.3862\n",
      "Epoch [21/100] Batch [100/2120] Loss: 0.3909\n",
      "Epoch [21/100] Batch [200/2120] Loss: 0.3747\n",
      "Epoch [21/100] Batch [300/2120] Loss: 0.3960\n",
      "Epoch [21/100] Batch [400/2120] Loss: 0.4087\n",
      "Epoch [21/100] Batch [500/2120] Loss: 0.3934\n",
      "Epoch [21/100] Batch [600/2120] Loss: 0.3781\n",
      "Epoch [21/100] Batch [700/2120] Loss: 0.3688\n",
      "Epoch [21/100] Batch [800/2120] Loss: 0.3842\n",
      "Epoch [21/100] Batch [900/2120] Loss: 0.3774\n",
      "Epoch [21/100] Batch [1000/2120] Loss: 0.3815\n",
      "Epoch [21/100] Batch [1100/2120] Loss: 0.3858\n",
      "Epoch [21/100] Batch [1200/2120] Loss: 0.3781\n",
      "Epoch [21/100] Batch [1300/2120] Loss: 0.3918\n",
      "Epoch [21/100] Batch [1400/2120] Loss: 0.3963\n",
      "Epoch [21/100] Batch [1500/2120] Loss: 0.3883\n",
      "Epoch [21/100] Batch [1600/2120] Loss: 0.3889\n",
      "Epoch [21/100] Batch [1700/2120] Loss: 0.3786\n",
      "Epoch [21/100] Batch [1800/2120] Loss: 0.3862\n",
      "Epoch [21/100] Batch [1900/2120] Loss: 0.3822\n",
      "Epoch [21/100] Batch [2000/2120] Loss: 0.3798\n",
      "Epoch [21/100] Batch [2100/2120] Loss: 0.3748\n",
      "Epoch [22/100] Batch [100/2120] Loss: 0.3943\n",
      "Epoch [22/100] Batch [200/2120] Loss: 0.3900\n",
      "Epoch [22/100] Batch [300/2120] Loss: 0.3901\n",
      "Epoch [22/100] Batch [400/2120] Loss: 0.3985\n",
      "Epoch [22/100] Batch [500/2120] Loss: 0.3822\n",
      "Epoch [22/100] Batch [600/2120] Loss: 0.3778\n",
      "Epoch [22/100] Batch [700/2120] Loss: 0.3833\n",
      "Epoch [22/100] Batch [800/2120] Loss: 0.3852\n",
      "Epoch [22/100] Batch [900/2120] Loss: 0.3675\n",
      "Epoch [22/100] Batch [1000/2120] Loss: 0.3941\n",
      "Epoch [22/100] Batch [1100/2120] Loss: 0.3929\n",
      "Epoch [22/100] Batch [1200/2120] Loss: 0.3955\n",
      "Epoch [22/100] Batch [1300/2120] Loss: 0.3731\n",
      "Epoch [22/100] Batch [1400/2120] Loss: 0.3742\n",
      "Epoch [22/100] Batch [1500/2120] Loss: 0.3812\n",
      "Epoch [22/100] Batch [1600/2120] Loss: 0.3823\n",
      "Epoch [22/100] Batch [1700/2120] Loss: 0.3825\n",
      "Epoch [22/100] Batch [1800/2120] Loss: 0.3737\n",
      "Epoch [22/100] Batch [1900/2120] Loss: 0.3725\n",
      "Epoch [22/100] Batch [2000/2120] Loss: 0.3854\n",
      "Epoch [22/100] Batch [2100/2120] Loss: 0.3787\n",
      "Epoch [23/100] Batch [100/2120] Loss: 0.3839\n",
      "Epoch [23/100] Batch [200/2120] Loss: 0.3833\n",
      "Epoch [23/100] Batch [300/2120] Loss: 0.3825\n",
      "Epoch [23/100] Batch [400/2120] Loss: 0.3707\n",
      "Epoch [23/100] Batch [500/2120] Loss: 0.3837\n",
      "Epoch [23/100] Batch [600/2120] Loss: 0.3905\n",
      "Epoch [23/100] Batch [700/2120] Loss: 0.3916\n",
      "Epoch [23/100] Batch [800/2120] Loss: 0.3681\n",
      "Epoch [23/100] Batch [900/2120] Loss: 0.3901\n",
      "Epoch [23/100] Batch [1000/2120] Loss: 0.3755\n",
      "Epoch [23/100] Batch [1100/2120] Loss: 0.3833\n",
      "Epoch [23/100] Batch [1200/2120] Loss: 0.3822\n",
      "Epoch [23/100] Batch [1300/2120] Loss: 0.3840\n",
      "Epoch [23/100] Batch [1400/2120] Loss: 0.3883\n",
      "Epoch [23/100] Batch [1500/2120] Loss: 0.3832\n",
      "Epoch [23/100] Batch [1600/2120] Loss: 0.3720\n",
      "Epoch [23/100] Batch [1700/2120] Loss: 0.3894\n",
      "Epoch [23/100] Batch [1800/2120] Loss: 0.3804\n",
      "Epoch [23/100] Batch [1900/2120] Loss: 0.3831\n",
      "Epoch [23/100] Batch [2000/2120] Loss: 0.3858\n",
      "Epoch [23/100] Batch [2100/2120] Loss: 0.3884\n",
      "Epoch [24/100] Batch [100/2120] Loss: 0.3654\n",
      "Epoch [24/100] Batch [200/2120] Loss: 0.3777\n",
      "Epoch [24/100] Batch [300/2120] Loss: 0.3807\n",
      "Epoch [24/100] Batch [400/2120] Loss: 0.3834\n",
      "Epoch [24/100] Batch [500/2120] Loss: 0.3965\n",
      "Epoch [24/100] Batch [600/2120] Loss: 0.3753\n",
      "Epoch [24/100] Batch [700/2120] Loss: 0.3889\n",
      "Epoch [24/100] Batch [800/2120] Loss: 0.3737\n",
      "Epoch [24/100] Batch [900/2120] Loss: 0.3815\n",
      "Epoch [24/100] Batch [1000/2120] Loss: 0.3903\n",
      "Epoch [24/100] Batch [1100/2120] Loss: 0.3854\n",
      "Epoch [24/100] Batch [1200/2120] Loss: 0.3868\n",
      "Epoch [24/100] Batch [1300/2120] Loss: 0.3710\n",
      "Epoch [24/100] Batch [1400/2120] Loss: 0.3712\n",
      "Epoch [24/100] Batch [1500/2120] Loss: 0.3909\n",
      "Epoch [24/100] Batch [1600/2120] Loss: 0.3680\n",
      "Epoch [24/100] Batch [1700/2120] Loss: 0.3844\n",
      "Epoch [24/100] Batch [1800/2120] Loss: 0.4009\n",
      "Epoch [24/100] Batch [1900/2120] Loss: 0.3932\n",
      "Epoch [24/100] Batch [2000/2120] Loss: 0.3867\n",
      "Epoch [24/100] Batch [2100/2120] Loss: 0.3829\n",
      "Epoch [25/100] Batch [100/2120] Loss: 0.3737\n",
      "Epoch [25/100] Batch [200/2120] Loss: 0.3953\n",
      "Epoch [25/100] Batch [300/2120] Loss: 0.3593\n",
      "Epoch [25/100] Batch [400/2120] Loss: 0.3852\n",
      "Epoch [25/100] Batch [500/2120] Loss: 0.3715\n",
      "Epoch [25/100] Batch [600/2120] Loss: 0.3868\n",
      "Epoch [25/100] Batch [700/2120] Loss: 0.3856\n",
      "Epoch [25/100] Batch [800/2120] Loss: 0.3704\n",
      "Epoch [25/100] Batch [900/2120] Loss: 0.3777\n",
      "Epoch [25/100] Batch [1000/2120] Loss: 0.3883\n",
      "Epoch [25/100] Batch [1100/2120] Loss: 0.3849\n",
      "Epoch [25/100] Batch [1200/2120] Loss: 0.3587\n",
      "Epoch [25/100] Batch [1300/2120] Loss: 0.3949\n",
      "Epoch [25/100] Batch [1400/2120] Loss: 0.3610\n",
      "Epoch [25/100] Batch [1500/2120] Loss: 0.3971\n",
      "Epoch [25/100] Batch [1600/2120] Loss: 0.3790\n",
      "Epoch [25/100] Batch [1700/2120] Loss: 0.3812\n",
      "Epoch [25/100] Batch [1800/2120] Loss: 0.3897\n",
      "Epoch [25/100] Batch [1900/2120] Loss: 0.3704\n",
      "Epoch [25/100] Batch [2000/2120] Loss: 0.3716\n",
      "Epoch [25/100] Batch [2100/2120] Loss: 0.3991\n",
      "Epoch [26/100] Batch [100/2120] Loss: 0.3785\n",
      "Epoch [26/100] Batch [200/2120] Loss: 0.3841\n",
      "Epoch [26/100] Batch [300/2120] Loss: 0.3882\n",
      "Epoch [26/100] Batch [400/2120] Loss: 0.3687\n",
      "Epoch [26/100] Batch [500/2120] Loss: 0.3825\n",
      "Epoch [26/100] Batch [600/2120] Loss: 0.3931\n",
      "Epoch [26/100] Batch [700/2120] Loss: 0.3623\n",
      "Epoch [26/100] Batch [800/2120] Loss: 0.3827\n",
      "Epoch [26/100] Batch [900/2120] Loss: 0.3776\n",
      "Epoch [26/100] Batch [1000/2120] Loss: 0.3726\n",
      "Epoch [26/100] Batch [1100/2120] Loss: 0.3706\n",
      "Epoch [26/100] Batch [1200/2120] Loss: 0.3731\n",
      "Epoch [26/100] Batch [1300/2120] Loss: 0.3912\n",
      "Epoch [26/100] Batch [1400/2120] Loss: 0.3627\n",
      "Epoch [26/100] Batch [1500/2120] Loss: 0.3911\n",
      "Epoch [26/100] Batch [1600/2120] Loss: 0.3774\n",
      "Epoch [26/100] Batch [1700/2120] Loss: 0.3917\n",
      "Epoch [26/100] Batch [1800/2120] Loss: 0.3783\n",
      "Epoch [26/100] Batch [1900/2120] Loss: 0.3910\n",
      "Epoch [26/100] Batch [2000/2120] Loss: 0.3738\n",
      "Epoch [26/100] Batch [2100/2120] Loss: 0.3812\n",
      "Epoch [27/100] Batch [100/2120] Loss: 0.3834\n",
      "Epoch [27/100] Batch [200/2120] Loss: 0.3727\n",
      "Epoch [27/100] Batch [300/2120] Loss: 0.3771\n",
      "Epoch [27/100] Batch [400/2120] Loss: 0.3766\n",
      "Epoch [27/100] Batch [500/2120] Loss: 0.3810\n",
      "Epoch [27/100] Batch [600/2120] Loss: 0.3893\n",
      "Epoch [27/100] Batch [700/2120] Loss: 0.3743\n",
      "Epoch [27/100] Batch [800/2120] Loss: 0.3817\n",
      "Epoch [27/100] Batch [900/2120] Loss: 0.3753\n",
      "Epoch [27/100] Batch [1000/2120] Loss: 0.3946\n",
      "Epoch [27/100] Batch [1100/2120] Loss: 0.3815\n",
      "Epoch [27/100] Batch [1200/2120] Loss: 0.3883\n",
      "Epoch [27/100] Batch [1300/2120] Loss: 0.3764\n",
      "Epoch [27/100] Batch [1400/2120] Loss: 0.3568\n",
      "Epoch [27/100] Batch [1500/2120] Loss: 0.3746\n",
      "Epoch [27/100] Batch [1600/2120] Loss: 0.3778\n",
      "Epoch [27/100] Batch [1700/2120] Loss: 0.3812\n",
      "Epoch [27/100] Batch [1800/2120] Loss: 0.3816\n",
      "Epoch [27/100] Batch [1900/2120] Loss: 0.3848\n",
      "Epoch [27/100] Batch [2000/2120] Loss: 0.3791\n",
      "Epoch [27/100] Batch [2100/2120] Loss: 0.3717\n",
      "Epoch [28/100] Batch [100/2120] Loss: 0.3810\n",
      "Epoch [28/100] Batch [200/2120] Loss: 0.4020\n",
      "Epoch [28/100] Batch [300/2120] Loss: 0.3784\n",
      "Epoch [28/100] Batch [400/2120] Loss: 0.3654\n",
      "Epoch [28/100] Batch [500/2120] Loss: 0.3810\n",
      "Epoch [28/100] Batch [600/2120] Loss: 0.3785\n",
      "Epoch [28/100] Batch [700/2120] Loss: 0.3981\n",
      "Epoch [28/100] Batch [800/2120] Loss: 0.3704\n",
      "Epoch [28/100] Batch [900/2120] Loss: 0.3831\n",
      "Epoch [28/100] Batch [1000/2120] Loss: 0.3771\n",
      "Epoch [28/100] Batch [1100/2120] Loss: 0.3674\n",
      "Epoch [28/100] Batch [1200/2120] Loss: 0.3855\n",
      "Epoch [28/100] Batch [1300/2120] Loss: 0.3835\n",
      "Epoch [28/100] Batch [1400/2120] Loss: 0.3747\n",
      "Epoch [28/100] Batch [1500/2120] Loss: 0.3786\n",
      "Epoch [28/100] Batch [1600/2120] Loss: 0.3680\n",
      "Epoch [28/100] Batch [1700/2120] Loss: 0.3708\n",
      "Epoch [28/100] Batch [1800/2120] Loss: 0.3879\n",
      "Epoch [28/100] Batch [1900/2120] Loss: 0.3760\n",
      "Epoch [28/100] Batch [2000/2120] Loss: 0.3662\n",
      "Epoch [28/100] Batch [2100/2120] Loss: 0.3697\n",
      "Epoch [29/100] Batch [100/2120] Loss: 0.3778\n",
      "Epoch [29/100] Batch [200/2120] Loss: 0.3710\n",
      "Epoch [29/100] Batch [300/2120] Loss: 0.3661\n",
      "Epoch [29/100] Batch [400/2120] Loss: 0.3527\n",
      "Epoch [29/100] Batch [500/2120] Loss: 0.3858\n",
      "Epoch [29/100] Batch [600/2120] Loss: 0.3734\n",
      "Epoch [29/100] Batch [700/2120] Loss: 0.3941\n",
      "Epoch [29/100] Batch [800/2120] Loss: 0.3861\n",
      "Epoch [29/100] Batch [900/2120] Loss: 0.3600\n",
      "Epoch [29/100] Batch [1000/2120] Loss: 0.3758\n",
      "Epoch [29/100] Batch [1100/2120] Loss: 0.3716\n",
      "Epoch [29/100] Batch [1200/2120] Loss: 0.3771\n",
      "Epoch [29/100] Batch [1300/2120] Loss: 0.3842\n",
      "Epoch [29/100] Batch [1400/2120] Loss: 0.3743\n",
      "Epoch [29/100] Batch [1500/2120] Loss: 0.3885\n",
      "Epoch [29/100] Batch [1600/2120] Loss: 0.3777\n",
      "Epoch [29/100] Batch [1700/2120] Loss: 0.3862\n",
      "Epoch [29/100] Batch [1800/2120] Loss: 0.3791\n",
      "Epoch [29/100] Batch [1900/2120] Loss: 0.3895\n",
      "Epoch [29/100] Batch [2000/2120] Loss: 0.3928\n",
      "Epoch [29/100] Batch [2100/2120] Loss: 0.3678\n",
      "Epoch [30/100] Batch [100/2120] Loss: 0.3709\n",
      "Epoch [30/100] Batch [200/2120] Loss: 0.3667\n",
      "Epoch [30/100] Batch [300/2120] Loss: 0.3603\n",
      "Epoch [30/100] Batch [400/2120] Loss: 0.3807\n",
      "Epoch [30/100] Batch [500/2120] Loss: 0.3795\n",
      "Epoch [30/100] Batch [600/2120] Loss: 0.3780\n",
      "Epoch [30/100] Batch [700/2120] Loss: 0.3794\n",
      "Epoch [30/100] Batch [800/2120] Loss: 0.3701\n",
      "Epoch [30/100] Batch [900/2120] Loss: 0.3717\n",
      "Epoch [30/100] Batch [1000/2120] Loss: 0.3762\n",
      "Epoch [30/100] Batch [1100/2120] Loss: 0.3753\n",
      "Epoch [30/100] Batch [1200/2120] Loss: 0.3920\n",
      "Epoch [30/100] Batch [1300/2120] Loss: 0.3730\n",
      "Epoch [30/100] Batch [1400/2120] Loss: 0.3779\n",
      "Epoch [30/100] Batch [1500/2120] Loss: 0.3722\n",
      "Epoch [30/100] Batch [1600/2120] Loss: 0.3801\n",
      "Epoch [30/100] Batch [1700/2120] Loss: 0.3878\n",
      "Epoch [30/100] Batch [1800/2120] Loss: 0.3782\n",
      "Epoch [30/100] Batch [1900/2120] Loss: 0.3915\n",
      "Epoch [30/100] Batch [2000/2120] Loss: 0.3764\n",
      "Epoch [30/100] Batch [2100/2120] Loss: 0.3732\n",
      "Epoch [31/100] Batch [100/2120] Loss: 0.3683\n",
      "Epoch [31/100] Batch [200/2120] Loss: 0.3924\n",
      "Epoch [31/100] Batch [300/2120] Loss: 0.3649\n",
      "Epoch [31/100] Batch [400/2120] Loss: 0.3605\n",
      "Epoch [31/100] Batch [500/2120] Loss: 0.3780\n",
      "Epoch [31/100] Batch [600/2120] Loss: 0.3670\n",
      "Epoch [31/100] Batch [700/2120] Loss: 0.3903\n",
      "Epoch [31/100] Batch [800/2120] Loss: 0.3669\n",
      "Epoch [31/100] Batch [900/2120] Loss: 0.3852\n",
      "Epoch [31/100] Batch [1000/2120] Loss: 0.3738\n",
      "Epoch [31/100] Batch [1100/2120] Loss: 0.3808\n",
      "Epoch [31/100] Batch [1200/2120] Loss: 0.3794\n",
      "Epoch [31/100] Batch [1300/2120] Loss: 0.3700\n",
      "Epoch [31/100] Batch [1400/2120] Loss: 0.3825\n",
      "Epoch [31/100] Batch [1500/2120] Loss: 0.3607\n",
      "Epoch [31/100] Batch [1600/2120] Loss: 0.3612\n",
      "Epoch [31/100] Batch [1700/2120] Loss: 0.3909\n",
      "Epoch [31/100] Batch [1800/2120] Loss: 0.3894\n",
      "Epoch [31/100] Batch [1900/2120] Loss: 0.3788\n",
      "Epoch [31/100] Batch [2000/2120] Loss: 0.3796\n",
      "Epoch [31/100] Batch [2100/2120] Loss: 0.3797\n",
      "Epoch [32/100] Batch [100/2120] Loss: 0.3690\n",
      "Epoch [32/100] Batch [200/2120] Loss: 0.3723\n",
      "Epoch [32/100] Batch [300/2120] Loss: 0.3639\n",
      "Epoch [32/100] Batch [400/2120] Loss: 0.3631\n",
      "Epoch [32/100] Batch [500/2120] Loss: 0.3765\n",
      "Epoch [32/100] Batch [600/2120] Loss: 0.3763\n",
      "Epoch [32/100] Batch [700/2120] Loss: 0.3898\n",
      "Epoch [32/100] Batch [800/2120] Loss: 0.3729\n",
      "Epoch [32/100] Batch [900/2120] Loss: 0.3696\n",
      "Epoch [32/100] Batch [1000/2120] Loss: 0.3782\n",
      "Epoch [32/100] Batch [1100/2120] Loss: 0.3791\n",
      "Epoch [32/100] Batch [1200/2120] Loss: 0.3669\n",
      "Epoch [32/100] Batch [1300/2120] Loss: 0.3794\n",
      "Epoch [32/100] Batch [1400/2120] Loss: 0.3587\n",
      "Epoch [32/100] Batch [1500/2120] Loss: 0.3947\n",
      "Epoch [32/100] Batch [1600/2120] Loss: 0.3798\n",
      "Epoch [32/100] Batch [1700/2120] Loss: 0.3636\n",
      "Epoch [32/100] Batch [1800/2120] Loss: 0.3891\n",
      "Epoch [32/100] Batch [1900/2120] Loss: 0.3880\n",
      "Epoch [32/100] Batch [2000/2120] Loss: 0.3842\n",
      "Epoch [32/100] Batch [2100/2120] Loss: 0.3718\n",
      "Epoch [33/100] Batch [100/2120] Loss: 0.3720\n",
      "Epoch [33/100] Batch [200/2120] Loss: 0.3622\n",
      "Epoch [33/100] Batch [300/2120] Loss: 0.3769\n",
      "Epoch [33/100] Batch [400/2120] Loss: 0.3535\n",
      "Epoch [33/100] Batch [500/2120] Loss: 0.3864\n",
      "Epoch [33/100] Batch [600/2120] Loss: 0.3872\n",
      "Epoch [33/100] Batch [700/2120] Loss: 0.3946\n",
      "Epoch [33/100] Batch [800/2120] Loss: 0.3628\n",
      "Epoch [33/100] Batch [900/2120] Loss: 0.3823\n",
      "Epoch [33/100] Batch [1000/2120] Loss: 0.3789\n",
      "Epoch [33/100] Batch [1100/2120] Loss: 0.3757\n",
      "Epoch [33/100] Batch [1200/2120] Loss: 0.3576\n",
      "Epoch [33/100] Batch [1300/2120] Loss: 0.3753\n",
      "Epoch [33/100] Batch [1400/2120] Loss: 0.3730\n",
      "Epoch [33/100] Batch [1500/2120] Loss: 0.3974\n",
      "Epoch [33/100] Batch [1600/2120] Loss: 0.3698\n",
      "Epoch [33/100] Batch [1700/2120] Loss: 0.3688\n",
      "Epoch [33/100] Batch [1800/2120] Loss: 0.3726\n",
      "Epoch [33/100] Batch [1900/2120] Loss: 0.3721\n",
      "Epoch [33/100] Batch [2000/2120] Loss: 0.3772\n",
      "Epoch [33/100] Batch [2100/2120] Loss: 0.3787\n",
      "Epoch [34/100] Batch [100/2120] Loss: 0.3788\n",
      "Epoch [34/100] Batch [200/2120] Loss: 0.3617\n",
      "Epoch [34/100] Batch [300/2120] Loss: 0.3733\n",
      "Epoch [34/100] Batch [400/2120] Loss: 0.3620\n",
      "Epoch [34/100] Batch [500/2120] Loss: 0.3839\n",
      "Epoch [34/100] Batch [600/2120] Loss: 0.3771\n",
      "Epoch [34/100] Batch [700/2120] Loss: 0.3899\n",
      "Epoch [34/100] Batch [800/2120] Loss: 0.3753\n",
      "Epoch [34/100] Batch [900/2120] Loss: 0.3780\n",
      "Epoch [34/100] Batch [1000/2120] Loss: 0.3701\n",
      "Epoch [34/100] Batch [1100/2120] Loss: 0.3575\n",
      "Epoch [34/100] Batch [1200/2120] Loss: 0.3676\n",
      "Epoch [34/100] Batch [1300/2120] Loss: 0.3748\n",
      "Epoch [34/100] Batch [1400/2120] Loss: 0.3698\n",
      "Epoch [34/100] Batch [1500/2120] Loss: 0.3680\n",
      "Epoch [34/100] Batch [1600/2120] Loss: 0.3978\n",
      "Epoch [34/100] Batch [1700/2120] Loss: 0.3653\n",
      "Epoch [34/100] Batch [1800/2120] Loss: 0.3890\n",
      "Epoch [34/100] Batch [1900/2120] Loss: 0.3673\n",
      "Epoch [34/100] Batch [2000/2120] Loss: 0.3703\n",
      "Epoch [34/100] Batch [2100/2120] Loss: 0.3857\n",
      "Epoch [35/100] Batch [100/2120] Loss: 0.3642\n",
      "Epoch [35/100] Batch [200/2120] Loss: 0.3853\n",
      "Epoch [35/100] Batch [300/2120] Loss: 0.3736\n",
      "Epoch [35/100] Batch [400/2120] Loss: 0.3610\n",
      "Epoch [35/100] Batch [500/2120] Loss: 0.3926\n",
      "Epoch [35/100] Batch [600/2120] Loss: 0.3721\n",
      "Epoch [35/100] Batch [700/2120] Loss: 0.3734\n",
      "Epoch [35/100] Batch [800/2120] Loss: 0.3679\n",
      "Epoch [35/100] Batch [900/2120] Loss: 0.3681\n",
      "Epoch [35/100] Batch [1000/2120] Loss: 0.3881\n",
      "Epoch [35/100] Batch [1100/2120] Loss: 0.3588\n",
      "Epoch [35/100] Batch [1200/2120] Loss: 0.3837\n",
      "Epoch [35/100] Batch [1300/2120] Loss: 0.3920\n",
      "Epoch [35/100] Batch [1400/2120] Loss: 0.3824\n",
      "Epoch [35/100] Batch [1500/2120] Loss: 0.3872\n",
      "Epoch [35/100] Batch [1600/2120] Loss: 0.3673\n",
      "Epoch [35/100] Batch [1700/2120] Loss: 0.3791\n",
      "Epoch [35/100] Batch [1800/2120] Loss: 0.3645\n",
      "Epoch [35/100] Batch [1900/2120] Loss: 0.3773\n",
      "Epoch [35/100] Batch [2000/2120] Loss: 0.3548\n",
      "Epoch [35/100] Batch [2100/2120] Loss: 0.3663\n",
      "Epoch [36/100] Batch [100/2120] Loss: 0.3770\n",
      "Epoch [36/100] Batch [200/2120] Loss: 0.3604\n",
      "Epoch [36/100] Batch [300/2120] Loss: 0.3605\n",
      "Epoch [36/100] Batch [400/2120] Loss: 0.3526\n",
      "Epoch [36/100] Batch [500/2120] Loss: 0.3845\n",
      "Epoch [36/100] Batch [600/2120] Loss: 0.3781\n",
      "Epoch [36/100] Batch [700/2120] Loss: 0.3773\n",
      "Epoch [36/100] Batch [800/2120] Loss: 0.3597\n",
      "Epoch [36/100] Batch [900/2120] Loss: 0.3715\n",
      "Epoch [36/100] Batch [1000/2120] Loss: 0.3697\n",
      "Epoch [36/100] Batch [1100/2120] Loss: 0.3841\n",
      "Epoch [36/100] Batch [1200/2120] Loss: 0.3513\n",
      "Epoch [36/100] Batch [1300/2120] Loss: 0.3910\n",
      "Epoch [36/100] Batch [1400/2120] Loss: 0.3837\n",
      "Epoch [36/100] Batch [1500/2120] Loss: 0.3756\n",
      "Epoch [36/100] Batch [1600/2120] Loss: 0.3707\n",
      "Epoch [36/100] Batch [1700/2120] Loss: 0.3714\n",
      "Epoch [36/100] Batch [1800/2120] Loss: 0.3868\n",
      "Epoch [36/100] Batch [1900/2120] Loss: 0.3705\n",
      "Epoch [36/100] Batch [2000/2120] Loss: 0.3779\n",
      "Epoch [36/100] Batch [2100/2120] Loss: 0.3875\n",
      "Epoch [37/100] Batch [100/2120] Loss: 0.3659\n",
      "Epoch [37/100] Batch [200/2120] Loss: 0.3751\n",
      "Epoch [37/100] Batch [300/2120] Loss: 0.3611\n",
      "Epoch [37/100] Batch [400/2120] Loss: 0.3724\n",
      "Epoch [37/100] Batch [500/2120] Loss: 0.3534\n",
      "Epoch [37/100] Batch [600/2120] Loss: 0.3760\n",
      "Epoch [37/100] Batch [700/2120] Loss: 0.3770\n",
      "Epoch [37/100] Batch [800/2120] Loss: 0.3729\n",
      "Epoch [37/100] Batch [900/2120] Loss: 0.3852\n",
      "Epoch [37/100] Batch [1000/2120] Loss: 0.3707\n",
      "Epoch [37/100] Batch [1100/2120] Loss: 0.3862\n",
      "Epoch [37/100] Batch [1200/2120] Loss: 0.3830\n",
      "Epoch [37/100] Batch [1300/2120] Loss: 0.3726\n",
      "Epoch [37/100] Batch [1400/2120] Loss: 0.3642\n",
      "Epoch [37/100] Batch [1500/2120] Loss: 0.3697\n",
      "Epoch [37/100] Batch [1600/2120] Loss: 0.3768\n",
      "Epoch [37/100] Batch [1700/2120] Loss: 0.3738\n",
      "Epoch [37/100] Batch [1800/2120] Loss: 0.3626\n",
      "Epoch [37/100] Batch [1900/2120] Loss: 0.3738\n",
      "Epoch [37/100] Batch [2000/2120] Loss: 0.3791\n",
      "Epoch [37/100] Batch [2100/2120] Loss: 0.3714\n",
      "Epoch [38/100] Batch [100/2120] Loss: 0.3652\n",
      "Epoch [38/100] Batch [200/2120] Loss: 0.3666\n",
      "Epoch [38/100] Batch [300/2120] Loss: 0.3588\n",
      "Epoch [38/100] Batch [400/2120] Loss: 0.3674\n",
      "Epoch [38/100] Batch [500/2120] Loss: 0.3706\n",
      "Epoch [38/100] Batch [600/2120] Loss: 0.3756\n",
      "Epoch [38/100] Batch [700/2120] Loss: 0.3719\n",
      "Epoch [38/100] Batch [800/2120] Loss: 0.3620\n",
      "Epoch [38/100] Batch [900/2120] Loss: 0.3628\n",
      "Epoch [38/100] Batch [1000/2120] Loss: 0.3785\n",
      "Epoch [38/100] Batch [1100/2120] Loss: 0.3688\n",
      "Epoch [38/100] Batch [1200/2120] Loss: 0.3802\n",
      "Epoch [38/100] Batch [1300/2120] Loss: 0.3821\n",
      "Epoch [38/100] Batch [1400/2120] Loss: 0.3843\n",
      "Epoch [38/100] Batch [1500/2120] Loss: 0.3731\n",
      "Epoch [38/100] Batch [1600/2120] Loss: 0.3784\n",
      "Epoch [38/100] Batch [1700/2120] Loss: 0.3661\n",
      "Epoch [38/100] Batch [1800/2120] Loss: 0.3680\n",
      "Epoch [38/100] Batch [1900/2120] Loss: 0.3862\n",
      "Epoch [38/100] Batch [2000/2120] Loss: 0.3726\n",
      "Epoch [38/100] Batch [2100/2120] Loss: 0.3833\n",
      "Epoch [39/100] Batch [100/2120] Loss: 0.3655\n",
      "Epoch [39/100] Batch [200/2120] Loss: 0.3584\n",
      "Epoch [39/100] Batch [300/2120] Loss: 0.3653\n",
      "Epoch [39/100] Batch [400/2120] Loss: 0.3625\n",
      "Epoch [39/100] Batch [500/2120] Loss: 0.3770\n",
      "Epoch [39/100] Batch [600/2120] Loss: 0.3626\n",
      "Epoch [39/100] Batch [700/2120] Loss: 0.3830\n",
      "Epoch [39/100] Batch [800/2120] Loss: 0.3762\n",
      "Epoch [39/100] Batch [900/2120] Loss: 0.3648\n",
      "Epoch [39/100] Batch [1000/2120] Loss: 0.3725\n",
      "Epoch [39/100] Batch [1100/2120] Loss: 0.3823\n",
      "Epoch [39/100] Batch [1200/2120] Loss: 0.3613\n",
      "Epoch [39/100] Batch [1300/2120] Loss: 0.3721\n",
      "Epoch [39/100] Batch [1400/2120] Loss: 0.3723\n",
      "Epoch [39/100] Batch [1500/2120] Loss: 0.3565\n",
      "Epoch [39/100] Batch [1600/2120] Loss: 0.3700\n",
      "Epoch [39/100] Batch [1700/2120] Loss: 0.3741\n",
      "Epoch [39/100] Batch [1800/2120] Loss: 0.3762\n",
      "Epoch [39/100] Batch [1900/2120] Loss: 0.3786\n",
      "Epoch [39/100] Batch [2000/2120] Loss: 0.3870\n",
      "Epoch [39/100] Batch [2100/2120] Loss: 0.3834\n",
      "Epoch [40/100] Batch [100/2120] Loss: 0.3747\n",
      "Epoch [40/100] Batch [200/2120] Loss: 0.3790\n",
      "Epoch [40/100] Batch [300/2120] Loss: 0.3642\n",
      "Epoch [40/100] Batch [400/2120] Loss: 0.3607\n",
      "Epoch [40/100] Batch [500/2120] Loss: 0.3786\n",
      "Epoch [40/100] Batch [600/2120] Loss: 0.3671\n",
      "Epoch [40/100] Batch [700/2120] Loss: 0.3679\n",
      "Epoch [40/100] Batch [800/2120] Loss: 0.3681\n",
      "Epoch [40/100] Batch [900/2120] Loss: 0.3802\n",
      "Epoch [40/100] Batch [1000/2120] Loss: 0.3604\n",
      "Epoch [40/100] Batch [1100/2120] Loss: 0.3744\n",
      "Epoch [40/100] Batch [1200/2120] Loss: 0.3829\n",
      "Epoch [40/100] Batch [1300/2120] Loss: 0.3630\n",
      "Epoch [40/100] Batch [1400/2120] Loss: 0.3730\n",
      "Epoch [40/100] Batch [1500/2120] Loss: 0.3773\n",
      "Epoch [40/100] Batch [1600/2120] Loss: 0.3638\n",
      "Epoch [40/100] Batch [1700/2120] Loss: 0.3611\n",
      "Epoch [40/100] Batch [1800/2120] Loss: 0.3673\n",
      "Epoch [40/100] Batch [1900/2120] Loss: 0.3803\n",
      "Epoch [40/100] Batch [2000/2120] Loss: 0.3739\n",
      "Epoch [40/100] Batch [2100/2120] Loss: 0.3703\n",
      "Epoch [41/100] Batch [100/2120] Loss: 0.3523\n",
      "Epoch [41/100] Batch [200/2120] Loss: 0.3683\n",
      "Epoch [41/100] Batch [300/2120] Loss: 0.3744\n",
      "Epoch [41/100] Batch [400/2120] Loss: 0.3592\n",
      "Epoch [41/100] Batch [500/2120] Loss: 0.3761\n",
      "Epoch [41/100] Batch [600/2120] Loss: 0.3545\n",
      "Epoch [41/100] Batch [700/2120] Loss: 0.3725\n",
      "Epoch [41/100] Batch [800/2120] Loss: 0.3728\n",
      "Epoch [41/100] Batch [900/2120] Loss: 0.3595\n",
      "Epoch [41/100] Batch [1000/2120] Loss: 0.3719\n",
      "Epoch [41/100] Batch [1100/2120] Loss: 0.3711\n",
      "Epoch [41/100] Batch [1200/2120] Loss: 0.3912\n",
      "Epoch [41/100] Batch [1300/2120] Loss: 0.3582\n",
      "Epoch [41/100] Batch [1400/2120] Loss: 0.3879\n",
      "Epoch [41/100] Batch [1500/2120] Loss: 0.3682\n",
      "Epoch [41/100] Batch [1600/2120] Loss: 0.3699\n",
      "Epoch [41/100] Batch [1700/2120] Loss: 0.3627\n",
      "Epoch [41/100] Batch [1800/2120] Loss: 0.3829\n",
      "Epoch [41/100] Batch [1900/2120] Loss: 0.3757\n",
      "Epoch [41/100] Batch [2000/2120] Loss: 0.3768\n",
      "Epoch [41/100] Batch [2100/2120] Loss: 0.3713\n",
      "Epoch [42/100] Batch [100/2120] Loss: 0.3577\n",
      "Epoch [42/100] Batch [200/2120] Loss: 0.3660\n",
      "Epoch [42/100] Batch [300/2120] Loss: 0.3746\n",
      "Epoch [42/100] Batch [400/2120] Loss: 0.3585\n",
      "Epoch [42/100] Batch [500/2120] Loss: 0.3993\n",
      "Epoch [42/100] Batch [600/2120] Loss: 0.3785\n",
      "Epoch [42/100] Batch [700/2120] Loss: 0.3553\n",
      "Epoch [42/100] Batch [800/2120] Loss: 0.3520\n",
      "Epoch [42/100] Batch [900/2120] Loss: 0.3809\n",
      "Epoch [42/100] Batch [1000/2120] Loss: 0.3523\n",
      "Epoch [42/100] Batch [1100/2120] Loss: 0.3768\n",
      "Epoch [42/100] Batch [1200/2120] Loss: 0.3686\n",
      "Epoch [42/100] Batch [1300/2120] Loss: 0.3823\n",
      "Epoch [42/100] Batch [1400/2120] Loss: 0.3756\n",
      "Epoch [42/100] Batch [1500/2120] Loss: 0.3920\n",
      "Epoch [42/100] Batch [1600/2120] Loss: 0.3590\n",
      "Epoch [42/100] Batch [1700/2120] Loss: 0.3655\n",
      "Epoch [42/100] Batch [1800/2120] Loss: 0.3691\n",
      "Epoch [42/100] Batch [1900/2120] Loss: 0.3650\n",
      "Epoch [42/100] Batch [2000/2120] Loss: 0.3605\n",
      "Epoch [42/100] Batch [2100/2120] Loss: 0.3757\n",
      "Epoch [43/100] Batch [100/2120] Loss: 0.3670\n",
      "Epoch [43/100] Batch [200/2120] Loss: 0.3498\n",
      "Epoch [43/100] Batch [300/2120] Loss: 0.3859\n",
      "Epoch [43/100] Batch [400/2120] Loss: 0.3752\n",
      "Epoch [43/100] Batch [500/2120] Loss: 0.3592\n",
      "Epoch [43/100] Batch [600/2120] Loss: 0.3739\n",
      "Epoch [43/100] Batch [700/2120] Loss: 0.3765\n",
      "Epoch [43/100] Batch [800/2120] Loss: 0.3805\n",
      "Epoch [43/100] Batch [900/2120] Loss: 0.3803\n",
      "Epoch [43/100] Batch [1000/2120] Loss: 0.3755\n",
      "Epoch [43/100] Batch [1100/2120] Loss: 0.3702\n",
      "Epoch [43/100] Batch [1200/2120] Loss: 0.3551\n",
      "Epoch [43/100] Batch [1300/2120] Loss: 0.3605\n",
      "Epoch [43/100] Batch [1400/2120] Loss: 0.3597\n",
      "Epoch [43/100] Batch [1500/2120] Loss: 0.3641\n",
      "Epoch [43/100] Batch [1600/2120] Loss: 0.3786\n",
      "Epoch [43/100] Batch [1700/2120] Loss: 0.3916\n",
      "Epoch [43/100] Batch [1800/2120] Loss: 0.3628\n",
      "Epoch [43/100] Batch [1900/2120] Loss: 0.3718\n",
      "Epoch [43/100] Batch [2000/2120] Loss: 0.3619\n",
      "Epoch [43/100] Batch [2100/2120] Loss: 0.3662\n",
      "Epoch [44/100] Batch [100/2120] Loss: 0.3593\n",
      "Epoch [44/100] Batch [200/2120] Loss: 0.3688\n",
      "Epoch [44/100] Batch [300/2120] Loss: 0.3668\n",
      "Epoch [44/100] Batch [400/2120] Loss: 0.3674\n",
      "Epoch [44/100] Batch [500/2120] Loss: 0.3647\n",
      "Epoch [44/100] Batch [600/2120] Loss: 0.3714\n",
      "Epoch [44/100] Batch [700/2120] Loss: 0.3746\n",
      "Epoch [44/100] Batch [800/2120] Loss: 0.3748\n",
      "Epoch [44/100] Batch [900/2120] Loss: 0.3594\n",
      "Epoch [44/100] Batch [1000/2120] Loss: 0.3506\n",
      "Epoch [44/100] Batch [1100/2120] Loss: 0.3676\n",
      "Epoch [44/100] Batch [1200/2120] Loss: 0.3709\n",
      "Epoch [44/100] Batch [1300/2120] Loss: 0.3682\n",
      "Epoch [44/100] Batch [1400/2120] Loss: 0.3597\n",
      "Epoch [44/100] Batch [1500/2120] Loss: 0.3872\n",
      "Epoch [44/100] Batch [1600/2120] Loss: 0.3782\n",
      "Epoch [44/100] Batch [1700/2120] Loss: 0.3733\n",
      "Epoch [44/100] Batch [1800/2120] Loss: 0.3655\n",
      "Epoch [44/100] Batch [1900/2120] Loss: 0.3762\n",
      "Epoch [44/100] Batch [2000/2120] Loss: 0.3837\n",
      "Epoch [44/100] Batch [2100/2120] Loss: 0.3753\n",
      "Epoch [45/100] Batch [100/2120] Loss: 0.3451\n",
      "Epoch [45/100] Batch [200/2120] Loss: 0.3694\n",
      "Epoch [45/100] Batch [300/2120] Loss: 0.3744\n",
      "Epoch [45/100] Batch [400/2120] Loss: 0.3670\n",
      "Epoch [45/100] Batch [500/2120] Loss: 0.3647\n",
      "Epoch [45/100] Batch [600/2120] Loss: 0.3659\n",
      "Epoch [45/100] Batch [700/2120] Loss: 0.3820\n",
      "Epoch [45/100] Batch [800/2120] Loss: 0.3921\n",
      "Epoch [45/100] Batch [900/2120] Loss: 0.3755\n",
      "Epoch [45/100] Batch [1000/2120] Loss: 0.3654\n",
      "Epoch [45/100] Batch [1100/2120] Loss: 0.3779\n",
      "Epoch [45/100] Batch [1200/2120] Loss: 0.3735\n",
      "Epoch [45/100] Batch [1300/2120] Loss: 0.3682\n",
      "Epoch [45/100] Batch [1400/2120] Loss: 0.3634\n",
      "Epoch [45/100] Batch [1500/2120] Loss: 0.3572\n",
      "Epoch [45/100] Batch [1600/2120] Loss: 0.3502\n",
      "Epoch [45/100] Batch [1700/2120] Loss: 0.3813\n",
      "Epoch [45/100] Batch [1800/2120] Loss: 0.3657\n",
      "Epoch [45/100] Batch [1900/2120] Loss: 0.3612\n",
      "Epoch [45/100] Batch [2000/2120] Loss: 0.3858\n",
      "Epoch [45/100] Batch [2100/2120] Loss: 0.3615\n",
      "Epoch [46/100] Batch [100/2120] Loss: 0.3456\n",
      "Epoch [46/100] Batch [200/2120] Loss: 0.3824\n",
      "Epoch [46/100] Batch [300/2120] Loss: 0.3769\n",
      "Epoch [46/100] Batch [400/2120] Loss: 0.3616\n",
      "Epoch [46/100] Batch [500/2120] Loss: 0.3726\n",
      "Epoch [46/100] Batch [600/2120] Loss: 0.3601\n",
      "Epoch [46/100] Batch [700/2120] Loss: 0.3685\n",
      "Epoch [46/100] Batch [800/2120] Loss: 0.3602\n",
      "Epoch [46/100] Batch [900/2120] Loss: 0.3637\n",
      "Epoch [46/100] Batch [1000/2120] Loss: 0.3720\n",
      "Epoch [46/100] Batch [1100/2120] Loss: 0.3651\n",
      "Epoch [46/100] Batch [1200/2120] Loss: 0.3726\n",
      "Epoch [46/100] Batch [1300/2120] Loss: 0.3730\n",
      "Epoch [46/100] Batch [1400/2120] Loss: 0.3706\n",
      "Epoch [46/100] Batch [1500/2120] Loss: 0.3624\n",
      "Epoch [46/100] Batch [1600/2120] Loss: 0.3749\n",
      "Epoch [46/100] Batch [1700/2120] Loss: 0.3745\n",
      "Epoch [46/100] Batch [1800/2120] Loss: 0.3648\n",
      "Epoch [46/100] Batch [1900/2120] Loss: 0.3684\n",
      "Epoch [46/100] Batch [2000/2120] Loss: 0.3604\n",
      "Epoch [46/100] Batch [2100/2120] Loss: 0.3812\n",
      "Epoch [47/100] Batch [100/2120] Loss: 0.3565\n",
      "Epoch [47/100] Batch [200/2120] Loss: 0.3434\n",
      "Epoch [47/100] Batch [300/2120] Loss: 0.3701\n",
      "Epoch [47/100] Batch [400/2120] Loss: 0.3576\n",
      "Epoch [47/100] Batch [500/2120] Loss: 0.3620\n",
      "Epoch [47/100] Batch [600/2120] Loss: 0.3758\n",
      "Epoch [47/100] Batch [700/2120] Loss: 0.3692\n",
      "Epoch [47/100] Batch [800/2120] Loss: 0.3485\n",
      "Epoch [47/100] Batch [900/2120] Loss: 0.3791\n",
      "Epoch [47/100] Batch [1000/2120] Loss: 0.3637\n",
      "Epoch [47/100] Batch [1100/2120] Loss: 0.3756\n",
      "Epoch [47/100] Batch [1200/2120] Loss: 0.3761\n",
      "Epoch [47/100] Batch [1300/2120] Loss: 0.3818\n",
      "Epoch [47/100] Batch [1400/2120] Loss: 0.3636\n",
      "Epoch [47/100] Batch [1500/2120] Loss: 0.3523\n",
      "Epoch [47/100] Batch [1600/2120] Loss: 0.3783\n",
      "Epoch [47/100] Batch [1700/2120] Loss: 0.3678\n",
      "Epoch [47/100] Batch [1800/2120] Loss: 0.3661\n",
      "Epoch [47/100] Batch [1900/2120] Loss: 0.3729\n",
      "Epoch [47/100] Batch [2000/2120] Loss: 0.3936\n",
      "Epoch [47/100] Batch [2100/2120] Loss: 0.3782\n",
      "Epoch [48/100] Batch [100/2120] Loss: 0.3677\n",
      "Epoch [48/100] Batch [200/2120] Loss: 0.3594\n",
      "Epoch [48/100] Batch [300/2120] Loss: 0.3659\n",
      "Epoch [48/100] Batch [400/2120] Loss: 0.3709\n",
      "Epoch [48/100] Batch [500/2120] Loss: 0.3789\n",
      "Epoch [48/100] Batch [600/2120] Loss: 0.3658\n",
      "Epoch [48/100] Batch [700/2120] Loss: 0.3638\n",
      "Epoch [48/100] Batch [800/2120] Loss: 0.3697\n",
      "Epoch [48/100] Batch [900/2120] Loss: 0.3458\n",
      "Epoch [48/100] Batch [1000/2120] Loss: 0.3615\n",
      "Epoch [48/100] Batch [1100/2120] Loss: 0.3660\n",
      "Epoch [48/100] Batch [1200/2120] Loss: 0.3744\n",
      "Epoch [48/100] Batch [1300/2120] Loss: 0.3794\n",
      "Epoch [48/100] Batch [1400/2120] Loss: 0.3534\n",
      "Epoch [48/100] Batch [1500/2120] Loss: 0.3692\n",
      "Epoch [48/100] Batch [1600/2120] Loss: 0.3757\n",
      "Epoch [48/100] Batch [1700/2120] Loss: 0.3785\n",
      "Epoch [48/100] Batch [1800/2120] Loss: 0.3713\n",
      "Epoch [48/100] Batch [1900/2120] Loss: 0.3700\n",
      "Epoch [48/100] Batch [2000/2120] Loss: 0.3720\n",
      "Epoch [48/100] Batch [2100/2120] Loss: 0.3619\n",
      "Epoch [49/100] Batch [100/2120] Loss: 0.3478\n",
      "Epoch [49/100] Batch [200/2120] Loss: 0.3625\n",
      "Epoch [49/100] Batch [300/2120] Loss: 0.3676\n",
      "Epoch [49/100] Batch [400/2120] Loss: 0.3716\n",
      "Epoch [49/100] Batch [500/2120] Loss: 0.3778\n",
      "Epoch [49/100] Batch [600/2120] Loss: 0.3607\n",
      "Epoch [49/100] Batch [700/2120] Loss: 0.3729\n",
      "Epoch [49/100] Batch [800/2120] Loss: 0.3558\n",
      "Epoch [49/100] Batch [900/2120] Loss: 0.3666\n",
      "Epoch [49/100] Batch [1000/2120] Loss: 0.3468\n",
      "Epoch [49/100] Batch [1100/2120] Loss: 0.3844\n",
      "Epoch [49/100] Batch [1200/2120] Loss: 0.3778\n",
      "Epoch [49/100] Batch [1300/2120] Loss: 0.3674\n",
      "Epoch [49/100] Batch [1400/2120] Loss: 0.3600\n",
      "Epoch [49/100] Batch [1500/2120] Loss: 0.3865\n",
      "Epoch [49/100] Batch [1600/2120] Loss: 0.3668\n",
      "Epoch [49/100] Batch [1700/2120] Loss: 0.3599\n",
      "Epoch [49/100] Batch [1800/2120] Loss: 0.3682\n",
      "Epoch [49/100] Batch [1900/2120] Loss: 0.3601\n",
      "Epoch [49/100] Batch [2000/2120] Loss: 0.3785\n",
      "Epoch [49/100] Batch [2100/2120] Loss: 0.3659\n",
      "Epoch [50/100] Batch [100/2120] Loss: 0.3617\n",
      "Epoch [50/100] Batch [200/2120] Loss: 0.3787\n",
      "Epoch [50/100] Batch [300/2120] Loss: 0.3602\n",
      "Epoch [50/100] Batch [400/2120] Loss: 0.3602\n",
      "Epoch [50/100] Batch [500/2120] Loss: 0.3629\n",
      "Epoch [50/100] Batch [600/2120] Loss: 0.3597\n",
      "Epoch [50/100] Batch [700/2120] Loss: 0.3649\n",
      "Epoch [50/100] Batch [800/2120] Loss: 0.3543\n",
      "Epoch [50/100] Batch [900/2120] Loss: 0.3666\n",
      "Epoch [50/100] Batch [1000/2120] Loss: 0.3671\n",
      "Epoch [50/100] Batch [1100/2120] Loss: 0.3657\n",
      "Epoch [50/100] Batch [1200/2120] Loss: 0.3787\n",
      "Epoch [50/100] Batch [1300/2120] Loss: 0.3879\n",
      "Epoch [50/100] Batch [1400/2120] Loss: 0.3766\n",
      "Epoch [50/100] Batch [1500/2120] Loss: 0.3721\n",
      "Epoch [50/100] Batch [1600/2120] Loss: 0.3768\n",
      "Epoch [50/100] Batch [1700/2120] Loss: 0.3649\n",
      "Epoch [50/100] Batch [1800/2120] Loss: 0.3637\n",
      "Epoch [50/100] Batch [1900/2120] Loss: 0.3769\n",
      "Epoch [50/100] Batch [2000/2120] Loss: 0.3536\n",
      "Epoch [50/100] Batch [2100/2120] Loss: 0.3644\n",
      "Epoch [51/100] Batch [100/2120] Loss: 0.3592\n",
      "Epoch [51/100] Batch [200/2120] Loss: 0.3565\n",
      "Epoch [51/100] Batch [300/2120] Loss: 0.3603\n",
      "Epoch [51/100] Batch [400/2120] Loss: 0.3551\n",
      "Epoch [51/100] Batch [500/2120] Loss: 0.3670\n",
      "Epoch [51/100] Batch [600/2120] Loss: 0.3719\n",
      "Epoch [51/100] Batch [700/2120] Loss: 0.3843\n",
      "Epoch [51/100] Batch [800/2120] Loss: 0.3765\n",
      "Epoch [51/100] Batch [900/2120] Loss: 0.3579\n",
      "Epoch [51/100] Batch [1000/2120] Loss: 0.3574\n",
      "Epoch [51/100] Batch [1100/2120] Loss: 0.3663\n",
      "Epoch [51/100] Batch [1200/2120] Loss: 0.3598\n",
      "Epoch [51/100] Batch [1300/2120] Loss: 0.3637\n",
      "Epoch [51/100] Batch [1400/2120] Loss: 0.3758\n",
      "Epoch [51/100] Batch [1500/2120] Loss: 0.3793\n",
      "Epoch [51/100] Batch [1600/2120] Loss: 0.3582\n",
      "Epoch [51/100] Batch [1700/2120] Loss: 0.3870\n",
      "Epoch [51/100] Batch [1800/2120] Loss: 0.3737\n",
      "Epoch [51/100] Batch [1900/2120] Loss: 0.3617\n",
      "Epoch [51/100] Batch [2000/2120] Loss: 0.3625\n",
      "Epoch [51/100] Batch [2100/2120] Loss: 0.3749\n",
      "Epoch [52/100] Batch [100/2120] Loss: 0.3515\n",
      "Epoch [52/100] Batch [200/2120] Loss: 0.3746\n",
      "Epoch [52/100] Batch [300/2120] Loss: 0.3586\n",
      "Epoch [52/100] Batch [400/2120] Loss: 0.3651\n",
      "Epoch [52/100] Batch [500/2120] Loss: 0.3600\n",
      "Epoch [52/100] Batch [600/2120] Loss: 0.3671\n",
      "Epoch [52/100] Batch [700/2120] Loss: 0.3588\n",
      "Epoch [52/100] Batch [800/2120] Loss: 0.3572\n",
      "Epoch [52/100] Batch [900/2120] Loss: 0.3728\n",
      "Epoch [52/100] Batch [1000/2120] Loss: 0.3710\n",
      "Epoch [52/100] Batch [1100/2120] Loss: 0.3688\n",
      "Epoch [52/100] Batch [1200/2120] Loss: 0.3802\n",
      "Epoch [52/100] Batch [1300/2120] Loss: 0.3694\n",
      "Epoch [52/100] Batch [1400/2120] Loss: 0.3618\n",
      "Epoch [52/100] Batch [1500/2120] Loss: 0.3736\n",
      "Epoch [52/100] Batch [1600/2120] Loss: 0.3555\n",
      "Epoch [52/100] Batch [1700/2120] Loss: 0.3672\n",
      "Epoch [52/100] Batch [1800/2120] Loss: 0.3734\n",
      "Epoch [52/100] Batch [1900/2120] Loss: 0.3647\n",
      "Epoch [52/100] Batch [2000/2120] Loss: 0.3664\n",
      "Epoch [52/100] Batch [2100/2120] Loss: 0.3780\n",
      "Epoch [53/100] Batch [100/2120] Loss: 0.3525\n",
      "Epoch [53/100] Batch [200/2120] Loss: 0.3714\n",
      "Epoch [53/100] Batch [300/2120] Loss: 0.3644\n",
      "Epoch [53/100] Batch [400/2120] Loss: 0.3583\n",
      "Epoch [53/100] Batch [500/2120] Loss: 0.3754\n",
      "Epoch [53/100] Batch [600/2120] Loss: 0.3568\n",
      "Epoch [53/100] Batch [700/2120] Loss: 0.3562\n",
      "Epoch [53/100] Batch [800/2120] Loss: 0.3719\n",
      "Epoch [53/100] Batch [900/2120] Loss: 0.3750\n",
      "Epoch [53/100] Batch [1000/2120] Loss: 0.3738\n",
      "Epoch [53/100] Batch [1100/2120] Loss: 0.3587\n",
      "Epoch [53/100] Batch [1200/2120] Loss: 0.3556\n",
      "Epoch [53/100] Batch [1300/2120] Loss: 0.3746\n",
      "Epoch [53/100] Batch [1400/2120] Loss: 0.3574\n",
      "Epoch [53/100] Batch [1500/2120] Loss: 0.3686\n",
      "Epoch [53/100] Batch [1600/2120] Loss: 0.3684\n",
      "Epoch [53/100] Batch [1700/2120] Loss: 0.3661\n",
      "Epoch [53/100] Batch [1800/2120] Loss: 0.3862\n",
      "Epoch [53/100] Batch [1900/2120] Loss: 0.3526\n",
      "Epoch [53/100] Batch [2000/2120] Loss: 0.3572\n",
      "Epoch [53/100] Batch [2100/2120] Loss: 0.3690\n",
      "Epoch [54/100] Batch [100/2120] Loss: 0.3519\n",
      "Epoch [54/100] Batch [200/2120] Loss: 0.3712\n",
      "Epoch [54/100] Batch [300/2120] Loss: 0.3559\n",
      "Epoch [54/100] Batch [400/2120] Loss: 0.3651\n",
      "Epoch [54/100] Batch [500/2120] Loss: 0.3629\n",
      "Epoch [54/100] Batch [600/2120] Loss: 0.3779\n",
      "Epoch [54/100] Batch [700/2120] Loss: 0.3605\n",
      "Epoch [54/100] Batch [800/2120] Loss: 0.3560\n",
      "Epoch [54/100] Batch [900/2120] Loss: 0.3680\n",
      "Epoch [54/100] Batch [1000/2120] Loss: 0.3460\n",
      "Epoch [54/100] Batch [1100/2120] Loss: 0.3647\n",
      "Epoch [54/100] Batch [1200/2120] Loss: 0.3719\n",
      "Epoch [54/100] Batch [1300/2120] Loss: 0.3607\n",
      "Epoch [54/100] Batch [1400/2120] Loss: 0.3884\n",
      "Epoch [54/100] Batch [1500/2120] Loss: 0.3744\n",
      "Epoch [54/100] Batch [1600/2120] Loss: 0.3770\n",
      "Epoch [54/100] Batch [1700/2120] Loss: 0.3578\n",
      "Epoch [54/100] Batch [1800/2120] Loss: 0.3763\n",
      "Epoch [54/100] Batch [1900/2120] Loss: 0.3721\n",
      "Epoch [54/100] Batch [2000/2120] Loss: 0.3585\n",
      "Epoch [54/100] Batch [2100/2120] Loss: 0.3546\n",
      "Epoch [55/100] Batch [100/2120] Loss: 0.3631\n",
      "Epoch [55/100] Batch [200/2120] Loss: 0.3524\n",
      "Epoch [55/100] Batch [300/2120] Loss: 0.3617\n",
      "Epoch [55/100] Batch [400/2120] Loss: 0.3553\n",
      "Epoch [55/100] Batch [500/2120] Loss: 0.3647\n",
      "Epoch [55/100] Batch [600/2120] Loss: 0.3638\n",
      "Epoch [55/100] Batch [700/2120] Loss: 0.3650\n",
      "Epoch [55/100] Batch [800/2120] Loss: 0.3750\n",
      "Epoch [55/100] Batch [900/2120] Loss: 0.3696\n",
      "Epoch [55/100] Batch [1000/2120] Loss: 0.3608\n",
      "Epoch [55/100] Batch [1100/2120] Loss: 0.3634\n",
      "Epoch [55/100] Batch [1200/2120] Loss: 0.3567\n",
      "Epoch [55/100] Batch [1300/2120] Loss: 0.3584\n",
      "Epoch [55/100] Batch [1400/2120] Loss: 0.3641\n",
      "Epoch [55/100] Batch [1500/2120] Loss: 0.3737\n",
      "Epoch [55/100] Batch [1600/2120] Loss: 0.3698\n",
      "Epoch [55/100] Batch [1700/2120] Loss: 0.3748\n",
      "Epoch [55/100] Batch [1800/2120] Loss: 0.3781\n",
      "Epoch [55/100] Batch [1900/2120] Loss: 0.3657\n",
      "Epoch [55/100] Batch [2000/2120] Loss: 0.3750\n",
      "Epoch [55/100] Batch [2100/2120] Loss: 0.3675\n",
      "Epoch [56/100] Batch [100/2120] Loss: 0.3555\n",
      "Epoch [56/100] Batch [200/2120] Loss: 0.3652\n",
      "Epoch [56/100] Batch [300/2120] Loss: 0.3562\n",
      "Epoch [56/100] Batch [400/2120] Loss: 0.3477\n",
      "Epoch [56/100] Batch [500/2120] Loss: 0.3811\n",
      "Epoch [56/100] Batch [600/2120] Loss: 0.3678\n",
      "Epoch [56/100] Batch [700/2120] Loss: 0.3784\n",
      "Epoch [56/100] Batch [800/2120] Loss: 0.3618\n",
      "Epoch [56/100] Batch [900/2120] Loss: 0.3610\n",
      "Epoch [56/100] Batch [1000/2120] Loss: 0.3625\n",
      "Epoch [56/100] Batch [1100/2120] Loss: 0.3576\n",
      "Epoch [56/100] Batch [1200/2120] Loss: 0.3687\n",
      "Epoch [56/100] Batch [1300/2120] Loss: 0.3613\n",
      "Epoch [56/100] Batch [1400/2120] Loss: 0.3706\n",
      "Epoch [56/100] Batch [1500/2120] Loss: 0.3621\n",
      "Epoch [56/100] Batch [1600/2120] Loss: 0.3518\n",
      "Epoch [56/100] Batch [1700/2120] Loss: 0.3696\n",
      "Epoch [56/100] Batch [1800/2120] Loss: 0.3706\n",
      "Epoch [56/100] Batch [1900/2120] Loss: 0.3814\n",
      "Epoch [56/100] Batch [2000/2120] Loss: 0.3610\n",
      "Epoch [56/100] Batch [2100/2120] Loss: 0.3641\n",
      "Epoch [57/100] Batch [100/2120] Loss: 0.3510\n",
      "Epoch [57/100] Batch [200/2120] Loss: 0.3634\n",
      "Epoch [57/100] Batch [300/2120] Loss: 0.3591\n",
      "Epoch [57/100] Batch [400/2120] Loss: 0.3687\n",
      "Epoch [57/100] Batch [500/2120] Loss: 0.3561\n",
      "Epoch [57/100] Batch [600/2120] Loss: 0.3653\n",
      "Epoch [57/100] Batch [700/2120] Loss: 0.3560\n",
      "Epoch [57/100] Batch [800/2120] Loss: 0.3576\n",
      "Epoch [57/100] Batch [900/2120] Loss: 0.3699\n",
      "Epoch [57/100] Batch [1000/2120] Loss: 0.3707\n",
      "Epoch [57/100] Batch [1100/2120] Loss: 0.3573\n",
      "Epoch [57/100] Batch [1200/2120] Loss: 0.3702\n",
      "Epoch [57/100] Batch [1300/2120] Loss: 0.3512\n",
      "Epoch [57/100] Batch [1400/2120] Loss: 0.3512\n",
      "Epoch [57/100] Batch [1500/2120] Loss: 0.3773\n",
      "Epoch [57/100] Batch [1600/2120] Loss: 0.3745\n",
      "Epoch [57/100] Batch [1700/2120] Loss: 0.3623\n",
      "Epoch [57/100] Batch [1800/2120] Loss: 0.3747\n",
      "Epoch [57/100] Batch [1900/2120] Loss: 0.3645\n",
      "Epoch [57/100] Batch [2000/2120] Loss: 0.3668\n",
      "Epoch [57/100] Batch [2100/2120] Loss: 0.3855\n",
      "Epoch [58/100] Batch [100/2120] Loss: 0.3680\n",
      "Epoch [58/100] Batch [200/2120] Loss: 0.3387\n",
      "Epoch [58/100] Batch [300/2120] Loss: 0.3606\n",
      "Epoch [58/100] Batch [400/2120] Loss: 0.3630\n",
      "Epoch [58/100] Batch [500/2120] Loss: 0.3689\n",
      "Epoch [58/100] Batch [600/2120] Loss: 0.3751\n",
      "Epoch [58/100] Batch [700/2120] Loss: 0.3549\n",
      "Epoch [58/100] Batch [800/2120] Loss: 0.3455\n",
      "Epoch [58/100] Batch [900/2120] Loss: 0.3622\n",
      "Epoch [58/100] Batch [1000/2120] Loss: 0.3567\n",
      "Epoch [58/100] Batch [1100/2120] Loss: 0.3808\n",
      "Epoch [58/100] Batch [1200/2120] Loss: 0.3663\n",
      "Epoch [58/100] Batch [1300/2120] Loss: 0.3876\n",
      "Epoch [58/100] Batch [1400/2120] Loss: 0.3643\n",
      "Epoch [58/100] Batch [1500/2120] Loss: 0.3651\n",
      "Epoch [58/100] Batch [1600/2120] Loss: 0.3578\n",
      "Epoch [58/100] Batch [1700/2120] Loss: 0.3525\n",
      "Epoch [58/100] Batch [1800/2120] Loss: 0.3763\n",
      "Epoch [58/100] Batch [1900/2120] Loss: 0.3762\n",
      "Epoch [58/100] Batch [2000/2120] Loss: 0.3790\n",
      "Epoch [58/100] Batch [2100/2120] Loss: 0.3532\n",
      "Epoch [59/100] Batch [100/2120] Loss: 0.3668\n",
      "Epoch [59/100] Batch [200/2120] Loss: 0.3506\n",
      "Epoch [59/100] Batch [300/2120] Loss: 0.3781\n",
      "Epoch [59/100] Batch [400/2120] Loss: 0.3608\n",
      "Epoch [59/100] Batch [500/2120] Loss: 0.3673\n",
      "Epoch [59/100] Batch [600/2120] Loss: 0.3705\n",
      "Epoch [59/100] Batch [700/2120] Loss: 0.3755\n",
      "Epoch [59/100] Batch [800/2120] Loss: 0.3601\n",
      "Epoch [59/100] Batch [900/2120] Loss: 0.3529\n",
      "Epoch [59/100] Batch [1000/2120] Loss: 0.3518\n",
      "Epoch [59/100] Batch [1100/2120] Loss: 0.3706\n",
      "Epoch [59/100] Batch [1200/2120] Loss: 0.3736\n",
      "Epoch [59/100] Batch [1300/2120] Loss: 0.3513\n",
      "Epoch [59/100] Batch [1400/2120] Loss: 0.3573\n",
      "Epoch [59/100] Batch [1500/2120] Loss: 0.3705\n",
      "Epoch [59/100] Batch [1600/2120] Loss: 0.3645\n",
      "Epoch [59/100] Batch [1700/2120] Loss: 0.3683\n",
      "Epoch [59/100] Batch [1800/2120] Loss: 0.3593\n",
      "Epoch [59/100] Batch [1900/2120] Loss: 0.3638\n",
      "Epoch [59/100] Batch [2000/2120] Loss: 0.3599\n",
      "Epoch [59/100] Batch [2100/2120] Loss: 0.3680\n",
      "Epoch [60/100] Batch [100/2120] Loss: 0.3392\n",
      "Epoch [60/100] Batch [200/2120] Loss: 0.3698\n",
      "Epoch [60/100] Batch [300/2120] Loss: 0.3667\n",
      "Epoch [60/100] Batch [400/2120] Loss: 0.3593\n",
      "Epoch [60/100] Batch [500/2120] Loss: 0.3350\n",
      "Epoch [60/100] Batch [600/2120] Loss: 0.3699\n",
      "Epoch [60/100] Batch [700/2120] Loss: 0.3542\n",
      "Epoch [60/100] Batch [800/2120] Loss: 0.3602\n",
      "Epoch [60/100] Batch [900/2120] Loss: 0.3568\n",
      "Epoch [60/100] Batch [1000/2120] Loss: 0.3633\n",
      "Epoch [60/100] Batch [1100/2120] Loss: 0.3668\n",
      "Epoch [60/100] Batch [1200/2120] Loss: 0.3660\n",
      "Epoch [60/100] Batch [1300/2120] Loss: 0.3705\n",
      "Epoch [60/100] Batch [1400/2120] Loss: 0.3550\n",
      "Epoch [60/100] Batch [1500/2120] Loss: 0.3560\n",
      "Epoch [60/100] Batch [1600/2120] Loss: 0.3689\n",
      "Epoch [60/100] Batch [1700/2120] Loss: 0.3735\n",
      "Epoch [60/100] Batch [1800/2120] Loss: 0.3792\n",
      "Epoch [60/100] Batch [1900/2120] Loss: 0.3754\n",
      "Epoch [60/100] Batch [2000/2120] Loss: 0.3619\n",
      "Epoch [60/100] Batch [2100/2120] Loss: 0.3812\n",
      "Epoch [61/100] Batch [100/2120] Loss: 0.3579\n",
      "Epoch [61/100] Batch [200/2120] Loss: 0.3457\n",
      "Epoch [61/100] Batch [300/2120] Loss: 0.3706\n",
      "Epoch [61/100] Batch [400/2120] Loss: 0.3566\n",
      "Epoch [61/100] Batch [500/2120] Loss: 0.3754\n",
      "Epoch [61/100] Batch [600/2120] Loss: 0.3781\n",
      "Epoch [61/100] Batch [700/2120] Loss: 0.3645\n",
      "Epoch [61/100] Batch [800/2120] Loss: 0.3562\n",
      "Epoch [61/100] Batch [900/2120] Loss: 0.3755\n",
      "Epoch [61/100] Batch [1000/2120] Loss: 0.3549\n",
      "Epoch [61/100] Batch [1100/2120] Loss: 0.3591\n",
      "Epoch [61/100] Batch [1200/2120] Loss: 0.3557\n",
      "Epoch [61/100] Batch [1300/2120] Loss: 0.3655\n",
      "Epoch [61/100] Batch [1400/2120] Loss: 0.3694\n",
      "Epoch [61/100] Batch [1500/2120] Loss: 0.3537\n",
      "Epoch [61/100] Batch [1600/2120] Loss: 0.3694\n",
      "Epoch [61/100] Batch [1700/2120] Loss: 0.3664\n",
      "Epoch [61/100] Batch [1800/2120] Loss: 0.3734\n",
      "Epoch [61/100] Batch [1900/2120] Loss: 0.3717\n",
      "Epoch [61/100] Batch [2000/2120] Loss: 0.3463\n",
      "Epoch [61/100] Batch [2100/2120] Loss: 0.3617\n",
      "Epoch [62/100] Batch [100/2120] Loss: 0.3883\n",
      "Epoch [62/100] Batch [200/2120] Loss: 0.3554\n",
      "Epoch [62/100] Batch [300/2120] Loss: 0.3590\n",
      "Epoch [62/100] Batch [400/2120] Loss: 0.3605\n",
      "Epoch [62/100] Batch [500/2120] Loss: 0.3484\n",
      "Epoch [62/100] Batch [600/2120] Loss: 0.3603\n",
      "Epoch [62/100] Batch [700/2120] Loss: 0.3852\n",
      "Epoch [62/100] Batch [800/2120] Loss: 0.3492\n",
      "Epoch [62/100] Batch [900/2120] Loss: 0.3574\n",
      "Epoch [62/100] Batch [1000/2120] Loss: 0.3615\n",
      "Epoch [62/100] Batch [1100/2120] Loss: 0.3714\n",
      "Epoch [62/100] Batch [1200/2120] Loss: 0.3689\n",
      "Epoch [62/100] Batch [1300/2120] Loss: 0.3731\n",
      "Epoch [62/100] Batch [1400/2120] Loss: 0.3614\n",
      "Epoch [62/100] Batch [1500/2120] Loss: 0.3555\n",
      "Epoch [62/100] Batch [1600/2120] Loss: 0.3534\n",
      "Epoch [62/100] Batch [1700/2120] Loss: 0.3623\n",
      "Epoch [62/100] Batch [1800/2120] Loss: 0.3498\n",
      "Epoch [62/100] Batch [1900/2120] Loss: 0.3760\n",
      "Epoch [62/100] Batch [2000/2120] Loss: 0.3749\n",
      "Epoch [62/100] Batch [2100/2120] Loss: 0.3735\n",
      "Epoch [63/100] Batch [100/2120] Loss: 0.3716\n",
      "Epoch [63/100] Batch [200/2120] Loss: 0.3622\n",
      "Epoch [63/100] Batch [300/2120] Loss: 0.3537\n",
      "Epoch [63/100] Batch [400/2120] Loss: 0.3719\n",
      "Epoch [63/100] Batch [500/2120] Loss: 0.3481\n",
      "Epoch [63/100] Batch [600/2120] Loss: 0.3664\n",
      "Epoch [63/100] Batch [700/2120] Loss: 0.3733\n",
      "Epoch [63/100] Batch [800/2120] Loss: 0.3617\n",
      "Epoch [63/100] Batch [900/2120] Loss: 0.3645\n",
      "Epoch [63/100] Batch [1000/2120] Loss: 0.3659\n",
      "Epoch [63/100] Batch [1100/2120] Loss: 0.3713\n",
      "Epoch [63/100] Batch [1200/2120] Loss: 0.3697\n",
      "Epoch [63/100] Batch [1300/2120] Loss: 0.3500\n",
      "Epoch [63/100] Batch [1400/2120] Loss: 0.3430\n",
      "Epoch [63/100] Batch [1500/2120] Loss: 0.3639\n",
      "Epoch [63/100] Batch [1600/2120] Loss: 0.3578\n",
      "Epoch [63/100] Batch [1700/2120] Loss: 0.3697\n",
      "Epoch [63/100] Batch [1800/2120] Loss: 0.3648\n",
      "Epoch [63/100] Batch [1900/2120] Loss: 0.3605\n",
      "Epoch [63/100] Batch [2000/2120] Loss: 0.3570\n",
      "Epoch [63/100] Batch [2100/2120] Loss: 0.3622\n",
      "Epoch [64/100] Batch [100/2120] Loss: 0.3655\n",
      "Epoch [64/100] Batch [200/2120] Loss: 0.3619\n",
      "Epoch [64/100] Batch [300/2120] Loss: 0.3664\n",
      "Epoch [64/100] Batch [400/2120] Loss: 0.3594\n",
      "Epoch [64/100] Batch [500/2120] Loss: 0.3639\n",
      "Epoch [64/100] Batch [600/2120] Loss: 0.3524\n",
      "Epoch [64/100] Batch [700/2120] Loss: 0.3570\n",
      "Epoch [64/100] Batch [800/2120] Loss: 0.3671\n",
      "Epoch [64/100] Batch [900/2120] Loss: 0.3641\n",
      "Epoch [64/100] Batch [1000/2120] Loss: 0.3698\n",
      "Epoch [64/100] Batch [1100/2120] Loss: 0.3630\n",
      "Epoch [64/100] Batch [1200/2120] Loss: 0.3626\n",
      "Epoch [64/100] Batch [1300/2120] Loss: 0.3807\n",
      "Epoch [64/100] Batch [1400/2120] Loss: 0.3676\n",
      "Epoch [64/100] Batch [1500/2120] Loss: 0.3658\n",
      "Epoch [64/100] Batch [1600/2120] Loss: 0.3635\n",
      "Epoch [64/100] Batch [1700/2120] Loss: 0.3637\n",
      "Epoch [64/100] Batch [1800/2120] Loss: 0.3428\n",
      "Epoch [64/100] Batch [1900/2120] Loss: 0.3634\n",
      "Epoch [64/100] Batch [2000/2120] Loss: 0.3589\n",
      "Epoch [64/100] Batch [2100/2120] Loss: 0.3605\n",
      "Epoch [65/100] Batch [100/2120] Loss: 0.3686\n",
      "Epoch [65/100] Batch [200/2120] Loss: 0.3614\n",
      "Epoch [65/100] Batch [300/2120] Loss: 0.3553\n",
      "Epoch [65/100] Batch [400/2120] Loss: 0.3730\n",
      "Epoch [65/100] Batch [500/2120] Loss: 0.3508\n",
      "Epoch [65/100] Batch [600/2120] Loss: 0.3673\n",
      "Epoch [65/100] Batch [700/2120] Loss: 0.3707\n",
      "Epoch [65/100] Batch [800/2120] Loss: 0.3789\n",
      "Epoch [65/100] Batch [900/2120] Loss: 0.3816\n",
      "Epoch [65/100] Batch [1000/2120] Loss: 0.3752\n",
      "Epoch [65/100] Batch [1100/2120] Loss: 0.3690\n",
      "Epoch [65/100] Batch [1200/2120] Loss: 0.3496\n",
      "Epoch [65/100] Batch [1300/2120] Loss: 0.3443\n",
      "Epoch [65/100] Batch [1400/2120] Loss: 0.3685\n",
      "Epoch [65/100] Batch [1500/2120] Loss: 0.3498\n",
      "Epoch [65/100] Batch [1600/2120] Loss: 0.3700\n",
      "Epoch [65/100] Batch [1700/2120] Loss: 0.3462\n",
      "Epoch [65/100] Batch [1800/2120] Loss: 0.3569\n",
      "Epoch [65/100] Batch [1900/2120] Loss: 0.3556\n",
      "Epoch [65/100] Batch [2000/2120] Loss: 0.3532\n",
      "Epoch [65/100] Batch [2100/2120] Loss: 0.3566\n",
      "Epoch [66/100] Batch [100/2120] Loss: 0.3662\n",
      "Epoch [66/100] Batch [200/2120] Loss: 0.3552\n",
      "Epoch [66/100] Batch [300/2120] Loss: 0.3576\n",
      "Epoch [66/100] Batch [400/2120] Loss: 0.3746\n",
      "Epoch [66/100] Batch [500/2120] Loss: 0.3580\n",
      "Epoch [66/100] Batch [600/2120] Loss: 0.3769\n",
      "Epoch [66/100] Batch [700/2120] Loss: 0.3552\n",
      "Epoch [66/100] Batch [800/2120] Loss: 0.3644\n",
      "Epoch [66/100] Batch [900/2120] Loss: 0.3670\n",
      "Epoch [66/100] Batch [1000/2120] Loss: 0.3506\n",
      "Epoch [66/100] Batch [1100/2120] Loss: 0.3592\n",
      "Epoch [66/100] Batch [1200/2120] Loss: 0.3768\n",
      "Epoch [66/100] Batch [1300/2120] Loss: 0.3558\n",
      "Epoch [66/100] Batch [1400/2120] Loss: 0.3729\n",
      "Epoch [66/100] Batch [1500/2120] Loss: 0.3504\n",
      "Epoch [66/100] Batch [1600/2120] Loss: 0.3649\n",
      "Epoch [66/100] Batch [1700/2120] Loss: 0.3659\n",
      "Epoch [66/100] Batch [1800/2120] Loss: 0.3576\n",
      "Epoch [66/100] Batch [1900/2120] Loss: 0.3543\n",
      "Epoch [66/100] Batch [2000/2120] Loss: 0.3544\n",
      "Epoch [66/100] Batch [2100/2120] Loss: 0.3636\n",
      "Epoch [67/100] Batch [100/2120] Loss: 0.3461\n",
      "Epoch [67/100] Batch [200/2120] Loss: 0.3608\n",
      "Epoch [67/100] Batch [300/2120] Loss: 0.3429\n",
      "Epoch [67/100] Batch [400/2120] Loss: 0.3637\n",
      "Epoch [67/100] Batch [500/2120] Loss: 0.3656\n",
      "Epoch [67/100] Batch [600/2120] Loss: 0.3653\n",
      "Epoch [67/100] Batch [700/2120] Loss: 0.3629\n",
      "Epoch [67/100] Batch [800/2120] Loss: 0.3681\n",
      "Epoch [67/100] Batch [900/2120] Loss: 0.3648\n",
      "Epoch [67/100] Batch [1000/2120] Loss: 0.3535\n",
      "Epoch [67/100] Batch [1100/2120] Loss: 0.3551\n",
      "Epoch [67/100] Batch [1200/2120] Loss: 0.3535\n",
      "Epoch [67/100] Batch [1300/2120] Loss: 0.3622\n",
      "Epoch [67/100] Batch [1400/2120] Loss: 0.3567\n",
      "Epoch [67/100] Batch [1500/2120] Loss: 0.3626\n",
      "Epoch [67/100] Batch [1600/2120] Loss: 0.3619\n",
      "Epoch [67/100] Batch [1700/2120] Loss: 0.3680\n",
      "Epoch [67/100] Batch [1800/2120] Loss: 0.3665\n",
      "Epoch [67/100] Batch [1900/2120] Loss: 0.3596\n",
      "Epoch [67/100] Batch [2000/2120] Loss: 0.3650\n",
      "Epoch [67/100] Batch [2100/2120] Loss: 0.3806\n",
      "Epoch [68/100] Batch [100/2120] Loss: 0.3450\n",
      "Epoch [68/100] Batch [200/2120] Loss: 0.3638\n",
      "Epoch [68/100] Batch [300/2120] Loss: 0.3573\n",
      "Epoch [68/100] Batch [400/2120] Loss: 0.3555\n",
      "Epoch [68/100] Batch [500/2120] Loss: 0.3665\n",
      "Epoch [68/100] Batch [600/2120] Loss: 0.3654\n",
      "Epoch [68/100] Batch [700/2120] Loss: 0.3685\n",
      "Epoch [68/100] Batch [800/2120] Loss: 0.3492\n",
      "Epoch [68/100] Batch [900/2120] Loss: 0.3515\n",
      "Epoch [68/100] Batch [1000/2120] Loss: 0.3798\n",
      "Epoch [68/100] Batch [1100/2120] Loss: 0.3664\n",
      "Epoch [68/100] Batch [1200/2120] Loss: 0.3754\n",
      "Epoch [68/100] Batch [1300/2120] Loss: 0.3585\n",
      "Epoch [68/100] Batch [1400/2120] Loss: 0.3559\n",
      "Epoch [68/100] Batch [1500/2120] Loss: 0.3621\n",
      "Epoch [68/100] Batch [1600/2120] Loss: 0.3535\n",
      "Epoch [68/100] Batch [1700/2120] Loss: 0.3710\n",
      "Epoch [68/100] Batch [1800/2120] Loss: 0.3635\n",
      "Epoch [68/100] Batch [1900/2120] Loss: 0.3635\n",
      "Epoch [68/100] Batch [2000/2120] Loss: 0.3583\n",
      "Epoch [68/100] Batch [2100/2120] Loss: 0.3681\n",
      "Epoch [69/100] Batch [100/2120] Loss: 0.3431\n",
      "Epoch [69/100] Batch [200/2120] Loss: 0.3538\n",
      "Epoch [69/100] Batch [300/2120] Loss: 0.3549\n",
      "Epoch [69/100] Batch [400/2120] Loss: 0.3553\n",
      "Epoch [69/100] Batch [500/2120] Loss: 0.3694\n",
      "Epoch [69/100] Batch [600/2120] Loss: 0.3642\n",
      "Epoch [69/100] Batch [700/2120] Loss: 0.3651\n",
      "Epoch [69/100] Batch [800/2120] Loss: 0.3849\n",
      "Epoch [69/100] Batch [900/2120] Loss: 0.3598\n",
      "Epoch [69/100] Batch [1000/2120] Loss: 0.3702\n",
      "Epoch [69/100] Batch [1100/2120] Loss: 0.3590\n",
      "Epoch [69/100] Batch [1200/2120] Loss: 0.3565\n",
      "Epoch [69/100] Batch [1300/2120] Loss: 0.3489\n",
      "Epoch [69/100] Batch [1400/2120] Loss: 0.3677\n",
      "Epoch [69/100] Batch [1500/2120] Loss: 0.3479\n",
      "Epoch [69/100] Batch [1600/2120] Loss: 0.3571\n",
      "Epoch [69/100] Batch [1700/2120] Loss: 0.3655\n",
      "Epoch [69/100] Batch [1800/2120] Loss: 0.3638\n",
      "Epoch [69/100] Batch [1900/2120] Loss: 0.3444\n",
      "Epoch [69/100] Batch [2000/2120] Loss: 0.3813\n",
      "Epoch [69/100] Batch [2100/2120] Loss: 0.3674\n",
      "Epoch [70/100] Batch [100/2120] Loss: 0.3515\n",
      "Epoch [70/100] Batch [200/2120] Loss: 0.3482\n",
      "Epoch [70/100] Batch [300/2120] Loss: 0.3490\n",
      "Epoch [70/100] Batch [400/2120] Loss: 0.3553\n",
      "Epoch [70/100] Batch [500/2120] Loss: 0.3489\n",
      "Epoch [70/100] Batch [600/2120] Loss: 0.3625\n",
      "Epoch [70/100] Batch [700/2120] Loss: 0.3706\n",
      "Epoch [70/100] Batch [800/2120] Loss: 0.3673\n",
      "Epoch [70/100] Batch [900/2120] Loss: 0.3448\n",
      "Epoch [70/100] Batch [1000/2120] Loss: 0.3577\n",
      "Epoch [70/100] Batch [1100/2120] Loss: 0.3514\n",
      "Epoch [70/100] Batch [1200/2120] Loss: 0.3535\n",
      "Epoch [70/100] Batch [1300/2120] Loss: 0.3649\n",
      "Epoch [70/100] Batch [1400/2120] Loss: 0.3489\n",
      "Epoch [70/100] Batch [1500/2120] Loss: 0.3615\n",
      "Epoch [70/100] Batch [1600/2120] Loss: 0.3666\n",
      "Epoch [70/100] Batch [1700/2120] Loss: 0.3784\n",
      "Epoch [70/100] Batch [1800/2120] Loss: 0.3683\n",
      "Epoch [70/100] Batch [1900/2120] Loss: 0.3694\n",
      "Epoch [70/100] Batch [2000/2120] Loss: 0.3740\n",
      "Epoch [70/100] Batch [2100/2120] Loss: 0.3894\n",
      "Epoch [71/100] Batch [100/2120] Loss: 0.3517\n",
      "Epoch [71/100] Batch [200/2120] Loss: 0.3379\n",
      "Epoch [71/100] Batch [300/2120] Loss: 0.3565\n",
      "Epoch [71/100] Batch [400/2120] Loss: 0.3759\n",
      "Epoch [71/100] Batch [500/2120] Loss: 0.3540\n",
      "Epoch [71/100] Batch [600/2120] Loss: 0.3638\n",
      "Epoch [71/100] Batch [700/2120] Loss: 0.3610\n",
      "Epoch [71/100] Batch [800/2120] Loss: 0.3690\n",
      "Epoch [71/100] Batch [900/2120] Loss: 0.3589\n",
      "Epoch [71/100] Batch [1000/2120] Loss: 0.3612\n",
      "Epoch [71/100] Batch [1100/2120] Loss: 0.3816\n",
      "Epoch [71/100] Batch [1200/2120] Loss: 0.3494\n",
      "Epoch [71/100] Batch [1300/2120] Loss: 0.3595\n",
      "Epoch [71/100] Batch [1400/2120] Loss: 0.3497\n",
      "Epoch [71/100] Batch [1500/2120] Loss: 0.3708\n",
      "Epoch [71/100] Batch [1600/2120] Loss: 0.3675\n",
      "Epoch [71/100] Batch [1700/2120] Loss: 0.3684\n",
      "Epoch [71/100] Batch [1800/2120] Loss: 0.3641\n",
      "Epoch [71/100] Batch [1900/2120] Loss: 0.3590\n",
      "Epoch [71/100] Batch [2000/2120] Loss: 0.3595\n",
      "Epoch [71/100] Batch [2100/2120] Loss: 0.3570\n",
      "Epoch [72/100] Batch [100/2120] Loss: 0.3523\n",
      "Epoch [72/100] Batch [200/2120] Loss: 0.3640\n",
      "Epoch [72/100] Batch [300/2120] Loss: 0.3445\n",
      "Epoch [72/100] Batch [400/2120] Loss: 0.3736\n",
      "Epoch [72/100] Batch [500/2120] Loss: 0.3585\n",
      "Epoch [72/100] Batch [600/2120] Loss: 0.3676\n",
      "Epoch [72/100] Batch [700/2120] Loss: 0.3636\n",
      "Epoch [72/100] Batch [800/2120] Loss: 0.3447\n",
      "Epoch [72/100] Batch [900/2120] Loss: 0.3610\n",
      "Epoch [72/100] Batch [1000/2120] Loss: 0.3648\n",
      "Epoch [72/100] Batch [1100/2120] Loss: 0.3690\n",
      "Epoch [72/100] Batch [1200/2120] Loss: 0.3540\n",
      "Epoch [72/100] Batch [1300/2120] Loss: 0.3445\n",
      "Epoch [72/100] Batch [1400/2120] Loss: 0.3544\n",
      "Epoch [72/100] Batch [1500/2120] Loss: 0.3731\n",
      "Epoch [72/100] Batch [1600/2120] Loss: 0.3661\n",
      "Epoch [72/100] Batch [1700/2120] Loss: 0.3728\n",
      "Epoch [72/100] Batch [1800/2120] Loss: 0.3459\n",
      "Epoch [72/100] Batch [1900/2120] Loss: 0.3709\n",
      "Epoch [72/100] Batch [2000/2120] Loss: 0.3709\n",
      "Epoch [72/100] Batch [2100/2120] Loss: 0.3611\n",
      "Epoch [73/100] Batch [100/2120] Loss: 0.3529\n",
      "Epoch [73/100] Batch [200/2120] Loss: 0.3484\n",
      "Epoch [73/100] Batch [300/2120] Loss: 0.3587\n",
      "Epoch [73/100] Batch [400/2120] Loss: 0.3506\n",
      "Epoch [73/100] Batch [500/2120] Loss: 0.3702\n",
      "Epoch [73/100] Batch [600/2120] Loss: 0.3696\n",
      "Epoch [73/100] Batch [700/2120] Loss: 0.3560\n",
      "Epoch [73/100] Batch [800/2120] Loss: 0.3754\n",
      "Epoch [73/100] Batch [900/2120] Loss: 0.3542\n",
      "Epoch [73/100] Batch [1000/2120] Loss: 0.3602\n",
      "Epoch [73/100] Batch [1100/2120] Loss: 0.3665\n",
      "Epoch [73/100] Batch [1200/2120] Loss: 0.3723\n",
      "Epoch [73/100] Batch [1300/2120] Loss: 0.3702\n",
      "Epoch [73/100] Batch [1400/2120] Loss: 0.3689\n",
      "Epoch [73/100] Batch [1500/2120] Loss: 0.3567\n",
      "Epoch [73/100] Batch [1600/2120] Loss: 0.3566\n",
      "Epoch [73/100] Batch [1700/2120] Loss: 0.3654\n",
      "Epoch [73/100] Batch [1800/2120] Loss: 0.3433\n",
      "Epoch [73/100] Batch [1900/2120] Loss: 0.3563\n",
      "Epoch [73/100] Batch [2000/2120] Loss: 0.3549\n",
      "Epoch [73/100] Batch [2100/2120] Loss: 0.3662\n",
      "Epoch [74/100] Batch [100/2120] Loss: 0.3569\n",
      "Epoch [74/100] Batch [200/2120] Loss: 0.3705\n",
      "Epoch [74/100] Batch [300/2120] Loss: 0.3475\n",
      "Epoch [74/100] Batch [400/2120] Loss: 0.3606\n",
      "Epoch [74/100] Batch [500/2120] Loss: 0.3531\n",
      "Epoch [74/100] Batch [600/2120] Loss: 0.3629\n",
      "Epoch [74/100] Batch [700/2120] Loss: 0.3575\n",
      "Epoch [74/100] Batch [800/2120] Loss: 0.3732\n",
      "Epoch [74/100] Batch [900/2120] Loss: 0.3494\n",
      "Epoch [74/100] Batch [1000/2120] Loss: 0.3525\n",
      "Epoch [74/100] Batch [1100/2120] Loss: 0.3522\n",
      "Epoch [74/100] Batch [1200/2120] Loss: 0.3574\n",
      "Epoch [74/100] Batch [1300/2120] Loss: 0.3676\n",
      "Epoch [74/100] Batch [1400/2120] Loss: 0.3629\n",
      "Epoch [74/100] Batch [1500/2120] Loss: 0.3610\n",
      "Epoch [74/100] Batch [1600/2120] Loss: 0.3581\n",
      "Epoch [74/100] Batch [1700/2120] Loss: 0.3668\n",
      "Epoch [74/100] Batch [1800/2120] Loss: 0.3666\n",
      "Epoch [74/100] Batch [1900/2120] Loss: 0.3501\n",
      "Epoch [74/100] Batch [2000/2120] Loss: 0.3781\n",
      "Epoch [74/100] Batch [2100/2120] Loss: 0.3669\n",
      "Epoch [75/100] Batch [100/2120] Loss: 0.3521\n",
      "Epoch [75/100] Batch [200/2120] Loss: 0.3711\n",
      "Epoch [75/100] Batch [300/2120] Loss: 0.3489\n",
      "Epoch [75/100] Batch [400/2120] Loss: 0.3497\n",
      "Epoch [75/100] Batch [500/2120] Loss: 0.3667\n",
      "Epoch [75/100] Batch [600/2120] Loss: 0.3513\n",
      "Epoch [75/100] Batch [700/2120] Loss: 0.3517\n",
      "Epoch [75/100] Batch [800/2120] Loss: 0.3532\n",
      "Epoch [75/100] Batch [900/2120] Loss: 0.3475\n",
      "Epoch [75/100] Batch [1000/2120] Loss: 0.3536\n",
      "Epoch [75/100] Batch [1100/2120] Loss: 0.3626\n",
      "Epoch [75/100] Batch [1200/2120] Loss: 0.3790\n",
      "Epoch [75/100] Batch [1300/2120] Loss: 0.3564\n",
      "Epoch [75/100] Batch [1400/2120] Loss: 0.3765\n",
      "Epoch [75/100] Batch [1500/2120] Loss: 0.3763\n",
      "Epoch [75/100] Batch [1600/2120] Loss: 0.3539\n",
      "Epoch [75/100] Batch [1700/2120] Loss: 0.3558\n",
      "Epoch [75/100] Batch [1800/2120] Loss: 0.3501\n",
      "Epoch [75/100] Batch [1900/2120] Loss: 0.3581\n",
      "Epoch [75/100] Batch [2000/2120] Loss: 0.3573\n",
      "Epoch [75/100] Batch [2100/2120] Loss: 0.3800\n",
      "Epoch [76/100] Batch [100/2120] Loss: 0.3526\n",
      "Epoch [76/100] Batch [200/2120] Loss: 0.3583\n",
      "Epoch [76/100] Batch [300/2120] Loss: 0.3504\n",
      "Epoch [76/100] Batch [400/2120] Loss: 0.3528\n",
      "Epoch [76/100] Batch [500/2120] Loss: 0.3726\n",
      "Epoch [76/100] Batch [600/2120] Loss: 0.3490\n",
      "Epoch [76/100] Batch [700/2120] Loss: 0.3622\n",
      "Epoch [76/100] Batch [800/2120] Loss: 0.3432\n",
      "Epoch [76/100] Batch [900/2120] Loss: 0.3668\n",
      "Epoch [76/100] Batch [1000/2120] Loss: 0.3527\n",
      "Epoch [76/100] Batch [1100/2120] Loss: 0.3692\n",
      "Epoch [76/100] Batch [1200/2120] Loss: 0.3560\n",
      "Epoch [76/100] Batch [1300/2120] Loss: 0.3590\n",
      "Epoch [76/100] Batch [1400/2120] Loss: 0.3633\n",
      "Epoch [76/100] Batch [1500/2120] Loss: 0.3786\n",
      "Epoch [76/100] Batch [1600/2120] Loss: 0.3696\n",
      "Epoch [76/100] Batch [1700/2120] Loss: 0.3570\n",
      "Epoch [76/100] Batch [1800/2120] Loss: 0.3442\n",
      "Epoch [76/100] Batch [1900/2120] Loss: 0.3564\n",
      "Epoch [76/100] Batch [2000/2120] Loss: 0.3646\n",
      "Epoch [76/100] Batch [2100/2120] Loss: 0.3635\n",
      "Epoch [77/100] Batch [100/2120] Loss: 0.3525\n",
      "Epoch [77/100] Batch [200/2120] Loss: 0.3406\n",
      "Epoch [77/100] Batch [300/2120] Loss: 0.3546\n",
      "Epoch [77/100] Batch [400/2120] Loss: 0.3558\n",
      "Epoch [77/100] Batch [500/2120] Loss: 0.3494\n",
      "Epoch [77/100] Batch [600/2120] Loss: 0.3595\n",
      "Epoch [77/100] Batch [700/2120] Loss: 0.3597\n",
      "Epoch [77/100] Batch [800/2120] Loss: 0.3639\n",
      "Epoch [77/100] Batch [900/2120] Loss: 0.3702\n",
      "Epoch [77/100] Batch [1000/2120] Loss: 0.3607\n",
      "Epoch [77/100] Batch [1100/2120] Loss: 0.3631\n",
      "Epoch [77/100] Batch [1200/2120] Loss: 0.3580\n",
      "Epoch [77/100] Batch [1300/2120] Loss: 0.3538\n",
      "Epoch [77/100] Batch [1400/2120] Loss: 0.3482\n",
      "Epoch [77/100] Batch [1500/2120] Loss: 0.3632\n",
      "Epoch [77/100] Batch [1600/2120] Loss: 0.3744\n",
      "Epoch [77/100] Batch [1700/2120] Loss: 0.3641\n",
      "Epoch [77/100] Batch [1800/2120] Loss: 0.3621\n",
      "Epoch [77/100] Batch [1900/2120] Loss: 0.3695\n",
      "Epoch [77/100] Batch [2000/2120] Loss: 0.3571\n",
      "Epoch [77/100] Batch [2100/2120] Loss: 0.3536\n",
      "Epoch [78/100] Batch [100/2120] Loss: 0.3641\n",
      "Epoch [78/100] Batch [200/2120] Loss: 0.3579\n",
      "Epoch [78/100] Batch [300/2120] Loss: 0.3578\n",
      "Epoch [78/100] Batch [400/2120] Loss: 0.3528\n",
      "Epoch [78/100] Batch [500/2120] Loss: 0.3464\n",
      "Epoch [78/100] Batch [600/2120] Loss: 0.3561\n",
      "Epoch [78/100] Batch [700/2120] Loss: 0.3483\n",
      "Epoch [78/100] Batch [800/2120] Loss: 0.3694\n",
      "Epoch [78/100] Batch [900/2120] Loss: 0.3638\n",
      "Epoch [78/100] Batch [1000/2120] Loss: 0.3589\n",
      "Epoch [78/100] Batch [1100/2120] Loss: 0.3566\n",
      "Epoch [78/100] Batch [1200/2120] Loss: 0.3429\n",
      "Epoch [78/100] Batch [1300/2120] Loss: 0.3661\n",
      "Epoch [78/100] Batch [1400/2120] Loss: 0.3624\n",
      "Epoch [78/100] Batch [1500/2120] Loss: 0.3591\n",
      "Epoch [78/100] Batch [1600/2120] Loss: 0.3749\n",
      "Epoch [78/100] Batch [1700/2120] Loss: 0.3621\n",
      "Epoch [78/100] Batch [1800/2120] Loss: 0.3530\n",
      "Epoch [78/100] Batch [1900/2120] Loss: 0.3775\n",
      "Epoch [78/100] Batch [2000/2120] Loss: 0.3674\n",
      "Epoch [78/100] Batch [2100/2120] Loss: 0.3533\n",
      "Epoch [79/100] Batch [100/2120] Loss: 0.3563\n",
      "Epoch [79/100] Batch [200/2120] Loss: 0.3530\n",
      "Epoch [79/100] Batch [300/2120] Loss: 0.3670\n",
      "Epoch [79/100] Batch [400/2120] Loss: 0.3672\n",
      "Epoch [79/100] Batch [500/2120] Loss: 0.3576\n",
      "Epoch [79/100] Batch [600/2120] Loss: 0.3481\n",
      "Epoch [79/100] Batch [700/2120] Loss: 0.3441\n",
      "Epoch [79/100] Batch [800/2120] Loss: 0.3452\n",
      "Epoch [79/100] Batch [900/2120] Loss: 0.3601\n",
      "Epoch [79/100] Batch [1000/2120] Loss: 0.3528\n",
      "Epoch [79/100] Batch [1100/2120] Loss: 0.3532\n",
      "Epoch [79/100] Batch [1200/2120] Loss: 0.3446\n",
      "Epoch [79/100] Batch [1300/2120] Loss: 0.3762\n",
      "Epoch [79/100] Batch [1400/2120] Loss: 0.3844\n",
      "Epoch [79/100] Batch [1500/2120] Loss: 0.3464\n",
      "Epoch [79/100] Batch [1600/2120] Loss: 0.3571\n",
      "Epoch [79/100] Batch [1700/2120] Loss: 0.3600\n",
      "Epoch [79/100] Batch [1800/2120] Loss: 0.3716\n",
      "Epoch [79/100] Batch [1900/2120] Loss: 0.3702\n",
      "Epoch [79/100] Batch [2000/2120] Loss: 0.3553\n",
      "Epoch [79/100] Batch [2100/2120] Loss: 0.3670\n",
      "Epoch [80/100] Batch [100/2120] Loss: 0.3736\n",
      "Epoch [80/100] Batch [200/2120] Loss: 0.3455\n",
      "Epoch [80/100] Batch [300/2120] Loss: 0.3605\n",
      "Epoch [80/100] Batch [400/2120] Loss: 0.3611\n",
      "Epoch [80/100] Batch [500/2120] Loss: 0.3567\n",
      "Epoch [80/100] Batch [600/2120] Loss: 0.3652\n",
      "Epoch [80/100] Batch [700/2120] Loss: 0.3699\n",
      "Epoch [80/100] Batch [800/2120] Loss: 0.3638\n",
      "Epoch [80/100] Batch [900/2120] Loss: 0.3396\n",
      "Epoch [80/100] Batch [1000/2120] Loss: 0.3653\n",
      "Epoch [80/100] Batch [1100/2120] Loss: 0.3470\n",
      "Epoch [80/100] Batch [1200/2120] Loss: 0.3609\n",
      "Epoch [80/100] Batch [1300/2120] Loss: 0.3494\n",
      "Epoch [80/100] Batch [1400/2120] Loss: 0.3722\n",
      "Epoch [80/100] Batch [1500/2120] Loss: 0.3714\n",
      "Epoch [80/100] Batch [1600/2120] Loss: 0.3474\n",
      "Epoch [80/100] Batch [1700/2120] Loss: 0.3510\n",
      "Epoch [80/100] Batch [1800/2120] Loss: 0.3490\n",
      "Epoch [80/100] Batch [1900/2120] Loss: 0.3567\n",
      "Epoch [80/100] Batch [2000/2120] Loss: 0.3558\n",
      "Epoch [80/100] Batch [2100/2120] Loss: 0.3616\n",
      "Epoch [81/100] Batch [100/2120] Loss: 0.3539\n",
      "Epoch [81/100] Batch [200/2120] Loss: 0.3591\n",
      "Epoch [81/100] Batch [300/2120] Loss: 0.3528\n",
      "Epoch [81/100] Batch [400/2120] Loss: 0.3710\n",
      "Epoch [81/100] Batch [500/2120] Loss: 0.3512\n",
      "Epoch [81/100] Batch [600/2120] Loss: 0.3643\n",
      "Epoch [81/100] Batch [700/2120] Loss: 0.3528\n",
      "Epoch [81/100] Batch [800/2120] Loss: 0.3692\n",
      "Epoch [81/100] Batch [900/2120] Loss: 0.3504\n",
      "Epoch [81/100] Batch [1000/2120] Loss: 0.3409\n",
      "Epoch [81/100] Batch [1100/2120] Loss: 0.3562\n",
      "Epoch [81/100] Batch [1200/2120] Loss: 0.3594\n",
      "Epoch [81/100] Batch [1300/2120] Loss: 0.3552\n",
      "Epoch [81/100] Batch [1400/2120] Loss: 0.3600\n",
      "Epoch [81/100] Batch [1500/2120] Loss: 0.3733\n",
      "Epoch [81/100] Batch [1600/2120] Loss: 0.3541\n",
      "Epoch [81/100] Batch [1700/2120] Loss: 0.3652\n",
      "Epoch [81/100] Batch [1800/2120] Loss: 0.3572\n",
      "Epoch [81/100] Batch [1900/2120] Loss: 0.3584\n",
      "Epoch [81/100] Batch [2000/2120] Loss: 0.3708\n",
      "Epoch [81/100] Batch [2100/2120] Loss: 0.3499\n",
      "Epoch [82/100] Batch [100/2120] Loss: 0.3527\n",
      "Epoch [82/100] Batch [200/2120] Loss: 0.3508\n",
      "Epoch [82/100] Batch [300/2120] Loss: 0.3542\n",
      "Epoch [82/100] Batch [400/2120] Loss: 0.3698\n",
      "Epoch [82/100] Batch [500/2120] Loss: 0.3516\n",
      "Epoch [82/100] Batch [600/2120] Loss: 0.3511\n",
      "Epoch [82/100] Batch [700/2120] Loss: 0.3470\n",
      "Epoch [82/100] Batch [800/2120] Loss: 0.3591\n",
      "Epoch [82/100] Batch [900/2120] Loss: 0.3576\n",
      "Epoch [82/100] Batch [1000/2120] Loss: 0.3604\n",
      "Epoch [82/100] Batch [1100/2120] Loss: 0.3499\n",
      "Epoch [82/100] Batch [1200/2120] Loss: 0.3685\n",
      "Epoch [82/100] Batch [1300/2120] Loss: 0.3676\n",
      "Epoch [82/100] Batch [1400/2120] Loss: 0.3612\n",
      "Epoch [82/100] Batch [1500/2120] Loss: 0.3584\n",
      "Epoch [82/100] Batch [1600/2120] Loss: 0.3627\n",
      "Epoch [82/100] Batch [1700/2120] Loss: 0.3573\n",
      "Epoch [82/100] Batch [1800/2120] Loss: 0.3741\n",
      "Epoch [82/100] Batch [1900/2120] Loss: 0.3604\n",
      "Epoch [82/100] Batch [2000/2120] Loss: 0.3787\n",
      "Epoch [82/100] Batch [2100/2120] Loss: 0.3334\n",
      "Epoch [83/100] Batch [100/2120] Loss: 0.3500\n",
      "Epoch [83/100] Batch [200/2120] Loss: 0.3689\n",
      "Epoch [83/100] Batch [300/2120] Loss: 0.3641\n",
      "Epoch [83/100] Batch [400/2120] Loss: 0.3360\n",
      "Epoch [83/100] Batch [500/2120] Loss: 0.3603\n",
      "Epoch [83/100] Batch [600/2120] Loss: 0.3642\n",
      "Epoch [83/100] Batch [700/2120] Loss: 0.3677\n",
      "Epoch [83/100] Batch [800/2120] Loss: 0.3656\n",
      "Epoch [83/100] Batch [900/2120] Loss: 0.3510\n",
      "Epoch [83/100] Batch [1000/2120] Loss: 0.3512\n",
      "Epoch [83/100] Batch [1100/2120] Loss: 0.3658\n",
      "Epoch [83/100] Batch [1200/2120] Loss: 0.3604\n",
      "Epoch [83/100] Batch [1300/2120] Loss: 0.3611\n",
      "Epoch [83/100] Batch [1400/2120] Loss: 0.3538\n",
      "Epoch [83/100] Batch [1500/2120] Loss: 0.3433\n",
      "Epoch [83/100] Batch [1600/2120] Loss: 0.3591\n",
      "Epoch [83/100] Batch [1700/2120] Loss: 0.3673\n",
      "Epoch [83/100] Batch [1800/2120] Loss: 0.3533\n",
      "Epoch [83/100] Batch [1900/2120] Loss: 0.3620\n",
      "Epoch [83/100] Batch [2000/2120] Loss: 0.3630\n",
      "Epoch [83/100] Batch [2100/2120] Loss: 0.3637\n",
      "Epoch [84/100] Batch [100/2120] Loss: 0.3591\n",
      "Epoch [84/100] Batch [200/2120] Loss: 0.3566\n",
      "Epoch [84/100] Batch [300/2120] Loss: 0.3567\n",
      "Epoch [84/100] Batch [400/2120] Loss: 0.3731\n",
      "Epoch [84/100] Batch [500/2120] Loss: 0.3501\n",
      "Epoch [84/100] Batch [600/2120] Loss: 0.3608\n",
      "Epoch [84/100] Batch [700/2120] Loss: 0.3455\n",
      "Epoch [84/100] Batch [800/2120] Loss: 0.3520\n",
      "Epoch [84/100] Batch [900/2120] Loss: 0.3531\n",
      "Epoch [84/100] Batch [1000/2120] Loss: 0.3624\n",
      "Epoch [84/100] Batch [1100/2120] Loss: 0.3481\n",
      "Epoch [84/100] Batch [1200/2120] Loss: 0.3519\n",
      "Epoch [84/100] Batch [1300/2120] Loss: 0.3578\n",
      "Epoch [84/100] Batch [1400/2120] Loss: 0.3557\n",
      "Epoch [84/100] Batch [1500/2120] Loss: 0.3723\n",
      "Epoch [84/100] Batch [1600/2120] Loss: 0.3553\n",
      "Epoch [84/100] Batch [1700/2120] Loss: 0.3623\n",
      "Epoch [84/100] Batch [1800/2120] Loss: 0.3523\n",
      "Epoch [84/100] Batch [1900/2120] Loss: 0.3547\n",
      "Epoch [84/100] Batch [2000/2120] Loss: 0.3724\n",
      "Epoch [84/100] Batch [2100/2120] Loss: 0.3572\n",
      "Epoch [85/100] Batch [100/2120] Loss: 0.3547\n",
      "Epoch [85/100] Batch [200/2120] Loss: 0.3521\n",
      "Epoch [85/100] Batch [300/2120] Loss: 0.3518\n",
      "Epoch [85/100] Batch [400/2120] Loss: 0.3328\n",
      "Epoch [85/100] Batch [500/2120] Loss: 0.3644\n",
      "Epoch [85/100] Batch [600/2120] Loss: 0.3515\n",
      "Epoch [85/100] Batch [700/2120] Loss: 0.3562\n",
      "Epoch [85/100] Batch [800/2120] Loss: 0.3512\n",
      "Epoch [85/100] Batch [900/2120] Loss: 0.3672\n",
      "Epoch [85/100] Batch [1000/2120] Loss: 0.3658\n",
      "Epoch [85/100] Batch [1100/2120] Loss: 0.3428\n",
      "Epoch [85/100] Batch [1200/2120] Loss: 0.3614\n",
      "Epoch [85/100] Batch [1300/2120] Loss: 0.3726\n",
      "Epoch [85/100] Batch [1400/2120] Loss: 0.3658\n",
      "Epoch [85/100] Batch [1500/2120] Loss: 0.3639\n",
      "Epoch [85/100] Batch [1600/2120] Loss: 0.3491\n",
      "Epoch [85/100] Batch [1700/2120] Loss: 0.3660\n",
      "Epoch [85/100] Batch [1800/2120] Loss: 0.3601\n",
      "Epoch [85/100] Batch [1900/2120] Loss: 0.3563\n",
      "Epoch [85/100] Batch [2000/2120] Loss: 0.3711\n",
      "Epoch [85/100] Batch [2100/2120] Loss: 0.3551\n",
      "Epoch [86/100] Batch [100/2120] Loss: 0.3503\n",
      "Epoch [86/100] Batch [200/2120] Loss: 0.3532\n",
      "Epoch [86/100] Batch [300/2120] Loss: 0.3592\n",
      "Epoch [86/100] Batch [400/2120] Loss: 0.3571\n",
      "Epoch [86/100] Batch [500/2120] Loss: 0.3685\n",
      "Epoch [86/100] Batch [600/2120] Loss: 0.3527\n",
      "Epoch [86/100] Batch [700/2120] Loss: 0.3621\n",
      "Epoch [86/100] Batch [800/2120] Loss: 0.3585\n",
      "Epoch [86/100] Batch [900/2120] Loss: 0.3502\n",
      "Epoch [86/100] Batch [1000/2120] Loss: 0.3335\n",
      "Epoch [86/100] Batch [1100/2120] Loss: 0.3495\n",
      "Epoch [86/100] Batch [1200/2120] Loss: 0.3625\n",
      "Epoch [86/100] Batch [1300/2120] Loss: 0.3587\n",
      "Epoch [86/100] Batch [1400/2120] Loss: 0.3636\n",
      "Epoch [86/100] Batch [1500/2120] Loss: 0.3725\n",
      "Epoch [86/100] Batch [1600/2120] Loss: 0.3618\n",
      "Epoch [86/100] Batch [1700/2120] Loss: 0.3729\n",
      "Epoch [86/100] Batch [1800/2120] Loss: 0.3487\n",
      "Epoch [86/100] Batch [1900/2120] Loss: 0.3627\n",
      "Epoch [86/100] Batch [2000/2120] Loss: 0.3586\n",
      "Epoch [86/100] Batch [2100/2120] Loss: 0.3630\n",
      "Epoch [87/100] Batch [100/2120] Loss: 0.3527\n",
      "Epoch [87/100] Batch [200/2120] Loss: 0.3532\n",
      "Epoch [87/100] Batch [300/2120] Loss: 0.3533\n",
      "Epoch [87/100] Batch [400/2120] Loss: 0.3652\n",
      "Epoch [87/100] Batch [500/2120] Loss: 0.3553\n",
      "Epoch [87/100] Batch [600/2120] Loss: 0.3611\n",
      "Epoch [87/100] Batch [700/2120] Loss: 0.3499\n",
      "Epoch [87/100] Batch [800/2120] Loss: 0.3523\n",
      "Epoch [87/100] Batch [900/2120] Loss: 0.3578\n",
      "Epoch [87/100] Batch [1000/2120] Loss: 0.3638\n",
      "Epoch [87/100] Batch [1100/2120] Loss: 0.3721\n",
      "Epoch [87/100] Batch [1200/2120] Loss: 0.3577\n",
      "Epoch [87/100] Batch [1300/2120] Loss: 0.3621\n",
      "Epoch [87/100] Batch [1400/2120] Loss: 0.3612\n",
      "Epoch [87/100] Batch [1500/2120] Loss: 0.3489\n",
      "Epoch [87/100] Batch [1600/2120] Loss: 0.3557\n",
      "Epoch [87/100] Batch [1700/2120] Loss: 0.3598\n",
      "Epoch [87/100] Batch [1800/2120] Loss: 0.3553\n",
      "Epoch [87/100] Batch [1900/2120] Loss: 0.3492\n",
      "Epoch [87/100] Batch [2000/2120] Loss: 0.3528\n",
      "Epoch [87/100] Batch [2100/2120] Loss: 0.3674\n",
      "Epoch [88/100] Batch [100/2120] Loss: 0.3453\n",
      "Epoch [88/100] Batch [200/2120] Loss: 0.3637\n",
      "Epoch [88/100] Batch [300/2120] Loss: 0.3411\n",
      "Epoch [88/100] Batch [400/2120] Loss: 0.3610\n",
      "Epoch [88/100] Batch [500/2120] Loss: 0.3530\n",
      "Epoch [88/100] Batch [600/2120] Loss: 0.3487\n",
      "Epoch [88/100] Batch [700/2120] Loss: 0.3447\n",
      "Epoch [88/100] Batch [800/2120] Loss: 0.3493\n",
      "Epoch [88/100] Batch [900/2120] Loss: 0.3778\n",
      "Epoch [88/100] Batch [1000/2120] Loss: 0.3684\n",
      "Epoch [88/100] Batch [1100/2120] Loss: 0.3601\n",
      "Epoch [88/100] Batch [1200/2120] Loss: 0.3567\n",
      "Epoch [88/100] Batch [1300/2120] Loss: 0.3482\n",
      "Epoch [88/100] Batch [1400/2120] Loss: 0.3657\n",
      "Epoch [88/100] Batch [1500/2120] Loss: 0.3553\n",
      "Epoch [88/100] Batch [1600/2120] Loss: 0.3642\n",
      "Epoch [88/100] Batch [1700/2120] Loss: 0.3540\n",
      "Epoch [88/100] Batch [1800/2120] Loss: 0.3543\n",
      "Epoch [88/100] Batch [1900/2120] Loss: 0.3614\n",
      "Epoch [88/100] Batch [2000/2120] Loss: 0.3714\n",
      "Epoch [88/100] Batch [2100/2120] Loss: 0.3610\n",
      "Epoch [89/100] Batch [100/2120] Loss: 0.3450\n",
      "Epoch [89/100] Batch [200/2120] Loss: 0.3549\n",
      "Epoch [89/100] Batch [300/2120] Loss: 0.3558\n",
      "Epoch [89/100] Batch [400/2120] Loss: 0.3498\n",
      "Epoch [89/100] Batch [500/2120] Loss: 0.3521\n",
      "Epoch [89/100] Batch [600/2120] Loss: 0.3675\n",
      "Epoch [89/100] Batch [700/2120] Loss: 0.3595\n",
      "Epoch [89/100] Batch [800/2120] Loss: 0.3639\n",
      "Epoch [89/100] Batch [900/2120] Loss: 0.3550\n",
      "Epoch [89/100] Batch [1000/2120] Loss: 0.3406\n",
      "Epoch [89/100] Batch [1100/2120] Loss: 0.3723\n",
      "Epoch [89/100] Batch [1200/2120] Loss: 0.3548\n",
      "Epoch [89/100] Batch [1300/2120] Loss: 0.3622\n",
      "Epoch [89/100] Batch [1400/2120] Loss: 0.3624\n",
      "Epoch [89/100] Batch [1500/2120] Loss: 0.3503\n",
      "Epoch [89/100] Batch [1600/2120] Loss: 0.3503\n",
      "Epoch [89/100] Batch [1700/2120] Loss: 0.3617\n",
      "Epoch [89/100] Batch [1800/2120] Loss: 0.3837\n",
      "Epoch [89/100] Batch [1900/2120] Loss: 0.3553\n",
      "Epoch [89/100] Batch [2000/2120] Loss: 0.3493\n",
      "Epoch [89/100] Batch [2100/2120] Loss: 0.3652\n",
      "Epoch [90/100] Batch [100/2120] Loss: 0.3401\n",
      "Epoch [90/100] Batch [200/2120] Loss: 0.3575\n",
      "Epoch [90/100] Batch [300/2120] Loss: 0.3743\n",
      "Epoch [90/100] Batch [400/2120] Loss: 0.3578\n",
      "Epoch [90/100] Batch [500/2120] Loss: 0.3591\n",
      "Epoch [90/100] Batch [600/2120] Loss: 0.3464\n",
      "Epoch [90/100] Batch [700/2120] Loss: 0.3475\n",
      "Epoch [90/100] Batch [800/2120] Loss: 0.3515\n",
      "Epoch [90/100] Batch [900/2120] Loss: 0.3608\n",
      "Epoch [90/100] Batch [1000/2120] Loss: 0.3551\n",
      "Epoch [90/100] Batch [1100/2120] Loss: 0.3556\n",
      "Epoch [90/100] Batch [1200/2120] Loss: 0.3562\n",
      "Epoch [90/100] Batch [1300/2120] Loss: 0.3518\n",
      "Epoch [90/100] Batch [1400/2120] Loss: 0.3611\n",
      "Epoch [90/100] Batch [1500/2120] Loss: 0.3525\n",
      "Epoch [90/100] Batch [1600/2120] Loss: 0.3786\n",
      "Epoch [90/100] Batch [1700/2120] Loss: 0.3527\n",
      "Epoch [90/100] Batch [1800/2120] Loss: 0.3591\n",
      "Epoch [90/100] Batch [1900/2120] Loss: 0.3549\n",
      "Epoch [90/100] Batch [2000/2120] Loss: 0.3605\n",
      "Epoch [90/100] Batch [2100/2120] Loss: 0.3616\n",
      "Epoch [91/100] Batch [100/2120] Loss: 0.3604\n",
      "Epoch [91/100] Batch [200/2120] Loss: 0.3447\n",
      "Epoch [91/100] Batch [300/2120] Loss: 0.3578\n",
      "Epoch [91/100] Batch [400/2120] Loss: 0.3531\n",
      "Epoch [91/100] Batch [500/2120] Loss: 0.3650\n",
      "Epoch [91/100] Batch [600/2120] Loss: 0.3692\n",
      "Epoch [91/100] Batch [700/2120] Loss: 0.3476\n",
      "Epoch [91/100] Batch [800/2120] Loss: 0.3462\n",
      "Epoch [91/100] Batch [900/2120] Loss: 0.3540\n",
      "Epoch [91/100] Batch [1000/2120] Loss: 0.3572\n",
      "Epoch [91/100] Batch [1100/2120] Loss: 0.3622\n",
      "Epoch [91/100] Batch [1200/2120] Loss: 0.3616\n",
      "Epoch [91/100] Batch [1300/2120] Loss: 0.3623\n",
      "Epoch [91/100] Batch [1400/2120] Loss: 0.3582\n",
      "Epoch [91/100] Batch [1500/2120] Loss: 0.3639\n",
      "Epoch [91/100] Batch [1600/2120] Loss: 0.3602\n",
      "Epoch [91/100] Batch [1700/2120] Loss: 0.3537\n",
      "Epoch [91/100] Batch [1800/2120] Loss: 0.3648\n",
      "Epoch [91/100] Batch [1900/2120] Loss: 0.3638\n",
      "Epoch [91/100] Batch [2000/2120] Loss: 0.3578\n",
      "Epoch [91/100] Batch [2100/2120] Loss: 0.3391\n",
      "Epoch [92/100] Batch [100/2120] Loss: 0.3530\n",
      "Epoch [92/100] Batch [200/2120] Loss: 0.3566\n",
      "Epoch [92/100] Batch [300/2120] Loss: 0.3528\n",
      "Epoch [92/100] Batch [400/2120] Loss: 0.3683\n",
      "Epoch [92/100] Batch [500/2120] Loss: 0.3481\n",
      "Epoch [92/100] Batch [600/2120] Loss: 0.3468\n",
      "Epoch [92/100] Batch [700/2120] Loss: 0.3670\n",
      "Epoch [92/100] Batch [800/2120] Loss: 0.3588\n",
      "Epoch [92/100] Batch [900/2120] Loss: 0.3484\n",
      "Epoch [92/100] Batch [1000/2120] Loss: 0.3500\n",
      "Epoch [92/100] Batch [1100/2120] Loss: 0.3573\n",
      "Epoch [92/100] Batch [1200/2120] Loss: 0.3492\n",
      "Epoch [92/100] Batch [1300/2120] Loss: 0.3556\n",
      "Epoch [92/100] Batch [1400/2120] Loss: 0.3550\n",
      "Epoch [92/100] Batch [1500/2120] Loss: 0.3629\n",
      "Epoch [92/100] Batch [1600/2120] Loss: 0.3669\n",
      "Epoch [92/100] Batch [1700/2120] Loss: 0.3514\n",
      "Epoch [92/100] Batch [1800/2120] Loss: 0.3528\n",
      "Epoch [92/100] Batch [1900/2120] Loss: 0.3784\n",
      "Epoch [92/100] Batch [2000/2120] Loss: 0.3578\n",
      "Epoch [92/100] Batch [2100/2120] Loss: 0.3495\n",
      "Epoch [93/100] Batch [100/2120] Loss: 0.3402\n",
      "Epoch [93/100] Batch [200/2120] Loss: 0.3736\n",
      "Epoch [93/100] Batch [300/2120] Loss: 0.3598\n",
      "Epoch [93/100] Batch [400/2120] Loss: 0.3429\n",
      "Epoch [93/100] Batch [500/2120] Loss: 0.3418\n",
      "Epoch [93/100] Batch [600/2120] Loss: 0.3495\n",
      "Epoch [93/100] Batch [700/2120] Loss: 0.3777\n",
      "Epoch [93/100] Batch [800/2120] Loss: 0.3527\n",
      "Epoch [93/100] Batch [900/2120] Loss: 0.3563\n",
      "Epoch [93/100] Batch [1000/2120] Loss: 0.3504\n",
      "Epoch [93/100] Batch [1100/2120] Loss: 0.3584\n",
      "Epoch [93/100] Batch [1200/2120] Loss: 0.3698\n",
      "Epoch [93/100] Batch [1300/2120] Loss: 0.3527\n",
      "Epoch [93/100] Batch [1400/2120] Loss: 0.3704\n",
      "Epoch [93/100] Batch [1500/2120] Loss: 0.3461\n",
      "Epoch [93/100] Batch [1600/2120] Loss: 0.3652\n",
      "Epoch [93/100] Batch [1700/2120] Loss: 0.3533\n",
      "Epoch [93/100] Batch [1800/2120] Loss: 0.3632\n",
      "Epoch [93/100] Batch [1900/2120] Loss: 0.3517\n",
      "Epoch [93/100] Batch [2000/2120] Loss: 0.3513\n",
      "Epoch [93/100] Batch [2100/2120] Loss: 0.3666\n",
      "Epoch [94/100] Batch [100/2120] Loss: 0.3553\n",
      "Epoch [94/100] Batch [200/2120] Loss: 0.3549\n",
      "Epoch [94/100] Batch [300/2120] Loss: 0.3541\n",
      "Epoch [94/100] Batch [400/2120] Loss: 0.3404\n",
      "Epoch [94/100] Batch [500/2120] Loss: 0.3534\n",
      "Epoch [94/100] Batch [600/2120] Loss: 0.3485\n",
      "Epoch [94/100] Batch [700/2120] Loss: 0.3424\n",
      "Epoch [94/100] Batch [800/2120] Loss: 0.3522\n",
      "Epoch [94/100] Batch [900/2120] Loss: 0.3580\n",
      "Epoch [94/100] Batch [1000/2120] Loss: 0.3529\n",
      "Epoch [94/100] Batch [1100/2120] Loss: 0.3676\n",
      "Epoch [94/100] Batch [1200/2120] Loss: 0.3532\n",
      "Epoch [94/100] Batch [1300/2120] Loss: 0.3530\n",
      "Epoch [94/100] Batch [1400/2120] Loss: 0.3517\n",
      "Epoch [94/100] Batch [1500/2120] Loss: 0.3813\n",
      "Epoch [94/100] Batch [1600/2120] Loss: 0.3564\n",
      "Epoch [94/100] Batch [1700/2120] Loss: 0.3366\n",
      "Epoch [94/100] Batch [1800/2120] Loss: 0.3750\n",
      "Epoch [94/100] Batch [1900/2120] Loss: 0.3679\n",
      "Epoch [94/100] Batch [2000/2120] Loss: 0.3663\n",
      "Epoch [94/100] Batch [2100/2120] Loss: 0.3519\n",
      "Epoch [95/100] Batch [100/2120] Loss: 0.3526\n",
      "Epoch [95/100] Batch [200/2120] Loss: 0.3475\n",
      "Epoch [95/100] Batch [300/2120] Loss: 0.3447\n",
      "Epoch [95/100] Batch [400/2120] Loss: 0.3483\n",
      "Epoch [95/100] Batch [500/2120] Loss: 0.3478\n",
      "Epoch [95/100] Batch [600/2120] Loss: 0.3524\n",
      "Epoch [95/100] Batch [700/2120] Loss: 0.3679\n",
      "Epoch [95/100] Batch [800/2120] Loss: 0.3604\n",
      "Epoch [95/100] Batch [900/2120] Loss: 0.3720\n",
      "Epoch [95/100] Batch [1000/2120] Loss: 0.3605\n",
      "Epoch [95/100] Batch [1100/2120] Loss: 0.3538\n",
      "Epoch [95/100] Batch [1200/2120] Loss: 0.3381\n",
      "Epoch [95/100] Batch [1300/2120] Loss: 0.3521\n",
      "Epoch [95/100] Batch [1400/2120] Loss: 0.3572\n",
      "Epoch [95/100] Batch [1500/2120] Loss: 0.3623\n",
      "Epoch [95/100] Batch [1600/2120] Loss: 0.3614\n",
      "Epoch [95/100] Batch [1700/2120] Loss: 0.3516\n",
      "Epoch [95/100] Batch [1800/2120] Loss: 0.3540\n",
      "Epoch [95/100] Batch [1900/2120] Loss: 0.3642\n",
      "Epoch [95/100] Batch [2000/2120] Loss: 0.3696\n",
      "Epoch [95/100] Batch [2100/2120] Loss: 0.3678\n",
      "Epoch [96/100] Batch [100/2120] Loss: 0.3483\n",
      "Epoch [96/100] Batch [200/2120] Loss: 0.3608\n",
      "Epoch [96/100] Batch [300/2120] Loss: 0.3633\n",
      "Epoch [96/100] Batch [400/2120] Loss: 0.3312\n",
      "Epoch [96/100] Batch [500/2120] Loss: 0.3644\n",
      "Epoch [96/100] Batch [600/2120] Loss: 0.3635\n",
      "Epoch [96/100] Batch [700/2120] Loss: 0.3617\n",
      "Epoch [96/100] Batch [800/2120] Loss: 0.3488\n",
      "Epoch [96/100] Batch [900/2120] Loss: 0.3351\n",
      "Epoch [96/100] Batch [1000/2120] Loss: 0.3537\n",
      "Epoch [96/100] Batch [1100/2120] Loss: 0.3523\n",
      "Epoch [96/100] Batch [1200/2120] Loss: 0.3707\n",
      "Epoch [96/100] Batch [1300/2120] Loss: 0.3521\n",
      "Epoch [96/100] Batch [1400/2120] Loss: 0.3553\n",
      "Epoch [96/100] Batch [1500/2120] Loss: 0.3539\n",
      "Epoch [96/100] Batch [1600/2120] Loss: 0.3433\n",
      "Epoch [96/100] Batch [1700/2120] Loss: 0.3598\n",
      "Epoch [96/100] Batch [1800/2120] Loss: 0.3680\n",
      "Epoch [96/100] Batch [1900/2120] Loss: 0.3648\n",
      "Epoch [96/100] Batch [2000/2120] Loss: 0.3564\n",
      "Epoch [96/100] Batch [2100/2120] Loss: 0.3603\n",
      "Epoch [97/100] Batch [100/2120] Loss: 0.3401\n",
      "Epoch [97/100] Batch [200/2120] Loss: 0.3650\n",
      "Epoch [97/100] Batch [300/2120] Loss: 0.3413\n",
      "Epoch [97/100] Batch [400/2120] Loss: 0.3535\n",
      "Epoch [97/100] Batch [500/2120] Loss: 0.3643\n",
      "Epoch [97/100] Batch [600/2120] Loss: 0.3627\n",
      "Epoch [97/100] Batch [700/2120] Loss: 0.3333\n",
      "Epoch [97/100] Batch [800/2120] Loss: 0.3516\n",
      "Epoch [97/100] Batch [900/2120] Loss: 0.3631\n",
      "Epoch [97/100] Batch [1000/2120] Loss: 0.3380\n",
      "Epoch [97/100] Batch [1100/2120] Loss: 0.3737\n",
      "Epoch [97/100] Batch [1200/2120] Loss: 0.3529\n",
      "Epoch [97/100] Batch [1300/2120] Loss: 0.3535\n",
      "Epoch [97/100] Batch [1400/2120] Loss: 0.3596\n",
      "Epoch [97/100] Batch [1500/2120] Loss: 0.3570\n",
      "Epoch [97/100] Batch [1600/2120] Loss: 0.3573\n",
      "Epoch [97/100] Batch [1700/2120] Loss: 0.3676\n",
      "Epoch [97/100] Batch [1800/2120] Loss: 0.3623\n",
      "Epoch [97/100] Batch [1900/2120] Loss: 0.3621\n",
      "Epoch [97/100] Batch [2000/2120] Loss: 0.3472\n",
      "Epoch [97/100] Batch [2100/2120] Loss: 0.3516\n",
      "Epoch [98/100] Batch [100/2120] Loss: 0.3531\n",
      "Epoch [98/100] Batch [200/2120] Loss: 0.3370\n",
      "Epoch [98/100] Batch [300/2120] Loss: 0.3503\n",
      "Epoch [98/100] Batch [400/2120] Loss: 0.3590\n",
      "Epoch [98/100] Batch [500/2120] Loss: 0.3500\n",
      "Epoch [98/100] Batch [600/2120] Loss: 0.3667\n",
      "Epoch [98/100] Batch [700/2120] Loss: 0.3606\n",
      "Epoch [98/100] Batch [800/2120] Loss: 0.3511\n",
      "Epoch [98/100] Batch [900/2120] Loss: 0.3561\n",
      "Epoch [98/100] Batch [1000/2120] Loss: 0.3497\n",
      "Epoch [98/100] Batch [1100/2120] Loss: 0.3651\n",
      "Epoch [98/100] Batch [1200/2120] Loss: 0.3560\n",
      "Epoch [98/100] Batch [1300/2120] Loss: 0.3584\n",
      "Epoch [98/100] Batch [1400/2120] Loss: 0.3485\n",
      "Epoch [98/100] Batch [1500/2120] Loss: 0.3674\n",
      "Epoch [98/100] Batch [1600/2120] Loss: 0.3541\n",
      "Epoch [98/100] Batch [1700/2120] Loss: 0.3572\n",
      "Epoch [98/100] Batch [1800/2120] Loss: 0.3497\n",
      "Epoch [98/100] Batch [1900/2120] Loss: 0.3470\n",
      "Epoch [98/100] Batch [2000/2120] Loss: 0.3592\n",
      "Epoch [98/100] Batch [2100/2120] Loss: 0.3706\n",
      "Epoch [99/100] Batch [100/2120] Loss: 0.3476\n",
      "Epoch [99/100] Batch [200/2120] Loss: 0.3460\n",
      "Epoch [99/100] Batch [300/2120] Loss: 0.3618\n",
      "Epoch [99/100] Batch [400/2120] Loss: 0.3456\n",
      "Epoch [99/100] Batch [500/2120] Loss: 0.3632\n",
      "Epoch [99/100] Batch [600/2120] Loss: 0.3481\n",
      "Epoch [99/100] Batch [700/2120] Loss: 0.3455\n",
      "Epoch [99/100] Batch [800/2120] Loss: 0.3482\n",
      "Epoch [99/100] Batch [900/2120] Loss: 0.3420\n",
      "Epoch [99/100] Batch [1000/2120] Loss: 0.3651\n",
      "Epoch [99/100] Batch [1100/2120] Loss: 0.3571\n",
      "Epoch [99/100] Batch [1200/2120] Loss: 0.3588\n",
      "Epoch [99/100] Batch [1300/2120] Loss: 0.3634\n",
      "Epoch [99/100] Batch [1400/2120] Loss: 0.3515\n",
      "Epoch [99/100] Batch [1500/2120] Loss: 0.3578\n",
      "Epoch [99/100] Batch [1600/2120] Loss: 0.3603\n",
      "Epoch [99/100] Batch [1700/2120] Loss: 0.3629\n",
      "Epoch [99/100] Batch [1800/2120] Loss: 0.3580\n",
      "Epoch [99/100] Batch [1900/2120] Loss: 0.3600\n",
      "Epoch [99/100] Batch [2000/2120] Loss: 0.3560\n",
      "Epoch [99/100] Batch [2100/2120] Loss: 0.3632\n",
      "Epoch [100/100] Batch [100/2120] Loss: 0.3553\n",
      "Epoch [100/100] Batch [200/2120] Loss: 0.3594\n",
      "Epoch [100/100] Batch [300/2120] Loss: 0.3670\n",
      "Epoch [100/100] Batch [400/2120] Loss: 0.3401\n",
      "Epoch [100/100] Batch [500/2120] Loss: 0.3482\n",
      "Epoch [100/100] Batch [600/2120] Loss: 0.3572\n",
      "Epoch [100/100] Batch [700/2120] Loss: 0.3483\n",
      "Epoch [100/100] Batch [800/2120] Loss: 0.3606\n",
      "Epoch [100/100] Batch [900/2120] Loss: 0.3556\n",
      "Epoch [100/100] Batch [1000/2120] Loss: 0.3601\n",
      "Epoch [100/100] Batch [1100/2120] Loss: 0.3552\n",
      "Epoch [100/100] Batch [1200/2120] Loss: 0.3464\n",
      "Epoch [100/100] Batch [1300/2120] Loss: 0.3586\n",
      "Epoch [100/100] Batch [1400/2120] Loss: 0.3551\n",
      "Epoch [100/100] Batch [1500/2120] Loss: 0.3623\n",
      "Epoch [100/100] Batch [1600/2120] Loss: 0.3604\n",
      "Epoch [100/100] Batch [1700/2120] Loss: 0.3659\n",
      "Epoch [100/100] Batch [1800/2120] Loss: 0.3463\n",
      "Epoch [100/100] Batch [1900/2120] Loss: 0.3568\n",
      "Epoch [100/100] Batch [2000/2120] Loss: 0.3486\n",
      "Epoch [100/100] Batch [2100/2120] Loss: 0.3529\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "print_freq = 100\n",
    "\n",
    "saved_loss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0  \n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % print_freq == 0:\n",
    "            saved_loss.append((epoch, batch_idx, running_loss/print_freq))\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}] Batch [{batch_idx+1}/{len(train_loader)}] Loss: {running_loss / print_freq:.4f}\")\n",
    "            running_loss = 0.0  \n",
    "\n",
    "save(\"saved_loss\", \"saved_loss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './select-game-classification/model/classifier.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167/2378170592.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return torch.tensor([self.X.iloc[idx]], device=device), torch.tensor(self.y.iloc[idx], device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 83.71%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SelectGameNN(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# TODO: Evaluate for seperate classes\n",
    "\n",
    "model.train() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Output:  Farbwenz Schelle\n"
     ]
    }
   ],
   "source": [
    "# Define input\n",
    "X = torch.tensor(train_data[2:3].values, device=device)\n",
    "# Execute\n",
    "out = model(X)\n",
    "# Map output\n",
    "output_code = torch.max(out, 1).indices[0].item()\n",
    "category_mapping = output_data.astype(\"category\").cat.categories\n",
    "print(\"Example Output: \",category_mapping[output_code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
