{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player1</th>\n",
       "      <th>Player2</th>\n",
       "      <th>Player3</th>\n",
       "      <th>Player4</th>\n",
       "      <th>Eichel Ober</th>\n",
       "      <th>Eichel Unter</th>\n",
       "      <th>Eichel Ass</th>\n",
       "      <th>Eichel 10</th>\n",
       "      <th>Eichel König</th>\n",
       "      <th>Eichel 9</th>\n",
       "      <th>...</th>\n",
       "      <th>SchellenOber</th>\n",
       "      <th>SchellenUnter</th>\n",
       "      <th>SchellenAss</th>\n",
       "      <th>Schellen10</th>\n",
       "      <th>SchellenKönig</th>\n",
       "      <th>Schellen9</th>\n",
       "      <th>Schellen8</th>\n",
       "      <th>Schellen7</th>\n",
       "      <th>Modus</th>\n",
       "      <th>Win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>weiter</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>weiter</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Farbwenz Schelle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Farbgeier Schelle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>weiter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Player1  Player2  Player3  Player4  Eichel Ober  Eichel Unter  Eichel Ass  \\\n",
       "0        1        0        0        0            1             0           1   \n",
       "1        0        1        0        0            0             0           0   \n",
       "2        0        0        0        1            0             1           0   \n",
       "3        0        0        0        1            1             0           0   \n",
       "4        1        0        0        0            0             0           0   \n",
       "\n",
       "   Eichel 10  Eichel König  Eichel 9  ...  SchellenOber  SchellenUnter  \\\n",
       "0          0             1         0  ...             0              0   \n",
       "1          0             0         1  ...             0              0   \n",
       "2          0             0         0  ...             1              1   \n",
       "3          0             0         0  ...             1              1   \n",
       "4          0             1         0  ...             1              0   \n",
       "\n",
       "   SchellenAss  Schellen10  SchellenKönig  Schellen9  Schellen8  Schellen7  \\\n",
       "0            0           0              1          1          0          0   \n",
       "1            0           1              0          0          0          0   \n",
       "2            0           0              0          0          0          1   \n",
       "3            0           0              0          0          0          1   \n",
       "4            0           0              0          0          1          1   \n",
       "\n",
       "               Modus  Win  \n",
       "0             weiter   -1  \n",
       "1             weiter   -1  \n",
       "2   Farbwenz Schelle    1  \n",
       "3  Farbgeier Schelle    1  \n",
       "4             weiter    1  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv', sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sauspiel Alte            0.172273\n",
       "Sauspiel Hundsgfickte    0.166309\n",
       "Sauspiel Blaue           0.163832\n",
       "Geier                    0.051654\n",
       "Farbwenz Gras            0.037755\n",
       "Farbgeier Gras           0.037755\n",
       "Farbwenz Herz            0.037603\n",
       "Farbgeier Herz           0.037603\n",
       "Farbwenz Schelle         0.037073\n",
       "Farbgeier Schelle        0.037073\n",
       "Farbgeier Eichel         0.036239\n",
       "Farbwenz Eichel          0.036239\n",
       "Wenz                     0.036011\n",
       "Solo Gras                0.029163\n",
       "Solo Herz                0.029112\n",
       "Solo Schelle             0.027545\n",
       "Solo Eichel              0.026762\n",
       "Name: Modus, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df[df['Modus'] != 'weiter']\n",
    "game_modes = df_filtered['Modus'].unique()\n",
    "df_filtered['Modus'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eichel Ober</th>\n",
       "      <th>Eichel Unter</th>\n",
       "      <th>Eichel Ass</th>\n",
       "      <th>Eichel 10</th>\n",
       "      <th>Eichel König</th>\n",
       "      <th>Eichel 9</th>\n",
       "      <th>Eichel 8</th>\n",
       "      <th>Eichel 7</th>\n",
       "      <th>Gras Ober</th>\n",
       "      <th>Gras Unter</th>\n",
       "      <th>...</th>\n",
       "      <th>Herz 8</th>\n",
       "      <th>Herz 7</th>\n",
       "      <th>SchellenOber</th>\n",
       "      <th>SchellenUnter</th>\n",
       "      <th>SchellenAss</th>\n",
       "      <th>Schellen10</th>\n",
       "      <th>SchellenKönig</th>\n",
       "      <th>Schellen9</th>\n",
       "      <th>Schellen8</th>\n",
       "      <th>Schellen7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Eichel Ober  Eichel Unter  Eichel Ass  Eichel 10  Eichel König  Eichel 9  \\\n",
       "2          0.0           1.0         0.0        0.0           0.0       0.0   \n",
       "3          1.0           0.0         0.0        0.0           0.0       0.0   \n",
       "7          1.0           1.0         1.0        0.0           0.0       0.0   \n",
       "8          1.0           1.0         1.0        0.0           0.0       0.0   \n",
       "9          0.0           0.0         1.0        0.0           0.0       0.0   \n",
       "\n",
       "   Eichel 8  Eichel 7  Gras Ober  Gras Unter  ...  Herz 8  Herz 7  \\\n",
       "2       1.0       0.0        0.0         1.0  ...     0.0     0.0   \n",
       "3       1.0       0.0        1.0         0.0  ...     0.0     0.0   \n",
       "7       0.0       0.0        0.0         0.0  ...     0.0     0.0   \n",
       "8       0.0       0.0        0.0         0.0  ...     0.0     0.0   \n",
       "9       0.0       0.0        1.0         1.0  ...     0.0     0.0   \n",
       "\n",
       "   SchellenOber  SchellenUnter  SchellenAss  Schellen10  SchellenKönig  \\\n",
       "2           1.0            1.0          0.0         0.0            0.0   \n",
       "3           1.0            1.0          0.0         0.0            0.0   \n",
       "7           0.0            0.0          0.0         0.0            1.0   \n",
       "8           0.0            0.0          0.0         0.0            1.0   \n",
       "9           0.0            0.0          0.0         1.0            0.0   \n",
       "\n",
       "   Schellen9  Schellen8  Schellen7  \n",
       "2        0.0        0.0        1.0  \n",
       "3        0.0        0.0        1.0  \n",
       "7        0.0        0.0        0.0  \n",
       "8        0.0        0.0        0.0  \n",
       "9        0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = df_filtered.drop(['Player1','Player2','Player3','Player4','Win','Modus'], axis=1).astype(\"float32\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Size:  32\n"
     ]
    }
   ],
   "source": [
    "train_data_size = np.shape(np.array(train_data))\n",
    "input_size = train_data_size[1]\n",
    "print(\"Input Size: \", input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Size:  17\n"
     ]
    }
   ],
   "source": [
    "output_data = df_filtered['Modus']\n",
    "output_data_codes = output_data.astype(\"category\").cat.codes\n",
    "output_size = max(output_data_codes) + 1\n",
    "y = output_data_codes.astype(\"long\")\n",
    "print(\"Output Size: \", output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103571    11\n",
       "114923     8\n",
       "127855     5\n",
       "51701     11\n",
       "88413     10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_data, y, test_size=0.2, random_state=42)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectGameDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor([self.X.iloc[idx]], device=device), torch.tensor(self.y.iloc[idx], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SelectGameDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SelectGameDataset(X_val, y_val)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectGameNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectGameNN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=17, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SelectGameNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300] Batch [250/495] Loss: 2.1356\n",
      "Epoch [2/300] Batch [250/495] Loss: 1.1544\n",
      "Epoch [3/300] Batch [250/495] Loss: 0.9880\n",
      "Epoch [4/300] Batch [250/495] Loss: 0.8728\n",
      "Epoch [5/300] Batch [250/495] Loss: 0.8332\n",
      "Epoch [6/300] Batch [250/495] Loss: 0.8015\n",
      "Epoch [7/300] Batch [250/495] Loss: 0.7824\n",
      "Epoch [8/300] Batch [250/495] Loss: 0.7697\n",
      "Epoch [9/300] Batch [250/495] Loss: 0.7608\n",
      "Epoch [10/300] Batch [250/495] Loss: 0.7539\n",
      "Epoch [11/300] Batch [250/495] Loss: 0.7367\n",
      "Epoch [12/300] Batch [250/495] Loss: 0.7299\n",
      "Epoch [13/300] Batch [250/495] Loss: 0.7280\n",
      "Epoch [14/300] Batch [250/495] Loss: 0.7182\n",
      "Epoch [15/300] Batch [250/495] Loss: 0.7095\n",
      "Epoch [16/300] Batch [250/495] Loss: 0.6949\n",
      "Epoch [17/300] Batch [250/495] Loss: 0.6888\n",
      "Epoch [18/300] Batch [250/495] Loss: 0.6866\n",
      "Epoch [19/300] Batch [250/495] Loss: 0.6893\n",
      "Epoch [20/300] Batch [250/495] Loss: 0.6840\n",
      "Epoch [21/300] Batch [250/495] Loss: 0.6799\n",
      "Epoch [22/300] Batch [250/495] Loss: 0.6816\n",
      "Epoch [23/300] Batch [250/495] Loss: 0.6767\n",
      "Epoch [24/300] Batch [250/495] Loss: 0.6648\n",
      "Epoch [25/300] Batch [250/495] Loss: 0.6763\n",
      "Epoch [26/300] Batch [250/495] Loss: 0.6608\n",
      "Epoch [27/300] Batch [250/495] Loss: 0.6613\n",
      "Epoch [28/300] Batch [250/495] Loss: 0.6612\n",
      "Epoch [29/300] Batch [250/495] Loss: 0.6542\n",
      "Epoch [30/300] Batch [250/495] Loss: 0.6464\n",
      "Epoch [31/300] Batch [250/495] Loss: 0.6511\n",
      "Epoch [32/300] Batch [250/495] Loss: 0.6500\n",
      "Epoch [33/300] Batch [250/495] Loss: 0.6502\n",
      "Epoch [34/300] Batch [250/495] Loss: 0.6487\n",
      "Epoch [35/300] Batch [250/495] Loss: 0.6357\n",
      "Epoch [36/300] Batch [250/495] Loss: 0.6470\n",
      "Epoch [37/300] Batch [250/495] Loss: 0.6391\n",
      "Epoch [38/300] Batch [250/495] Loss: 0.6321\n",
      "Epoch [39/300] Batch [250/495] Loss: 0.6397\n",
      "Epoch [40/300] Batch [250/495] Loss: 0.6305\n",
      "Epoch [41/300] Batch [250/495] Loss: 0.6317\n",
      "Epoch [42/300] Batch [250/495] Loss: 0.6256\n",
      "Epoch [43/300] Batch [250/495] Loss: 0.6225\n",
      "Epoch [44/300] Batch [250/495] Loss: 0.6251\n",
      "Epoch [45/300] Batch [250/495] Loss: 0.6236\n",
      "Epoch [46/300] Batch [250/495] Loss: 0.6138\n",
      "Epoch [47/300] Batch [250/495] Loss: 0.6161\n",
      "Epoch [48/300] Batch [250/495] Loss: 0.6123\n",
      "Epoch [49/300] Batch [250/495] Loss: 0.6175\n",
      "Epoch [50/300] Batch [250/495] Loss: 0.6166\n",
      "Epoch [51/300] Batch [250/495] Loss: 0.6105\n",
      "Epoch [52/300] Batch [250/495] Loss: 0.6067\n",
      "Epoch [53/300] Batch [250/495] Loss: 0.6172\n",
      "Epoch [54/300] Batch [250/495] Loss: 0.6077\n",
      "Epoch [55/300] Batch [250/495] Loss: 0.6000\n",
      "Epoch [56/300] Batch [250/495] Loss: 0.6108\n",
      "Epoch [57/300] Batch [250/495] Loss: 0.6031\n",
      "Epoch [58/300] Batch [250/495] Loss: 0.6008\n",
      "Epoch [59/300] Batch [250/495] Loss: 0.6095\n",
      "Epoch [60/300] Batch [250/495] Loss: 0.5974\n",
      "Epoch [61/300] Batch [250/495] Loss: 0.5973\n",
      "Epoch [62/300] Batch [250/495] Loss: 0.6042\n",
      "Epoch [63/300] Batch [250/495] Loss: 0.5954\n",
      "Epoch [64/300] Batch [250/495] Loss: 0.5931\n",
      "Epoch [65/300] Batch [250/495] Loss: 0.5941\n",
      "Epoch [66/300] Batch [250/495] Loss: 0.6007\n",
      "Epoch [67/300] Batch [250/495] Loss: 0.5901\n",
      "Epoch [68/300] Batch [250/495] Loss: 0.5941\n",
      "Epoch [69/300] Batch [250/495] Loss: 0.5866\n",
      "Epoch [70/300] Batch [250/495] Loss: 0.5923\n",
      "Epoch [71/300] Batch [250/495] Loss: 0.5965\n",
      "Epoch [72/300] Batch [250/495] Loss: 0.5861\n",
      "Epoch [73/300] Batch [250/495] Loss: 0.5906\n",
      "Epoch [74/300] Batch [250/495] Loss: 0.6009\n",
      "Epoch [75/300] Batch [250/495] Loss: 0.5912\n",
      "Epoch [76/300] Batch [250/495] Loss: 0.5873\n",
      "Epoch [77/300] Batch [250/495] Loss: 0.5820\n",
      "Epoch [78/300] Batch [250/495] Loss: 0.5834\n",
      "Epoch [79/300] Batch [250/495] Loss: 0.5762\n",
      "Epoch [80/300] Batch [250/495] Loss: 0.5947\n",
      "Epoch [81/300] Batch [250/495] Loss: 0.5860\n",
      "Epoch [82/300] Batch [250/495] Loss: 0.5826\n",
      "Epoch [83/300] Batch [250/495] Loss: 0.5742\n",
      "Epoch [84/300] Batch [250/495] Loss: 0.5758\n",
      "Epoch [85/300] Batch [250/495] Loss: 0.5785\n",
      "Epoch [86/300] Batch [250/495] Loss: 0.5721\n",
      "Epoch [87/300] Batch [250/495] Loss: 0.5855\n",
      "Epoch [88/300] Batch [250/495] Loss: 0.5725\n",
      "Epoch [89/300] Batch [250/495] Loss: 0.5738\n",
      "Epoch [90/300] Batch [250/495] Loss: 0.5780\n",
      "Epoch [91/300] Batch [250/495] Loss: 0.5732\n",
      "Epoch [92/300] Batch [250/495] Loss: 0.5696\n",
      "Epoch [93/300] Batch [250/495] Loss: 0.5718\n",
      "Epoch [94/300] Batch [250/495] Loss: 0.5708\n",
      "Epoch [95/300] Batch [250/495] Loss: 0.5727\n",
      "Epoch [96/300] Batch [250/495] Loss: 0.5625\n",
      "Epoch [97/300] Batch [250/495] Loss: 0.5625\n",
      "Epoch [98/300] Batch [250/495] Loss: 0.5671\n",
      "Epoch [99/300] Batch [250/495] Loss: 0.5658\n",
      "Epoch [100/300] Batch [250/495] Loss: 0.5644\n",
      "Epoch [101/300] Batch [250/495] Loss: 0.5690\n",
      "Epoch [102/300] Batch [250/495] Loss: 0.5714\n",
      "Epoch [103/300] Batch [250/495] Loss: 0.5619\n",
      "Epoch [104/300] Batch [250/495] Loss: 0.5712\n",
      "Epoch [105/300] Batch [250/495] Loss: 0.5700\n",
      "Epoch [106/300] Batch [250/495] Loss: 0.5676\n",
      "Epoch [107/300] Batch [250/495] Loss: 0.5654\n",
      "Epoch [108/300] Batch [250/495] Loss: 0.5709\n",
      "Epoch [109/300] Batch [250/495] Loss: 0.5583\n",
      "Epoch [110/300] Batch [250/495] Loss: 0.5654\n",
      "Epoch [111/300] Batch [250/495] Loss: 0.5544\n",
      "Epoch [112/300] Batch [250/495] Loss: 0.5486\n",
      "Epoch [113/300] Batch [250/495] Loss: 0.5465\n",
      "Epoch [114/300] Batch [250/495] Loss: 0.5590\n",
      "Epoch [115/300] Batch [250/495] Loss: 0.5533\n",
      "Epoch [116/300] Batch [250/495] Loss: 0.5614\n",
      "Epoch [117/300] Batch [250/495] Loss: 0.5569\n",
      "Epoch [118/300] Batch [250/495] Loss: 0.5508\n",
      "Epoch [119/300] Batch [250/495] Loss: 0.5540\n",
      "Epoch [120/300] Batch [250/495] Loss: 0.5542\n",
      "Epoch [121/300] Batch [250/495] Loss: 0.5514\n",
      "Epoch [122/300] Batch [250/495] Loss: 0.5592\n",
      "Epoch [123/300] Batch [250/495] Loss: 0.5490\n",
      "Epoch [124/300] Batch [250/495] Loss: 0.5468\n",
      "Epoch [125/300] Batch [250/495] Loss: 0.5466\n",
      "Epoch [126/300] Batch [250/495] Loss: 0.5542\n",
      "Epoch [127/300] Batch [250/495] Loss: 0.5474\n",
      "Epoch [128/300] Batch [250/495] Loss: 0.5461\n",
      "Epoch [129/300] Batch [250/495] Loss: 0.5472\n",
      "Epoch [130/300] Batch [250/495] Loss: 0.5398\n",
      "Epoch [131/300] Batch [250/495] Loss: 0.5485\n",
      "Epoch [132/300] Batch [250/495] Loss: 0.5487\n",
      "Epoch [133/300] Batch [250/495] Loss: 0.5462\n",
      "Epoch [134/300] Batch [250/495] Loss: 0.5498\n",
      "Epoch [135/300] Batch [250/495] Loss: 0.5522\n",
      "Epoch [136/300] Batch [250/495] Loss: 0.5439\n",
      "Epoch [137/300] Batch [250/495] Loss: 0.5400\n",
      "Epoch [138/300] Batch [250/495] Loss: 0.5447\n",
      "Epoch [139/300] Batch [250/495] Loss: 0.5421\n",
      "Epoch [140/300] Batch [250/495] Loss: 0.5379\n",
      "Epoch [141/300] Batch [250/495] Loss: 0.5367\n",
      "Epoch [142/300] Batch [250/495] Loss: 0.5323\n",
      "Epoch [143/300] Batch [250/495] Loss: 0.5466\n",
      "Epoch [144/300] Batch [250/495] Loss: 0.5410\n",
      "Epoch [145/300] Batch [250/495] Loss: 0.5519\n",
      "Epoch [146/300] Batch [250/495] Loss: 0.5361\n",
      "Epoch [147/300] Batch [250/495] Loss: 0.5432\n",
      "Epoch [148/300] Batch [250/495] Loss: 0.5326\n",
      "Epoch [149/300] Batch [250/495] Loss: 0.5446\n",
      "Epoch [150/300] Batch [250/495] Loss: 0.5411\n",
      "Epoch [151/300] Batch [250/495] Loss: 0.5342\n",
      "Epoch [152/300] Batch [250/495] Loss: 0.5338\n",
      "Epoch [153/300] Batch [250/495] Loss: 0.5268\n",
      "Epoch [154/300] Batch [250/495] Loss: 0.5308\n",
      "Epoch [155/300] Batch [250/495] Loss: 0.5309\n",
      "Epoch [156/300] Batch [250/495] Loss: 0.5356\n",
      "Epoch [157/300] Batch [250/495] Loss: 0.5422\n",
      "Epoch [158/300] Batch [250/495] Loss: 0.5317\n",
      "Epoch [159/300] Batch [250/495] Loss: 0.5398\n",
      "Epoch [160/300] Batch [250/495] Loss: 0.5380\n",
      "Epoch [161/300] Batch [250/495] Loss: 0.5288\n",
      "Epoch [162/300] Batch [250/495] Loss: 0.5322\n",
      "Epoch [163/300] Batch [250/495] Loss: 0.5291\n",
      "Epoch [164/300] Batch [250/495] Loss: 0.5285\n",
      "Epoch [165/300] Batch [250/495] Loss: 0.5361\n",
      "Epoch [166/300] Batch [250/495] Loss: 0.5265\n",
      "Epoch [167/300] Batch [250/495] Loss: 0.5250\n",
      "Epoch [168/300] Batch [250/495] Loss: 0.5262\n",
      "Epoch [169/300] Batch [250/495] Loss: 0.5270\n",
      "Epoch [170/300] Batch [250/495] Loss: 0.5302\n",
      "Epoch [171/300] Batch [250/495] Loss: 0.5264\n",
      "Epoch [172/300] Batch [250/495] Loss: 0.5317\n",
      "Epoch [173/300] Batch [250/495] Loss: 0.5223\n",
      "Epoch [174/300] Batch [250/495] Loss: 0.5350\n",
      "Epoch [175/300] Batch [250/495] Loss: 0.5188\n",
      "Epoch [176/300] Batch [250/495] Loss: 0.5306\n",
      "Epoch [177/300] Batch [250/495] Loss: 0.5227\n",
      "Epoch [178/300] Batch [250/495] Loss: 0.5205\n",
      "Epoch [179/300] Batch [250/495] Loss: 0.5351\n",
      "Epoch [180/300] Batch [250/495] Loss: 0.5237\n",
      "Epoch [181/300] Batch [250/495] Loss: 0.5321\n",
      "Epoch [182/300] Batch [250/495] Loss: 0.5216\n",
      "Epoch [183/300] Batch [250/495] Loss: 0.5296\n",
      "Epoch [184/300] Batch [250/495] Loss: 0.5319\n",
      "Epoch [185/300] Batch [250/495] Loss: 0.5237\n",
      "Epoch [186/300] Batch [250/495] Loss: 0.5249\n",
      "Epoch [187/300] Batch [250/495] Loss: 0.5232\n",
      "Epoch [188/300] Batch [250/495] Loss: 0.5217\n",
      "Epoch [189/300] Batch [250/495] Loss: 0.5079\n",
      "Epoch [190/300] Batch [250/495] Loss: 0.5075\n",
      "Epoch [191/300] Batch [250/495] Loss: 0.5251\n",
      "Epoch [192/300] Batch [250/495] Loss: 0.5174\n",
      "Epoch [193/300] Batch [250/495] Loss: 0.5171\n",
      "Epoch [194/300] Batch [250/495] Loss: 0.5226\n",
      "Epoch [195/300] Batch [250/495] Loss: 0.5206\n",
      "Epoch [196/300] Batch [250/495] Loss: 0.5183\n",
      "Epoch [197/300] Batch [250/495] Loss: 0.5146\n",
      "Epoch [198/300] Batch [250/495] Loss: 0.5223\n",
      "Epoch [199/300] Batch [250/495] Loss: 0.5195\n",
      "Epoch [200/300] Batch [250/495] Loss: 0.5226\n",
      "Epoch [201/300] Batch [250/495] Loss: 0.5129\n",
      "Epoch [202/300] Batch [250/495] Loss: 0.5203\n",
      "Epoch [203/300] Batch [250/495] Loss: 0.5140\n",
      "Epoch [204/300] Batch [250/495] Loss: 0.5159\n",
      "Epoch [205/300] Batch [250/495] Loss: 0.5180\n",
      "Epoch [206/300] Batch [250/495] Loss: 0.5241\n",
      "Epoch [207/300] Batch [250/495] Loss: 0.5114\n",
      "Epoch [208/300] Batch [250/495] Loss: 0.5193\n",
      "Epoch [209/300] Batch [250/495] Loss: 0.5145\n",
      "Epoch [210/300] Batch [250/495] Loss: 0.5076\n",
      "Epoch [211/300] Batch [250/495] Loss: 0.5113\n",
      "Epoch [212/300] Batch [250/495] Loss: 0.5191\n",
      "Epoch [213/300] Batch [250/495] Loss: 0.5174\n",
      "Epoch [214/300] Batch [250/495] Loss: 0.5189\n",
      "Epoch [215/300] Batch [250/495] Loss: 0.5098\n",
      "Epoch [216/300] Batch [250/495] Loss: 0.5205\n",
      "Epoch [217/300] Batch [250/495] Loss: 0.5065\n",
      "Epoch [218/300] Batch [250/495] Loss: 0.5134\n",
      "Epoch [219/300] Batch [250/495] Loss: 0.5087\n",
      "Epoch [220/300] Batch [250/495] Loss: 0.5164\n",
      "Epoch [221/300] Batch [250/495] Loss: 0.5059\n",
      "Epoch [222/300] Batch [250/495] Loss: 0.5111\n",
      "Epoch [223/300] Batch [250/495] Loss: 0.5141\n",
      "Epoch [224/300] Batch [250/495] Loss: 0.5080\n",
      "Epoch [225/300] Batch [250/495] Loss: 0.5016\n",
      "Epoch [226/300] Batch [250/495] Loss: 0.5117\n",
      "Epoch [227/300] Batch [250/495] Loss: 0.5057\n",
      "Epoch [228/300] Batch [250/495] Loss: 0.5044\n",
      "Epoch [229/300] Batch [250/495] Loss: 0.5166\n",
      "Epoch [230/300] Batch [250/495] Loss: 0.5107\n",
      "Epoch [231/300] Batch [250/495] Loss: 0.5082\n",
      "Epoch [232/300] Batch [250/495] Loss: 0.5163\n",
      "Epoch [233/300] Batch [250/495] Loss: 0.5203\n",
      "Epoch [234/300] Batch [250/495] Loss: 0.5110\n",
      "Epoch [235/300] Batch [250/495] Loss: 0.5095\n",
      "Epoch [236/300] Batch [250/495] Loss: 0.5091\n",
      "Epoch [237/300] Batch [250/495] Loss: 0.5079\n",
      "Epoch [238/300] Batch [250/495] Loss: 0.5003\n",
      "Epoch [239/300] Batch [250/495] Loss: 0.5074\n",
      "Epoch [240/300] Batch [250/495] Loss: 0.5031\n",
      "Epoch [241/300] Batch [250/495] Loss: 0.5051\n",
      "Epoch [242/300] Batch [250/495] Loss: 0.4997\n",
      "Epoch [243/300] Batch [250/495] Loss: 0.4998\n",
      "Epoch [244/300] Batch [250/495] Loss: 0.5070\n",
      "Epoch [245/300] Batch [250/495] Loss: 0.4992\n",
      "Epoch [246/300] Batch [250/495] Loss: 0.5105\n",
      "Epoch [247/300] Batch [250/495] Loss: 0.5137\n",
      "Epoch [248/300] Batch [250/495] Loss: 0.5069\n",
      "Epoch [249/300] Batch [250/495] Loss: 0.5063\n",
      "Epoch [250/300] Batch [250/495] Loss: 0.4998\n",
      "Epoch [251/300] Batch [250/495] Loss: 0.5063\n",
      "Epoch [252/300] Batch [250/495] Loss: 0.5001\n",
      "Epoch [253/300] Batch [250/495] Loss: 0.5104\n",
      "Epoch [254/300] Batch [250/495] Loss: 0.5046\n",
      "Epoch [255/300] Batch [250/495] Loss: 0.4990\n",
      "Epoch [256/300] Batch [250/495] Loss: 0.4990\n",
      "Epoch [257/300] Batch [250/495] Loss: 0.4957\n",
      "Epoch [258/300] Batch [250/495] Loss: 0.4997\n",
      "Epoch [259/300] Batch [250/495] Loss: 0.5005\n",
      "Epoch [260/300] Batch [250/495] Loss: 0.5136\n",
      "Epoch [261/300] Batch [250/495] Loss: 0.4968\n",
      "Epoch [262/300] Batch [250/495] Loss: 0.5013\n",
      "Epoch [263/300] Batch [250/495] Loss: 0.5058\n",
      "Epoch [264/300] Batch [250/495] Loss: 0.5009\n",
      "Epoch [265/300] Batch [250/495] Loss: 0.5093\n",
      "Epoch [266/300] Batch [250/495] Loss: 0.5030\n",
      "Epoch [267/300] Batch [250/495] Loss: 0.5053\n",
      "Epoch [268/300] Batch [250/495] Loss: 0.4942\n",
      "Epoch [269/300] Batch [250/495] Loss: 0.5011\n",
      "Epoch [270/300] Batch [250/495] Loss: 0.4940\n",
      "Epoch [271/300] Batch [250/495] Loss: 0.5037\n",
      "Epoch [272/300] Batch [250/495] Loss: 0.4991\n",
      "Epoch [273/300] Batch [250/495] Loss: 0.4901\n",
      "Epoch [274/300] Batch [250/495] Loss: 0.5052\n",
      "Epoch [275/300] Batch [250/495] Loss: 0.4898\n",
      "Epoch [276/300] Batch [250/495] Loss: 0.5000\n",
      "Epoch [277/300] Batch [250/495] Loss: 0.5000\n",
      "Epoch [278/300] Batch [250/495] Loss: 0.4942\n",
      "Epoch [279/300] Batch [250/495] Loss: 0.4942\n",
      "Epoch [280/300] Batch [250/495] Loss: 0.5017\n",
      "Epoch [281/300] Batch [250/495] Loss: 0.5026\n",
      "Epoch [282/300] Batch [250/495] Loss: 0.5085\n",
      "Epoch [283/300] Batch [250/495] Loss: 0.5101\n",
      "Epoch [284/300] Batch [250/495] Loss: 0.4908\n",
      "Epoch [285/300] Batch [250/495] Loss: 0.4871\n",
      "Epoch [286/300] Batch [250/495] Loss: 0.5035\n",
      "Epoch [287/300] Batch [250/495] Loss: 0.5002\n",
      "Epoch [288/300] Batch [250/495] Loss: 0.5079\n",
      "Epoch [289/300] Batch [250/495] Loss: 0.5058\n",
      "Epoch [290/300] Batch [250/495] Loss: 0.5039\n",
      "Epoch [291/300] Batch [250/495] Loss: 0.4988\n",
      "Epoch [292/300] Batch [250/495] Loss: 0.4910\n",
      "Epoch [293/300] Batch [250/495] Loss: 0.5018\n",
      "Epoch [294/300] Batch [250/495] Loss: 0.4906\n",
      "Epoch [295/300] Batch [250/495] Loss: 0.4966\n",
      "Epoch [296/300] Batch [250/495] Loss: 0.4880\n",
      "Epoch [297/300] Batch [250/495] Loss: 0.4915\n",
      "Epoch [298/300] Batch [250/495] Loss: 0.4956\n",
      "Epoch [299/300] Batch [250/495] Loss: 0.4945\n",
      "Epoch [300/300] Batch [250/495] Loss: 0.4887\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "print_freq = 250  \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0  \n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % print_freq == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}] Batch [{batch_idx+1}/{len(train_loader)}] Loss: {running_loss / print_freq:.4f}\")\n",
    "            running_loss = 0.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'game_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# TODO: Evaluate for seperate classes\n",
    "\n",
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc5d0a53b00113ddeee422859c93bab972c169b71b54eaf49823bc3a7db79142"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
